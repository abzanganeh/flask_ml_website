<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 1: The Attention Mechanism - Transformer Architecture Deep Dive</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/transformers/transformers.css') }}">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>


</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav">
            <div class="azbn-container">
                <a href="/tutorials/transformers" class="course-link">
                    <span>Transformer Architecture Deep Dive</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <div class="tutorial-header">
            <div class="azbn-container">
                <h1 class="chapter-title">Chapter 1: The Attention Mechanism</h1>
                <p class="chapter-subtitle">Foundation of Modern NLP - Understanding how attention revolutionized sequence modeling</p>
                
                <div class="chapter-progress">
                    <div class="chapter-progress-fill" data-progress="10"></div>
                </div>
                
                <div class="chapter-navigation">
                    <a href="/tutorials/transformers/chapter1" class="chapter-nav-btn active">Chapter 1</a>
                    <a href="/tutorials/transformers/chapter2" class="chapter-nav-btn">Chapter 2</a>
                    <a href="/tutorials/transformers/chapter3" class="chapter-nav-btn">Chapter 3</a>
                    <a href="/tutorials/transformers/chapter4" class="chapter-nav-btn">Chapter 4</a>
                    <a href="/tutorials/transformers/chapter5" class="chapter-nav-btn">Chapter 5</a>
                    <a href="/tutorials/transformers/chapter6" class="chapter-nav-btn">Chapter 6</a>
                    <a href="/tutorials/transformers/chapter7" class="chapter-nav-btn">Chapter 7</a>
                    <a href="/tutorials/transformers/chapter8" class="chapter-nav-btn">Chapter 8</a>
                    <a href="/tutorials/transformers/chapter9" class="chapter-nav-btn">Chapter 9</a>
                    <a href="/tutorials/transformers/chapter10" class="chapter-nav-btn">Chapter 10</a>
                </div>
                
                <div class="section-progress">
                    <div class="section-progress-fill" data-progress="14.3"></div>
                </div>
                
                <div class="section-nav">
                    <button class="section-nav-btn azbn-btn active" data-section="overview">Overview</button>
                    <button class="section-nav-btn azbn-btn" data-section="problem">The Problem</button>
                    <button class="section-nav-btn azbn-btn" data-section="attention">Attention Concept</button>
                    <button class="section-nav-btn azbn-btn" data-section="qkv">QKV Framework</button>
                    <button class="section-nav-btn azbn-btn" data-section="formula">Attention Formula</button>
                    <button class="section-nav-btn azbn-btn" data-section="implementation">Implementation</button>
                    <button class="section-nav-btn azbn-btn" data-section="quiz">Quiz</button>
                </div>
            </div>
        </div>

        <section class="azbn-section">
            <div class="azbn-container">
                <div class="learning-objectives-box">
                    <h2>Learning Objectives</h2>
                    <ul>
                        <li>Understand why attention was needed in sequence-to-sequence models</li>
                        <li>Master the Query, Key, Value (QKV) framework</li>
                        <li>Learn the mathematical formulation of attention</li>
                        <li>Understand how attention solves the information bottleneck</li>
                        <li>Implement attention mechanism from scratch</li>
                        <li>Recognize the limitations of RNNs/LSTMs that attention addresses</li>
                    </ul>
                </div>

                <main class="chapter-main-content">
                    <div id="overview" class="content-section active">
                        <h2>What is Attention?</h2>
                        
                        <div class="explanation-box">
                            <h3>The Revolutionary Idea</h3>
                            <p><strong>Attention is a mechanism that allows models to focus on relevant parts of the input when making predictions.</strong> It was introduced to solve a critical limitation in sequence-to-sequence models: the information bottleneck.</p>
                            
                            <p><strong>Think of attention like reading comprehension:</strong></p>
                            <ul>
                                <li><strong>Without attention:</strong> Like trying to summarize a book after reading it once - you remember only the main points, lose details</li>
                                <li><strong>With attention:</strong> Like having the book open while writing - you can look back at any part when needed</li>
                                <li><strong>Key insight:</strong> When generating each word, the model can "attend to" (look at) any part of the input sequence</li>
                            </ul>
                        </div>

                        <div class="example-box">
                            <h4>üìö Real-World Example: Translation</h4>
                            <p><strong>Translating: "The cat sat on the mat" ‚Üí "Le chat s'est assis sur le tapis"</strong></p>
                            
                            <div class="explanation-box">
                                <h5>Without Attention (Old RNN Approach):</h5>
                                <ul>
                                    <li>Encoder processes entire sentence into one fixed-size vector</li>
                                    <li>Decoder must generate translation from this single vector</li>
                                    <li><strong>Problem:</strong> Long sentences get compressed into same-size vector ‚Üí information loss</li>
                                    <li>Like trying to fit a 1000-page book summary into one sentence!</li>
                                </ul>
                            </div>
                            
                            <div class="explanation-box">
                                <h5>With Attention (Modern Approach):</h5>
                                <ul>
                                    <li>Encoder keeps all hidden states (one per input word)</li>
                                    <li>When generating "chat", decoder attends to "cat" in input</li>
                                    <li>When generating "tapis", decoder attends to "mat" in input</li>
                                    <li><strong>Result:</strong> Each output word can access any input word directly!</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div id="problem" class="content-section">
                        <h2>The Problem Attention Solves</h2>
                        
                        <div class="explanation-box">
                            <h3>‚ö†Ô∏è The Information Bottleneck</h3>
                            <p><strong>Sequence-to-sequence models (like RNNs) had a fundamental limitation:</strong></p>
                            
                            <div class="example-box">
                                <h4>The Bottleneck Problem</h4>
                                <p><strong>Old architecture (RNN encoder-decoder):</strong></p>
                                <ul>
                                    <li><strong>Encoder:</strong> Processes input sequence word by word</li>
                                    <li><strong>Final hidden state:</strong> Single vector representing entire input</li>
                                    <li><strong>Decoder:</strong> Must generate output from this single vector</li>
                                </ul>
                                
                                <p><strong>Why this is a problem:</strong></p>
                                <ul>
                                    <li>Short sentence: "Hello" ‚Üí Easy to compress into one vector</li>
                                    <li>Long sentence: "The quick brown fox jumps over the lazy dog and then runs through the forest..." ‚Üí Same-size vector!</li>
                                    <li><strong>Result:</strong> Information loss for long sequences</li>
                                    <li>Like trying to summarize War and Peace in one sentence</li>
                                </ul>
                            </div>
                            
                            <div class="explanation-box" style="margin-top: 2rem;">
                                <h4>Detailed Analysis of the Bottleneck</h4>
                                <p><strong>The fundamental issue:</strong> Traditional encoder-decoder architectures compress all information from the source sequence into a fixed-size context vector, regardless of sequence length. This creates several critical problems:</p>
                                
                                <div class="example-box">
                                    <h5>1. Information Loss in Long Sequences</h5>
                                    <p>Consider translating a 50-word sentence:</p>
                                    <ul>
                                        <li><strong>Encoder processes:</strong> Word 1 ‚Üí Word 2 ‚Üí ... ‚Üí Word 50</li>
                                        <li><strong>Each step:</strong> Hidden state updates, but earlier information gets diluted</li>
                                        <li><strong>Final state:</strong> Must encode all 50 words in same-size vector as a 5-word sentence</li>
                                        <li><strong>Result:</strong> Early words and fine details are lost or compressed beyond recognition</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>2. Fixed Context Window</h5>
                                    <p>The context vector has a fixed dimension (e.g., 512 or 1024), which means:</p>
                                    <ul>
                                        <li>Short sequences: Most of the vector space is unused or redundant</li>
                                        <li>Long sequences: Critical information must be discarded or averaged out</li>
                                        <li>No adaptive allocation of representation capacity based on sequence complexity</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>3. Sequential Processing Bottleneck</h5>
                                    <p>RNNs process sequences sequentially, which means:</p>
                                    <ul>
                                        <li>Cannot parallelize computation across sequence positions</li>
                                        <li>Long-range dependencies require many steps, leading to vanishing gradients</li>
                                        <li>Each word's representation depends on all previous words, creating a dependency chain</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>4. Real-World Impact</h5>
                                    <p><strong>Translation example:</strong> Translating "The cat that the dog that the bird saw chased sat on the mat"</p>
                                    <ul>
                                        <li>Complex nested structure with multiple relative clauses</li>
                                        <li>RNN encoder: Must compress all relationships into one vector</li>
                                        <li>Decoder: Tries to reconstruct meaning from compressed representation</li>
                                        <li><strong>Problem:</strong> Which "that" refers to which noun? This information is lost!</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="explanation-box" style="margin-top: 2rem;">
                                <h4>Why This Matters for NLP Tasks</h4>
                                <p><strong>Different tasks suffer differently from the bottleneck:</strong></p>
                                
                                <div class="example-box">
                                    <h5>Machine Translation</h5>
                                    <ul>
                                        <li>Long sentences lose word alignment information</li>
                                        <li>Complex grammatical structures get flattened</li>
                                        <li>Idiomatic expressions and context-dependent meanings are lost</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>Text Summarization</h5>
                                    <ul>
                                        <li>Important details from early in the document are forgotten</li>
                                        <li>Key relationships between distant sentences are lost</li>
                                        <li>Summary quality degrades significantly for long documents</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>Question Answering</h5>
                                    <ul>
                                        <li>Questions about specific details require accessing exact source positions</li>
                                        <li>Single vector cannot preserve all positional information</li>
                                        <li>Answer quality drops for questions requiring long-range context</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div id="attention" class="content-section">
                        <h2>The Attention Concept</h2>
                        
                        <div class="explanation-box">
                            <h3>üîç How Attention Works</h3>
                            <p><strong>Attention allows the decoder to look at ALL encoder hidden states, not just the final one:</strong></p>
                            
                            <div class="formula-box">
                                <h4>Attention Mechanism</h4>
                                <p><strong>For each decoder step:</strong></p>
                                <ol>
                                    <li>Compute attention scores for all encoder positions</li>
                                    <li>Convert scores to attention weights (probabilities)</li>
                                    <li>Create weighted combination of encoder hidden states</li>
                                    <li>Use this combination (context vector) for decoding</li>
                                </ol>
                            </div>
                            
                            <div class="explanation-box" style="margin-top: 2rem;">
                                <h4>Breaking Down the Attention Process</h4>
                                <p><strong>Attention fundamentally changes how information flows from encoder to decoder:</strong></p>
                                
                                <div class="example-box">
                                    <h5>Traditional Approach (Without Attention)</h5>
                                    <ul>
                                        <li>Encoder: Input sequence ‚Üí Final hidden state (single vector)</li>
                                        <li>Decoder: Final hidden state ‚Üí Output sequence</li>
                                        <li><strong>Information flow:</strong> All input ‚Üí One vector ‚Üí All output</li>
                                        <li><strong>Problem:</strong> Information bottleneck at the single vector</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>Attention-Based Approach</h5>
                                    <ul>
                                        <li>Encoder: Input sequence ‚Üí All hidden states (one per input position)</li>
                                        <li>Decoder: For each output position, dynamically selects relevant encoder states</li>
                                        <li><strong>Information flow:</strong> All input states ‚Üí Dynamic selection ‚Üí Each output position</li>
                                        <li><strong>Advantage:</strong> Each output can access any input position directly</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="explanation-box" style="margin-top: 2rem;">
                                <h4>Step-by-Step Attention Process</h4>
                                
                                <div class="example-box">
                                    <h5>Step 1: Compute Attention Scores</h5>
                                    <p>For each decoder position, compute how relevant each encoder position is:</p>
                                    <ul>
                                        <li>Compare decoder's current state with all encoder hidden states</li>
                                        <li>Generate a score for each encoder position</li>
                                        <li>Higher score = more relevant for current decoding step</li>
                                        <li><strong>Result:</strong> A vector of scores (one per encoder position)</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>Step 2: Normalize to Attention Weights</h5>
                                    <p>Convert raw scores into probabilities using softmax:</p>
                                    <ul>
                                        <li>Apply softmax to attention scores</li>
                                        <li>Ensures all weights sum to 1 (probability distribution)</li>
                                        <li>Higher scores get exponentially higher weights</li>
                                        <li><strong>Result:</strong> Attention weights that sum to 1.0</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>Step 3: Create Context Vector</h5>
                                    <p>Weighted combination of encoder hidden states:</p>
                                    <ul>
                                        <li>Multiply each encoder hidden state by its attention weight</li>
                                        <li>Sum all weighted encoder states</li>
                                        <li>This creates a context vector specific to current decoder position</li>
                                        <li><strong>Result:</strong> A context vector that emphasizes relevant input positions</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>Step 4: Use Context for Decoding</h5>
                                    <p>Combine context vector with decoder's current state:</p>
                                    <ul>
                                        <li>Context vector provides relevant source information</li>
                                        <li>Decoder state provides target-side context</li>
                                        <li>Combined information guides next token generation</li>
                                        <li><strong>Result:</strong> Better translation/decoding quality</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="explanation-box" style="margin-top: 2rem;">
                                <h4>Why Attention Solves the Bottleneck</h4>
                                <p><strong>Key advantages of attention over fixed context vector:</strong></p>
                                
                                <div class="example-box">
                                    <h5>1. Dynamic Information Access</h5>
                                    <ul>
                                        <li>Each decoder position can focus on different encoder positions</li>
                                        <li>No fixed compression - information remains accessible</li>
                                        <li>Model learns which positions to attend to for each output</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>2. Preserves All Information</h5>
                                    <ul>
                                        <li>All encoder hidden states are available, not just the final one</li>
                                        <li>No information is lost through compression</li>
                                        <li>Early and late positions in input are equally accessible</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>3. Interpretable Alignment</h5>
                                    <ul>
                                        <li>Attention weights show which input words align with which output words</li>
                                        <li>Provides interpretability - we can visualize what the model focuses on</li>
                                        <li>Helps debug and understand model behavior</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>4. Handles Variable Lengths</h5>
                                    <ul>
                                        <li>Works equally well for short and long sequences</li>
                                        <li>No fixed-size bottleneck</li>
                                        <li>Scales naturally with sequence length</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div id="qkv" class="content-section">
                        <h2>Query, Key, Value (QKV) Framework</h2>
                        
                        <div class="explanation-box">
                            <h3>üîë The Three Components</h3>
                            <p><strong>Attention uses three vectors: Query, Key, and Value</strong></p>
                            
                            <div class="example-box">
                                <h4>üìö Library Analogy</h4>
                                <p><strong>Think of attention like searching a library:</strong></p>
                                <ul>
                                    <li><strong>Query (Q):</strong> Your question - "I need information about cats"</li>
                                    <li><strong>Key (K):</strong> Book titles/index - Each book has a title describing its content</li>
                                    <li><strong>Value (V):</strong> Book content - The actual information in each book</li>
                                </ul>
                                
                                <p><strong>The process:</strong></p>
                                <ol>
                                    <li>Compare your Query to all Keys (book titles)</li>
                                    <li>Find which Keys match your Query best</li>
                                    <li>Retrieve the Values (content) from matching books</li>
                                    <li>Combine the relevant Values to answer your question</li>
                                </ol>
                            </div>
                            
                            <div class="explanation-box" style="margin-top: 2rem;">
                                <h4>Understanding Query, Key, and Value</h4>
                                
                                <div class="example-box">
                                    <h5>Query (Q) - "What am I looking for?"</h5>
                                    <p><strong>In sequence-to-sequence models:</strong></p>
                                    <ul>
                                        <li>Query comes from the decoder's current hidden state</li>
                                        <li>Represents: "What information do I need right now to generate the next word?"</li>
                                        <li>Example: When generating "chat" (French for "cat"), the query asks "What in the source sentence relates to what I'm translating?"</li>
                                        <li><strong>Shape:</strong> (1, d_k) for one query, or (n, d_k) for multiple queries</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>Key (K) - "What information is available?"</h5>
                                    <p><strong>In sequence-to-sequence models:</strong></p>
                                    <ul>
                                        <li>Keys come from encoder hidden states</li>
                                        <li>Represents: "What information does each source position contain?"</li>
                                        <li>Example: Each source word has a key that describes its content and relevance</li>
                                        <li><strong>Shape:</strong> (m, d_k) where m is source sequence length</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>Value (V) - "What is the actual information?"</h5>
                                    <p><strong>In sequence-to-sequence models:</strong></p>
                                    <ul>
                                        <li>Values also come from encoder hidden states</li>
                                        <li>Represents: "The actual content/representation at each source position"</li>
                                        <li>Example: The full semantic representation of each source word</li>
                                        <li><strong>Shape:</strong> (m, d_v) where m is source sequence length</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="explanation-box" style="margin-top: 2rem;">
                                <h4>Why Separate Q, K, and V?</h4>
                                <p><strong>Key insight: Query and Key determine relevance, Value provides the information</strong></p>
                                
                                <div class="example-box">
                                    <h5>1. Separation of Concerns</h5>
                                    <ul>
                                        <li><strong>Q and K:</strong> Used together to compute "how relevant is this?"</li>
                                        <li><strong>V:</strong> Used to provide "what is the actual information?"</li>
                                        <li>This separation allows the model to learn different representations for matching vs. content</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>2. Flexibility in Representation</h5>
                                    <ul>
                                        <li>Q, K, V can have different learned projections</li>
                                        <li>Model can learn: "How to describe what I'm looking for" (Q) vs "How to describe what I have" (K) vs "What information to extract" (V)</li>
                                        <li>This flexibility improves model capacity and performance</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>3. Real-World Example</h5>
                                    <p><strong>Translating: "The cat sat on the mat" ‚Üí "Le chat s'est assis sur le tapis"</strong></p>
                                    <ul>
                                        <li>When generating "chat":</li>
                                        <li><strong>Query:</strong> "I'm generating a noun, what should it be?"</li>
                                        <li><strong>Keys:</strong> ["The" ‚Üí article, "cat" ‚Üí noun, "sat" ‚Üí verb, ...]</li>
                                        <li><strong>Attention:</strong> High score for "cat" key (matches query for noun)</li>
                                        <li><strong>Value:</strong> The full representation of "cat" (semantic, grammatical info)</li>
                                        <li><strong>Result:</strong> Context vector emphasizes "cat" information</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="explanation-box" style="margin-top: 2rem;">
                                <h4>Computing Q, K, V from Input</h4>
                                <p><strong>In practice, Q, K, V are computed from input embeddings using learned linear transformations:</strong></p>
                                
                                <div class="example-box">
                                    <h5>Linear Projections</h5>
                                    <ul>
                                        <li><strong>Input:</strong> Embeddings X (e.g., from encoder or decoder)</li>
                                        <li><strong>Query:</strong> Q = X √ó W_Q (learned weight matrix)</li>
                                        <li><strong>Key:</strong> K = X √ó W_K (learned weight matrix)</li>
                                        <li><strong>Value:</strong> V = X √ó W_V (learned weight matrix)</li>
                                        <li><strong>Why different matrices?</strong> Allows model to learn different "views" of the same input</li>
                                    </ul>
                                </div>
                                
                                <div class="example-box">
                                    <h5>Dimension Considerations</h5>
                                    <ul>
                                        <li>Q and K typically have same dimension (d_k) for dot product compatibility</li>
                                        <li>V can have different dimension (d_v), though often d_v = d_k</li>
                                        <li>Common: d_k = d_v = 64 (for each head in multi-head attention)</li>
                                        <li>Original Transformer: d_model = 512, d_k = d_v = 64</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div id="formula" class="content-section">
                        <h2>Attention Formula</h2>
                        
                        <div class="formula-box">
                            <h4>Scaled Dot-Product Attention</h4>
                            
                            <div class="formula-display">
                                <strong>Attention(Q, K, V) = softmax(QK^T / ‚àöd_k) √ó V</strong>
                            </div>
                            
                            <div class="formula-explanation">
                                <h5>Step-by-Step Breakdown:</h5>
                                <ol>
                                    <li><strong>QK^T:</strong> Compute similarity between queries and keys (dot product)</li>
                                    <li><strong>/ ‚àöd_k:</strong> Scale by square root of key dimension (prevents large values)</li>
                                    <li><strong>softmax(...):</strong> Convert scores to probabilities (attention weights)</li>
                                    <li><strong>√ó V:</strong> Weighted sum of values based on attention weights</li>
                                </ol>
                            </div>
                        </div>
                        
                        <div class="explanation-box" style="margin-top: 2rem;">
                            <h4>Deep Dive into Each Component</h4>
                            
                            <div class="example-box">
                                <h5>1. Computing QK^T (Dot Product Similarity)</h5>
                                <p><strong>What it does:</strong> Measures how similar each query is to each key</p>
                                <ul>
                                    <li><strong>Mathematical operation:</strong> Matrix multiplication of Q and K^T (transpose of K)</li>
                                    <li><strong>Result shape:</strong> (num_queries, num_keys)</li>
                                    <li><strong>Each element:</strong> Dot product between one query and one key</li>
                                    <li><strong>Higher values:</strong> Query and key are more similar/relevant</li>
                                </ul>
                                
                                <p><strong>Example:</strong> If Q has 1 query and K has 5 keys:</p>
                                <ul>
                                    <li>QK^T produces 5 scores: [score_1, score_2, score_3, score_4, score_5]</li>
                                    <li>score_1 = how similar query is to key_1</li>
                                    <li>score_2 = how similar query is to key_2</li>
                                    <li>And so on...</li>
                                </ul>
                            </div>
                            
                            <div class="example-box">
                                <h5>2. Scaling by ‚àöd_k (Why It's Critical)</h5>
                                <p><strong>The problem without scaling:</strong></p>
                                <ul>
                                    <li>Dot products grow with dimension d_k</li>
                                    <li>For large d_k, dot products can be very large (e.g., 100, 200, 500+)</li>
                                    <li>Large values push softmax into saturation regions</li>
                                    <li><strong>Result:</strong> Very small gradients, making training difficult</li>
                                </ul>
                                
                                <p><strong>The solution - scaling:</strong></p>
                                <ul>
                                    <li>Divide by ‚àöd_k to normalize the scale</li>
                                    <li>Keeps dot products in a reasonable range (typically -10 to +10)</li>
                                    <li>Softmax operates in a region with good gradients</li>
                                    <li><strong>Result:</strong> Stable training and better gradients</li>
                                </ul>
                                
                                <p><strong>Mathematical intuition:</strong> If Q and K have dimension d_k, their dot product has variance proportional to d_k. Dividing by ‚àöd_k normalizes the variance to 1.</p>
                            </div>
                            
                            <div class="example-box">
                                <h5>3. Softmax Normalization</h5>
                                <p><strong>What softmax does:</strong> Converts raw scores into a probability distribution</p>
                                <ul>
                                    <li><strong>Input:</strong> Raw attention scores (can be any real numbers)</li>
                                    <li><strong>Output:</strong> Probabilities that sum to 1.0</li>
                                    <li><strong>Formula:</strong> softmax(x_i) = exp(x_i) / Œ£ exp(x_j)</li>
                                    <li><strong>Effect:</strong> Higher scores get exponentially higher probabilities</li>
                                </ul>
                                
                                <p><strong>Example:</strong> Scores [2, 1, 0.5] ‚Üí Softmax ‚Üí [0.58, 0.32, 0.10]</p>
                                <ul>
                                    <li>Highest score (2) gets 58% of attention</li>
                                    <li>Medium score (1) gets 32%</li>
                                    <li>Lowest score (0.5) gets 10%</li>
                                    <li>All sum to 1.0 (probability distribution)</li>
                                </ul>
                            </div>
                            
                            <div class="example-box">
                                <h5>4. Weighted Sum with Values</h5>
                                <p><strong>Final step:</strong> Multiply attention weights by values and sum</p>
                                <ul>
                                    <li><strong>Attention weights:</strong> [0.58, 0.32, 0.10] (from softmax)</li>
                                    <li><strong>Values:</strong> [V‚ÇÅ, V‚ÇÇ, V‚ÇÉ] (encoder hidden states)</li>
                                    <li><strong>Output:</strong> 0.58√óV‚ÇÅ + 0.32√óV‚ÇÇ + 0.10√óV‚ÇÉ</li>
                                    <li><strong>Result:</strong> A context vector that emphasizes V‚ÇÅ (most relevant)</li>
                                </ul>
                                
                                <p><strong>Why this works:</strong></p>
                                <ul>
                                    <li>More relevant positions (higher attention weights) contribute more</li>
                                    <li>Less relevant positions contribute less</li>
                                    <li>Creates a focused representation for the current decoding step</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="explanation-box" style="margin-top: 2rem;">
                            <h4>Complete Mathematical Flow</h4>
                            <p><strong>Let's trace through a concrete example:</strong></p>
                            
                            <div class="example-box">
                                <h5>Example: Translating "cat" ‚Üí "chat"</h5>
                                <p><strong>Setup:</strong></p>
                                <ul>
                                    <li>Source: "The cat sat on the mat" (5 words)</li>
                                    <li>Currently generating: "chat" (French for "cat")</li>
                                    <li>d_k = 64</li>
                                </ul>
                                
                                <p><strong>Step 1: Compute QK^T</strong></p>
                                <ul>
                                    <li>Q: Query from decoder (1 query vector, 64-dim)</li>
                                    <li>K: Keys from encoder (5 key vectors, each 64-dim)</li>
                                    <li>QK^T: [0.2, 8.5, 1.1, 0.3, 0.5] (5 scores, one per source word)</li>
                                    <li>High score (8.5) at position 1 ‚Üí "cat" is highly relevant!</li>
                                </ul>
                                
                                <p><strong>Step 2: Scale by ‚àöd_k</strong></p>
                                <ul>
                                    <li>‚àö64 = 8</li>
                                    <li>Scaled scores: [0.025, 1.0625, 0.1375, 0.0375, 0.0625]</li>
                                    <li>Scores are now in a reasonable range</li>
                                </ul>
                                
                                <p><strong>Step 3: Apply Softmax</strong></p>
                                <ul>
                                    <li>Softmax([0.025, 1.0625, 0.1375, 0.0375, 0.0625])</li>
                                    <li>Attention weights: [0.05, 0.70, 0.10, 0.05, 0.10]</li>
                                    <li>70% attention on "cat" (position 1) - exactly what we want!</li>
                                </ul>
                                
                                <p><strong>Step 4: Weighted Sum</strong></p>
                                <ul>
                                    <li>0.05√óV("The") + 0.70√óV("cat") + 0.10√óV("sat") + 0.05√óV("on") + 0.10√óV("the")</li>
                                    <li>Context vector heavily emphasizes "cat" information</li>
                                    <li>Decoder uses this to generate "chat"</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div id="implementation" class="content-section">
                        <h2>Implementation</h2>
                        
                        <div class="code-box">
                            <h4>Attention Implementation</h4>
                            <pre><code class="language-python">import numpy as np

def attention(Q, K, V):
    """
    Scaled dot-product attention
    
    Parameters:
    Q: Query matrix (seq_len_q, d_k)
    K: Key matrix (seq_len_k, d_k)
    V: Value matrix (seq_len_v, d_v)
    """
    d_k = K.shape[-1]
    
    # Compute attention scores
    scores = np.dot(Q, K.T) / np.sqrt(d_k)
    
    # Apply softmax
    attention_weights = softmax(scores, axis=-1)
    
    # Weighted sum of values
    output = np.dot(attention_weights, V)
    
    return output, attention_weights

def softmax(x, axis=-1):
    """Softmax function"""
    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))
    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)

# Example usage
Q = np.random.randn(5, 64)  # 5 queries, 64 dimensions
K = np.random.randn(10, 64)  # 10 keys, 64 dimensions
V = np.random.randn(10, 64)  # 10 values, 64 dimensions

output, weights = attention(Q, K, V)
print(f"Output shape: {output.shape}")  # (5, 64)
print(f"Attention weights shape: {weights.shape}")  # (5, 10)</code></pre>
                        </div>
                    </div>

                    <div id="quiz" class="content-section">
                        <h2>Test Your Understanding</h2>
                        
                        <div class="quiz-container">
                            <div class="quiz-question">
                                <h3>Question 1: What problem does attention solve in sequence-to-sequence models?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) The information bottleneck where all input is compressed into one vector</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Slow computation speed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Memory limitations</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Overfitting</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 2: What does the Query (Q) represent in attention?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) What we're looking for</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) The input data</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) The output data</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) The weights</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 3: Explain the attention mechanism in your own words.</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Attention lets a model focus on relevant parts of the input when producing each output. It computes how much each input position should influence the current output by comparing queries with keys and using those scores to weight the values</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) It processes all inputs equally</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) It only looks at the first input</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) It ignores inputs</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 4: What is the mathematical formula for attention scores?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) \(Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\) where d_k is the dimension of keys</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) \(Attention = Q + K\)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) \(Attention = Q \times K\)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) \(Attention = V\)</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 5: Why do we divide by sqrt(d_k) in the attention formula?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) To prevent the dot products from growing too large, which would push softmax into regions with extremely small gradients, making training unstable</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) To make computation faster</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) To reduce memory</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) It's not needed</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 6: What is the difference between Key (K) and Value (V) in attention?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Keys are used to compute attention scores (how relevant each position is), while values contain the actual information that gets weighted and summed to produce the output</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) They're the same</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Keys are outputs, values are inputs</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) No difference</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 7: How does attention solve the information bottleneck in sequence-to-sequence models?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Instead of compressing all input into a single fixed-size vector, attention allows the decoder to directly access all encoder states, dynamically focusing on relevant parts for each output step</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) By using larger vectors</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) By processing faster</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) By using less memory</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 8: What happens after computing attention scores?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Scores are passed through softmax to get attention weights (probabilities), then these weights are used to compute a weighted sum of the values</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Scores are used directly</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Scores are discarded</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Only maximum score is used</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 9: Why is attention better than fixed-size encoding for long sequences?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Fixed encoding loses information as sequence length increases, while attention maintains access to all positions and can focus on the most relevant parts regardless of sequence length</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) It's faster</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) It uses less memory</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) No difference</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 10: How would you implement attention from scratch?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Create Q, K, V matrices from input, compute scores as Q times K transpose, scale by sqrt(d_k), apply softmax, multiply by V to get weighted sum. Each step uses matrix operations</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Just add Q and K</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Use only V</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Random operations</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 11: What is the computational complexity of attention?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) O(n¬≤) where n is sequence length, because we compute attention scores between every pair of positions (each query attends to all keys)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) O(n)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) O(1)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) O(log n)</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 12: How does attention differ from RNN-based sequence modeling?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) RNNs process sequentially and struggle with long dependencies, while attention processes all positions in parallel and can directly model relationships between any positions regardless of distance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) They're the same</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) RNNs are always better</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Attention is sequential</div>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </section>
    </main>

    <footer style="background: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 2px solid #5B7553;">
        <div class="azbn-container" style="text-align: center;">
            <button onclick="scrollToSectionNav()" class="azbn-btn" style="margin: 0.5rem;">
                ‚Üë Back to Section Navigation
            </button>
            <div style="margin-top: 1.5rem;">
                <a href="/tutorials/transformers" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Back to Tutorial</a>
                <a href="/tutorials/transformers/chapter2" class="azbn-btn" style="text-decoration: none; margin: 0.5rem;">Chapter 2: Self-Attention ‚Üí</a>
            </div>
        </div>
    </footer>
    
        <!-- KaTeX for math rendering -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
<script src="{{ url_for('static', filename='js/tutorials/transformers/shared-tutorial.js') }}"></script>
    <script>
        function scrollToSectionNav() {
            const sectionNav = document.querySelector('.section-nav');
            if (sectionNav) {
                sectionNav.scrollIntoView({ behavior: 'smooth', block: 'start' });
            }
        }
        
        function checkAnswer(element, isCorrect) {
            element.parentNode.querySelectorAll('.quiz-option').forEach(opt => {
                opt.classList.remove('correct', 'incorrect');
            });
            if (isCorrect) {
                element.classList.add('correct');
                element.textContent += ' ‚úì Correct!';
            } else {
                element.classList.add('incorrect');
                element.textContent += ' ‚úó Incorrect';
                const correctOption = Array.from(element.parentNode.querySelectorAll('.quiz-option'))
                    .find(opt => {
                        const onclick = opt.getAttribute('onclick') || '';
                        return onclick.includes('true');
                    });
                if (correctOption && !correctOption.classList.contains('incorrect')) {
                    correctOption.classList.add('correct');
                    correctOption.textContent += ' ‚úì Correct Answer';
                }
            }
        }
            
// Initialize KaTeX rendering - ensure KaTeX is loaded first
        function initKaTeX() {
            if (typeof katex !== 'undefined' && typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "\\[", right: "\\]", display: true},
                        {left: "$", right: "$", display: false},
                        {left: "\\(", right: "\\)", display: false}
                    ],
                    throwOnError: false
                });
            } else {
                // Retry if KaTeX not loaded yet
                setTimeout(initKaTeX, 100);
                return;
            }
            
            // Initialize Prism.js syntax highlighting
            if (typeof Prism !== 'undefined') {
                Prism.highlightAll();
            }
        }
        
        // Wait for DOM and KaTeX to be ready
        if (document.readyState === 'loading') {
            document.addEventListener("DOMContentLoaded", initKaTeX);
        } else {
            // DOM already loaded, wait for KaTeX
            initKaTeX();
    </script>
</body>
</html>
