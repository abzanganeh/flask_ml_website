<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 4: Ensemble Methods - The Power of Many - ML Model Relationships</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/ml-model-relationships/ml-model-relationships.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/ml-model-relationships/chapter4.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/nlp/nlp.css') }}">
    <script src="{{ url_for('static', filename='js/tutorials/ml-model-relationships/shared-tutorial.js') }}"></script>
    <script src="{{ url_for('static', filename='js/tutorials/ml-model-relationships/chapter4.js') }}"></script>

</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav" style="top: 50px;">
            <div class="azbn-container" style="display: flex; justify-content: space-between; align-items: center;">
                <a href="/tutorials/ml-model-relationships" style="text-decoration: none; color: #4f46e5; display: flex; align-items: center; gap: 0.5rem;">
                    <span>ML Model Relationships</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main style="padding-top: 100px;">
        <!-- Tutorial Header -->
        <div class="nlp-header">
            <h1>Chapter 4: Ensemble Methods - The Power of Many</h1>
            <p>Discover how combining multiple models creates superior performance through bagging and boosting</p>
            <div class="progress-bar">
                <div class="progress-fill" style="width: 50%;"></div>
            </div>
        </div>

        <!-- Course Navigation -->
        <div class="course-nav">
            <button class="nav-btn" onclick="window.location.href='/tutorials/ml-model-relationships/chapter1'">Chapter 1</button>
            <button class="nav-btn" onclick="window.location.href='/tutorials/ml-model-relationships/chapter2'">Chapter 2</button>
            <button class="nav-btn" onclick="window.location.href='/tutorials/ml-model-relationships/chapter3'">Chapter 3</button>
            <button class="nav-btn active" onclick="window.location.href='/tutorials/ml-model-relationships/chapter4'">Chapter 4</button>
            <button class="nav-btn" onclick="window.location.href='/tutorials/ml-model-relationships/chapter5'">Chapter 5</button>
            <button class="nav-btn" onclick="window.location.href='/tutorials/ml-model-relationships/chapter6'">Chapter 6</button>
            <button class="nav-btn" onclick="window.location.href='/tutorials/ml-model-relationships/chapter7'">Chapter 7</button>
            <button class="nav-btn" onclick="window.location.href='/tutorials/ml-model-relationships/chapter8'">Chapter 8</button>
        </div>

        <section class="azbn-section">
            <div class="azbn-container chapter1-container">

                <div class="progress-tracker">
                    <div class="progress-dot completed"></div>
                    <div class="progress-dot completed"></div>
                    <div class="progress-dot completed"></div>
                    <div class="progress-dot completed"></div>
                    <div class="progress-dot"></div>
                </div>

                <div class="section-nav">
                    <button class="active" onclick="showSection('overview')">Overview</button>
                    <button onclick="showSection('wisdom')">Wisdom of Crowds</button>
                    <button onclick="showSection('bagging')">Bagging</button>
                    <button onclick="showSection('boosting')">Boosting</button>
                    <button onclick="showSection('quiz')">Quiz</button>
                </div>

                <!-- Overview Section -->
                <div id="overview" class="content-section active">
                    <h2>Why Single Models Aren't Enough</h2>
                    <p>
                        Even with regularization, single models have inherent limitations. Each model represents 
                        one perspective on the data. What if we could combine multiple perspectives?
                    </p>
                    
                    <div class="azbn-card">
                        <h3>The Ensemble Solution</h3>
                        <p>Ensemble methods combine predictions from multiple models to create a stronger predictor:</p>
                        
                        <div class="process-flow">
                            <div class="process-step">Train Multiple Models</div>
                            <div class="process-arrow">→</div>
                            <div class="process-step">Combine Predictions</div>
                            <div class="process-arrow">→</div>
                            <div class="process-step">Final Prediction</div>
                        </div>
                        
                        <p><strong>Key Insight:</strong> Individual models make different types of errors. 
                        When combined intelligently, these errors can cancel out!</p>
                    </div>

                    <div style="text-align: center; margin: 2rem 0;">
                        <img src="/static/images/tutorials/ml-model-relationships/chapter4/ensemble-voting.png" 
                             alt="Ensemble voting illustration showing multiple models contributing to final prediction"
                             style="width: 100%; max-width: 700px; border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15);">
                    </div>

                    <div class="ensemble-demo">
                        <h4>Interactive Ensemble Voting Demo</h4>
                        <p>Click on models to see how ensemble voting works:</p>
                        
                        <div class="voting-visualization">
                            <div class="model-vote" onclick="toggleModelPrediction(1)">
                                <div class="vote-prediction" id="model1-pred">Yes</div>
                                <div class="vote-confidence">85% conf</div>
                                <div style="font-size: 0.8rem; margin-top: 0.5rem;">Model 1</div>
                            </div>
                            <div class="model-vote" onclick="toggleModelPrediction(2)">
                                <div class="vote-prediction" id="model2-pred">No</div>
                                <div class="vote-confidence">73% conf</div>
                                <div style="font-size: 0.8rem; margin-top: 0.5rem;">Model 2</div>
                            </div>
                            <div class="model-vote" onclick="toggleModelPrediction(3)">
                                <div class="vote-prediction" id="model3-pred">Yes</div>
                                <div class="vote-confidence">91% conf</div>
                                <div style="font-size: 0.8rem; margin-top: 0.5rem;">Model 3</div>
                            </div>
                            <div class="model-vote" onclick="toggleModelPrediction(4)">
                                <div class="vote-prediction" id="model4-pred">Yes</div>
                                <div class="vote-confidence">67% conf</div>
                                <div style="font-size: 0.8rem; margin-top: 0.5rem;">Model 4</div>
                            </div>
                            <div class="model-vote" onclick="toggleModelPrediction(5)">
                                <div class="vote-prediction" id="model5-pred">No</div>
                                <div class="vote-confidence">79% conf</div>
                                <div style="font-size: 0.8rem; margin-top: 0.5rem;">Model 5</div>
                            </div>
                        </div>
                        
                        <div class="ensemble-result">
                            <div style="font-size: 2rem; font-weight: bold; margin-bottom: 0.5rem;" id="ensemble-prediction">YES</div>
                            <div style="font-size: 1.1rem;" id="ensemble-reasoning">3 models vote YES, 2 vote NO</div>
                            <div style="font-size: 0.9rem; opacity: 0.9; margin-top: 0.5rem;" id="ensemble-confidence">Average confidence: 79%</div>
                        </div>
                    </div>

                    <h3>Two Main Approaches</h3>
                    <p>There are two fundamental ways to create ensemble models:</p>
                    
                    <div class="bagging-boosting-comparison">
                        <div class="method-card bagging-card">
                            <h4>Bagging (Bootstrap Aggregating)</h4>
                            <p><strong>Strategy:</strong> Train models independently on different data samples</p>
                            <ul>
                                <li>Models trained in parallel</li>
                                <li>Each model sees different data subset</li>
                                <li>Final prediction: average/vote</li>
                                <li>Reduces variance</li>
                            </ul>
                            <p><strong>Example:</strong> Random Forest</p>
                        </div>
                        
                        <div class="method-card boosting-card">
                            <h4>Boosting</h4>
                            <p><strong>Strategy:</strong> Train models sequentially, each fixing previous errors</p>
                            <ul>
                                <li>Models trained sequentially</li>
                                <li>Each model focuses on previous mistakes</li>
                                <li>Final prediction: weighted combination</li>
                                <li>Reduces bias</li>
                            </ul>
                            <p><strong>Example:</strong> XGBoost</p>
                        </div>
                    </div>
                </div>

                <!-- Wisdom of Crowds Section -->
                <div id="wisdom" class="content-section">
                    <h2>The Wisdom of Crowds Principle</h2>
                    <p>
                        Ensemble methods work because of a fundamental principle: diverse, independent 
                        predictions are often more accurate than any single prediction.
                    </p>

                    <div class="wisdom-crowds">
                        <h4>The Classic Example: Guessing the Weight of a Bull</h4>
                        <p>In 1906, Francis Galton observed 787 people guessing the weight of a bull at a fair:</p>
                        <ul>
                            <li><strong>Individual guesses:</strong> Widely varying, many quite wrong</li>
                            <li><strong>Average of all guesses:</strong> Within 1% of the actual weight!</li>
                            <li><strong>Key insight:</strong> Errors in different directions canceled out</li>
                        </ul>
                    </div>

                    <div class="interactive-ensemble">
                        <h4>Interactive Wisdom of Crowds Demo</h4>
                        <p>Select different types of models to see how diversity affects ensemble performance:</p>
                        
                        <div class="model-selector">
                            <label class="model-checkbox selected" onclick="toggleModelType('linear')">
                                <input type="checkbox" checked>
                                <span>Linear Models</span>
                            </label>
                            <label class="model-checkbox selected" onclick="toggleModelType('tree')">
                                <input type="checkbox" checked>
                                <span>Decision Trees</span>
                            </label>
                            <label class="model-checkbox" onclick="toggleModelType('svm')">
                                <input type="checkbox">
                                <span>SVM</span>
                            </label>
                            <label class="model-checkbox" onclick="toggleModelType('knn')">
                                <input type="checkbox">
                                <span>K-NN</span>
                            </label>
                            <label class="model-checkbox" onclick="toggleModelType('nb')">
                                <input type="checkbox">
                                <span>Naive Bayes</span>
                            </label>
                        </div>
                        
                        <div class="performance-metrics">
                            <div class="metric-card">
                                <div class="metric-value" id="individual-best">0.84</div>
                                <div class="metric-label">Best Individual</div>
                            </div>
                            <div class="metric-card">
                                <div class="metric-value" id="ensemble-perf">0.89</div>
                                <div class="metric-label">Ensemble</div>
                            </div>
                            <div class="metric-card">
                                <div class="metric-value" id="diversity-score">0.73</div>
                                <div class="metric-label">Diversity</div>
                            </div>
                            <div class="metric-card">
                                <div class="metric-value" id="improvement">+6%</div>
                                <div class="metric-label">Improvement</div>
                            </div>
                        </div>
                        
                        <div id="diversity-explanation" style="background: white; padding: 1rem; border-radius: 8px; margin: 1rem 0;">
                            <h5>High Model Diversity</h5>
                            <p>Your selected models make different types of errors, leading to strong ensemble performance!</p>
                        </div>
                    </div>

                    <div class="azbn-card">
                        <h3>Requirements for Ensemble Success</h3>
                        <p>For ensembles to work effectively, you need:</p>
                        
                        <div class="diversity-demo">
                            <div class="diversity-card diversity-high">
                                <h5>Diversity</h5>
                                <p>Models should make different types of mistakes</p>
                                <p><strong>How:</strong> Different algorithms, features, or training data</p>
                            </div>
                            <div class="diversity-card diversity-high">
                                <h5>Individual Competence</h5>
                                <p>Each model should be better than random</p>
                                <p><strong>How:</strong> Proper training and validation</p>
                            </div>
                            <div class="diversity-card diversity-high">
                                <h5>Independence</h5>
                                <p>Models shouldn't all fail the same way</p>
                                <p><strong>How:</strong> Different data samples or approaches</p>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Bagging Section -->
                <div id="bagging" class="content-section">
                    <h2>Bagging: Independent Parallel Models</h2>
                    <p>
                        Bootstrap Aggregating (Bagging) creates diverse models by training each on a different 
                        random sample of the data.
                    </p>

                    <div style="text-align: center; margin: 2rem 0;">
                        <img src="/static/images/tutorials/ml-model-relationships/chapter4/bagging-vs-boosting.png" 
                             alt="Comparison diagram showing bagging (parallel training) versus boosting (sequential training)"
                             style="width: 100%; max-width: 800px; border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15);">
                    </div>

                    <div class="ensemble-demo">
                        <h4>Interactive Bagging Demonstration</h4>
                        <p>Watch how bagging creates diverse models from the same dataset:</p>
                        
                        <div style="margin: 1.5rem 0;">
                            <label for="bootstrap-size">Bootstrap Sample Size (% of original):</label>
                            <input type="range" id="bootstrap-size" min="50" max="100" value="75" oninput="updateBaggingDemo()">
                            <span id="bootstrap-value">75%</span>
                        </div>
                        
                        <div style="margin: 1.5rem 0;">
                            <label for="num-models">Number of Models:</label>
                            <input type="range" id="num-models" min="3" max="20" value="10" oninput="updateBaggingDemo()">
                            <span id="models-value">10</span>
                        </div>
                        
                        <div class="process-flow">
                            <div class="process-step">Original Data<br><small>1000 samples</small></div>
                            <div class="process-arrow">→</div>
                            <div class="process-step">Bootstrap Samples<br><small id="sample-info">10 × 750 samples</small></div>
                            <div class="process-arrow">→</div>
                            <div class="process-step">Train Models<br><small>In Parallel</small></div>
                            <div class="process-arrow">→</div>
                            <div class="process-step">Average Predictions<br><small>Final Result</small></div>
                        </div>
                        
                        <div class="performance-metrics">
                            <div class="metric-card">
                                <div class="metric-value" id="bagging-variance">0.12</div>
                                <div class="metric-label">Variance</div>
                            </div>
                            <div class="metric-card">
                                <div class="metric-value" id="bagging-bias">0.08</div>
                                <div class="metric-label">Bias</div>
                            </div>
                            <div class="metric-card">
                                <div class="metric-value" id="bagging-accuracy">0.87</div>
                                <div class="metric-label">Accuracy</div>
                            </div>
                        </div>
                    </div>

                    <div class="azbn-card">
                        <h3>How Bagging Works</h3>
                        <div class="process-flow">
                            <div class="process-step">1. Bootstrap<br><small>Sample with replacement</small></div>
                            <div class="process-arrow">→</div>
                            <div class="process-step">2. Train<br><small>Independent models</small></div>
                            <div class="process-arrow">→</div>
                            <div class="process-step">3. Aggregate<br><small>Average/Vote</small></div>
                        </div>
                        
                        <h4>Key Benefits:</h4>
                        <ul>
                            <li><strong>Variance Reduction:</strong> Averaging reduces prediction variance</li>
                            <li><strong>Overfitting Control:</strong> Individual overfitting gets averaged out</li>
                            <li><strong>Parallelizable:</strong> Models can be trained simultaneously</li>
                            <li><strong>Robustness:</strong> Less sensitive to outliers</li>
                        </ul>

                        <h4>When Bagging Works Best:</h4>
                        <ul>
                            <li>Base models have <strong>high variance</strong> (like deep decision trees)</li>
                            <li>You have <strong>sufficient data</strong> for multiple samples</li>
                            <li>Models can be trained <strong>independently</strong></li>
                            <li>You want to <strong>reduce overfitting</strong></li>
                        </ul>
                    </div>
                </div>

                <!-- Boosting Section -->
                <div id="boosting" class="content-section">
                    <h2>Boosting: Sequential Error Correction</h2>
                    <p>
                        Boosting takes a different approach: train models sequentially, with each new model 
                        focusing on the errors made by previous models.
                    </p>

                    <div class="ensemble-demo">
                        <h4>Interactive Boosting Demonstration</h4>
                        <p>Watch how boosting iteratively improves predictions:</p>
                        
                        <div style="margin: 1.5rem 0;">
                            <label for="boosting-rounds">Number of Boosting Rounds:</label>
                            <input type="range" id="boosting-rounds" min="1" max="10" value="1" oninput="updateBoostingDemo()">
                            <span id="rounds-value">1</span>
                        </div>
                        
                        <div id="boosting-sequence" style="margin: 2rem 0;">
                            <!-- Dynamic content will be inserted here -->
                        </div>
                        
                        <div class="performance-metrics">
                            <div class="metric-card">
                                <div class="metric-value" id="boosting-error">0.15</div>
                                <div class="metric-label">Training Error</div>
                            </div>
                            <div class="metric-card">
                                <div class="metric-value" id="boosting-bias">0.12</div>
                                <div class="metric-label">Bias</div>
                            </div>
                            <div class="metric-card">
                                <div class="metric-value" id="boosting-accuracy">0.85</div>
                                <div class="metric-label">Accuracy</div>
                            </div>
                        </div>
                    </div>

                    <div class="azbn-card">
                        <h3>Bagging vs Boosting: The Key Differences</h3>
                        
                        <div class="bagging-boosting-comparison">
                            <div class="method-card bagging-card">
                                <h4>Bagging Characteristics</h4>
                                <ul>
                                    <li><strong>Training:</strong> Parallel/Independent</li>
                                    <li><strong>Focus:</strong> Reduce variance</li>
                                    <li><strong>Base Models:</strong> Often complex (high variance)</li>
                                    <li><strong>Combination:</strong> Simple average/majority vote</li>
                                    <li><strong>Overfitting Risk:</strong> Lower</li>
                                    <li><strong>Speed:</strong> Can parallelize</li>
                                </ul>
                            </div>
                            
                            <div class="method-card boosting-card">
                                <h4>Boosting Characteristics</h4>
                                <ul>
                                    <li><strong>Training:</strong> Sequential/Adaptive</li>
                                    <li><strong>Focus:</strong> Reduce bias</li>
                                    <li><strong>Base Models:</strong> Often simple (high bias)</li>
                                    <li><strong>Combination:</strong> Weighted combination</li>
                                    <li><strong>Overfitting Risk:</strong> Higher (but powerful)</li>
                                    <li><strong>Speed:</strong> Sequential (slower)</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div class="wisdom-crowds">
                        <h4>Which Should You Choose?</h4>
                        <ul>
                            <li><strong>Choose Bagging when:</strong> Base models overfit, you want stability, you can parallelize</li>
                            <li><strong>Choose Boosting when:</strong> Base models underfit, you want maximum accuracy, you're willing to tune carefully</li>
                            <li><strong>In practice:</strong> Random Forest (bagging) for quick, robust results; XGBoost (boosting) for competitions and maximum performance</li>
                        </ul>
                    </div>
                </div>

                <!-- Quiz Section -->
                <div id="quiz" class="content-section">
                    <h2>Chapter 4 Quiz</h2>
                    <p>Test your understanding of ensemble methods:</p>

                    <div class="enhanced-quiz-container" data-quiz-id="chapter4-quiz1">
                        <div class="enhanced-quiz-question">
                            <h4>Question 1: What is the main difference between bagging and boosting?</h4>
                        </div>
                        <div class="enhanced-quiz-option" data-correct="true">Bagging trains models in parallel, boosting trains sequentially</div>
                        <div class="enhanced-quiz-option" data-correct="false">Bagging is more accurate than boosting</div>
                        <div class="enhanced-quiz-option" data-correct="false">Boosting always uses decision trees</div>
                        <div class="enhanced-quiz-option" data-correct="false">Bagging requires more data than boosting</div>
                        <div class="enhanced-quiz-explanation">
                            <strong>Correct!</strong> This is the fundamental difference: bagging creates independent models simultaneously, while boosting builds models sequentially where each new model learns from the mistakes of previous ones.
                        </div>
                     </div>
                     
                     <div class="enhanced-quiz-container" data-quiz-id="chapter4-quiz2">
                        <div class="enhanced-quiz-question">
                            <h4>Question 2: Why do ensemble methods often outperform single models?</h4>
                        </div>
                        <div class="enhanced-quiz-option" data-correct="false">They always use more data</div>
                        <div class="enhanced-quiz-option" data-correct="true">Different models make different errors that can cancel out when combined</div>
                        <div class="enhanced-quiz-option" data-correct="false">They are faster to train</div>
                        <div class="enhanced-quiz-option" data-correct="false">They require less feature engineering</div>
                        <div class="enhanced-quiz-explanation">
                            <strong>Exactly!</strong> The wisdom of crowds principle: when diverse models make different types of errors, combining their predictions can cancel out individual mistakes, leading to more accurate overall predictions.
                        </div>
                     </div>
                     
                     <div class="enhanced-quiz-container" data-quiz-id="chapter4-quiz3">
                        <div class="enhanced-quiz-question">
                            <h4>Question 3: When would you prefer bagging over boosting?</h4>
                        </div>
                        <div class="enhanced-quiz-option" data-correct="false">When you need the highest possible accuracy</div>
                        <div class="enhanced-quiz-option" data-correct="true">When you have high-variance base models and want stability</div>
                        <div class="enhanced-quiz-option" data-correct="false">When you have very simple base models</div>
                        <div class="enhanced-quiz-option" data-correct="false">When interpretability is most important</div>
                        <div class="enhanced-quiz-explanation">
                            <strong>Perfect!</strong> Bagging is ideal for high-variance models (like deep decision trees) because averaging their predictions reduces variance and creates more stable, robust predictions.
                        </div>
                     </div>
                </div>
            </div>
        </section>
    </main>
</body>
</html>