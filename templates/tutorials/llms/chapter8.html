<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 8: LLM Applications & Best Practices - Large Language Models (LLMs)</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/llms/llms.css') }}">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWAT2dVgYnHwpIK/NS" crossorigin="anonymous">
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>


</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav">
            <div class="azbn-container">
                <a href="/tutorials/llms" class="course-link">
                    <span>Large Language Models (LLMs)</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <div class="tutorial-header">
            <div class="azbn-container">
                <h1 class="chapter-title">Chapter 8: LLM Applications & Best Practices</h1>
                <p class="chapter-subtitle">Production Deployment</p>
                
                <div class="chapter-progress">
                    <div class="chapter-progress-fill" data-progress="100"></div>
                </div>
                
                <div class="chapter-navigation">
                    <a href="/tutorials/llms/chapter1" class="chapter-nav-btn ">Chapter 1</a>
                    <a href="/tutorials/llms/chapter2" class="chapter-nav-btn ">Chapter 2</a>
                    <a href="/tutorials/llms/chapter3" class="chapter-nav-btn ">Chapter 3</a>
                    <a href="/tutorials/llms/chapter4" class="chapter-nav-btn ">Chapter 4</a>
                    <a href="/tutorials/llms/chapter5" class="chapter-nav-btn ">Chapter 5</a>
                    <a href="/tutorials/llms/chapter6" class="chapter-nav-btn ">Chapter 6</a>
                    <a href="/tutorials/llms/chapter7" class="chapter-nav-btn ">Chapter 7</a>
                    <a href="/tutorials/llms/chapter8" class="chapter-nav-btn active">Chapter 8</a>
                </div>
                
                <div class="section-progress">
                    <div class="section-progress-fill" data-progress="14.3"></div>
                </div>
                
                <div class="section-nav">
                    <button class="section-nav-btn azbn-btn active" data-section="overview">Overview</button>
                    <button class="section-nav-btn azbn-btn" data-section="concepts">Key Concepts</button>
                    <button class="section-nav-btn azbn-btn" data-section="formulas">Formulas</button>
                    <button class="section-nav-btn azbn-btn" data-section="examples">Examples</button>
                    <button class="section-nav-btn azbn-btn" data-section="implementation">Implementation</button>
                    <button class="section-nav-btn azbn-btn" data-section="applications">Applications</button>
                    <button class="section-nav-btn azbn-btn" data-section="quiz">Quiz</button>
                </div>
            </div>
        </div>

        <section class="azbn-section">
            <div class="azbn-container">
                <div class="learning-objectives-box">
                    <h2>Learning Objectives</h2>
                    <ul>
                        <li>Understand llm applications & best practices fundamentals</li>
                        <li>Master the mathematical foundations</li>
                        <li>Learn practical implementation</li>
                        <li>Apply knowledge through examples</li>
                        <li>Recognize real-world applications</li>
                    </ul>
                </div>

                <main class="chapter-main-content">
                    <div id="overview" class="content-section active">
                        <h2>LLM Applications & Best Practices</h2>
                        
                        <div class="explanation-box">
                            <h3>Introduction</h3>
                            <p><strong>Production Deployment</strong></p>
                            <p>This chapter provides comprehensive coverage of llm applications & best practices, including detailed explanations, mathematical formulations, code implementations, and real-world examples.</p>
                        </div>

                        <div class="example-box">
                            <h4>üìö Why This Matters</h4>
                            <p>Understanding llm applications & best practices is crucial for mastering modern AI systems. This chapter breaks down complex concepts into digestible explanations with step-by-step examples.</p>
                        </div>
                    </div>

                    <div id="concepts" class="content-section">
                        <h2>Key Concepts</h2>
                        
                        <div class="explanation-box">
                            <h3>LLM Application Patterns</h3>
                            <p><strong>Direct generation:</strong> Model generates output directly from prompt. Used for creative writing, code generation, summarization.</p>
                            
                            <p><strong>Classification:</strong> Model outputs class label. Used for sentiment analysis, content moderation, spam detection.</p>
                            
                            <p><strong>Extraction:</strong> Model extracts structured information. Used for named entity recognition, data extraction, question answering.</p>
                            
                            <p><strong>Transformation:</strong> Model transforms input format. Used for translation, reformatting, style transfer.</p>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Best Practices for LLM Applications</h3>
                            <p><strong>Prompt design:</strong> Clear, specific, well-structured prompts significantly improve results.</p>
                            
                            <p><strong>Error handling:</strong> LLMs can fail or produce unexpected outputs. Implement validation, retries, and fallbacks.</p>
                            
                            <p><strong>Cost optimization:</strong> Use smaller models when possible, cache responses, batch requests, use efficient sampling.</p>
                            
                            <p><strong>Safety and monitoring:</strong> Filter harmful content, monitor for bias, track usage and costs, implement rate limiting.</p>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Deployment Considerations</h3>
                            <p><strong>Latency:</strong> Large models are slow. Consider model size, batching, caching, and optimization techniques.</p>
                            
                            <p><strong>Cost:</strong> API costs scale with usage. Monitor token usage, optimize prompts, consider fine-tuning for efficiency.</p>
                            
                            <p><strong>Reliability:</strong> Implement retries, fallbacks, and error handling. LLMs can be non-deterministic.</p>
                        </div>
                    </div>

                    <div id="formulas" class="content-section">
                        <h2>Mathematical Formulations</h2>
                        
                        <div class="formula-box">
                            <h4>Token Cost Calculation</h4>
                            <div class="formula-display">
                                \[\text{Cost} = (\text{input\_tokens} + \text{output\_tokens}) \times \text{price\_per\_token}\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>Input tokens: Prompt length</li>
                                    <li>Output tokens: Generated text length</li>
                                    <li>Price varies by model (GPT-4 more expensive than GPT-3.5)</li>
                                    <li>Optimize by reducing prompt size and output length</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Temperature Sampling</h4>
                            <div class="formula-display">
                                \[P_{\text{temp}}(x_i) = \frac{\exp(\logits_i / T)}{\sum_j \exp(\logits_j / T)}\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(T\): Temperature parameter</li>
                                    <li>\(T < 1\): Sharper distribution (more deterministic)</li>
                                    <li>\(T > 1\): Flatter distribution (more random)</li>
                                    <li>\(T = 1\): Standard softmax</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Top-k Sampling</h4>
                            <div class="formula-display">
                                \[P_{\text{top-k}}(x_i) = \begin{cases} 
                                \frac{\exp(\logits_i)}{\sum_{j \in \text{top-k}} \exp(\logits_j)} & \text{if } i \in \text{top-k} \\
                                0 & \text{otherwise}
                                \end{cases}\]
                            </div>
                            <div class="formula-explanation">
                                <p>Only consider top k tokens by probability. Filters out low-probability tokens to improve quality while maintaining diversity.</p>
                            </div>
                        </div>
                    </div>

                    <div id="examples" class="content-section">
                        <h2>Detailed Examples</h2>
                        
                        <div class="example-box">
                            <h4>Example: Building a Chatbot</h4>
                            <p><strong>Step 1: Define system prompt</strong></p>
                            <pre style="background: #f5f5f5; padding: 1rem; border-radius: 5px;">
You are a helpful assistant. Be concise, friendly, and accurate.</pre>
                            
                            <p><strong>Step 2: Handle conversation</strong></p>
                            <ul>
                                <li>Maintain conversation history</li>
                                <li>Format: [system] + [history] + [user message]</li>
                                <li>Generate response</li>
                                <li>Update history</li>
                            </ul>
                            
                            <p><strong>Step 3: Add safety checks</strong></p>
                            <ul>
                                <li>Filter harmful content</li>
                                <li>Validate responses</li>
                                <li>Implement rate limiting</li>
                            </ul>
                        </div>
                        
                        <div class="example-box">
                            <h4>Example: Cost Optimization</h4>
                            <p><strong>Scenario:</strong> Processing 10,000 documents</p>
                            
                            <p><strong>Without optimization:</strong></p>
                            <ul>
                                <li>Average prompt: 500 tokens</li>
                                <li>Average output: 200 tokens</li>
                                <li>Cost: 10,000 √ó 700 √ó $0.002 = $14,000</li>
                            </ul>
                            
                            <p><strong>With optimization:</strong></p>
                            <ul>
                                <li>Reduce prompt to 200 tokens (remove unnecessary context)</li>
                                <li>Limit output to 100 tokens (use max_tokens)</li>
                                <li>Cost: 10,000 √ó 300 √ó $0.002 = $6,000 (57% reduction!)</li>
                            </ul>
                        </div>
                    </div>

                    <div id="implementation" class="content-section">
                        <h2>Implementation</h2>
                        
                        <div class="code-box">
                            <h4>LLM Application with Error Handling</h4>
                            <pre><code class="language-python">from transformers import pipeline
import time
from typing import Optional

class LLMApplication:
    """LLM application with error handling and retries"""
    
    def __init__(self, model_name="gpt2", max_retries=3):
        self.generator = pipeline("text-generation", model=model_name)
        self.max_retries = max_retries
    
    def generate_with_retry(self, prompt: str, max_length: int = 100) -> Optional[str]:
        """Generate text with retry logic"""
        for attempt in range(self.max_retries):
            try:
                result = self.generator(
                    prompt,
                    max_length=max_length,
                    num_return_sequences=1,
                    temperature=0.7,
                    do_sample=True
                )
                return result[0]['generated_text']
            except Exception as e:
                print(f"Attempt {attempt + 1} failed: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(2 ** attempt)  # Exponential backoff
                else:
                    return None
        return None
    
    def validate_output(self, output: str) -> bool:
        """Validate generated output"""
        # Add validation logic
        if len(output) < 10:
            return False
        if any(word in output.lower() for word in ["error", "invalid"]):
            return False
        return True

# Example usage
app = LLMApplication()
result = app.generate_with_retry("The capital of France is")
if result and app.validate_output(result):
    print(result)</code></pre>
                        </div>
                        
                        <div class="code-box">
                            <h4>Cost Tracking</h4>
                            <pre><code class="language-python">class CostTracker:
    """Track token usage and costs"""
    
    def __init__(self, price_per_1k_tokens=0.002):
        self.price_per_1k = price_per_1k_tokens
        self.total_input_tokens = 0
        self.total_output_tokens = 0
    
    def record_usage(self, input_tokens: int, output_tokens: int):
        """Record token usage"""
        self.total_input_tokens += input_tokens
        self.total_output_tokens += output_tokens
    
    def get_cost(self) -> float:
        """Calculate total cost"""
        total_tokens = self.total_input_tokens + self.total_output_tokens
        return (total_tokens / 1000) * self.price_per_1k
    
    def get_stats(self) -> dict:
        """Get usage statistics"""
        return {
            "input_tokens": self.total_input_tokens,
            "output_tokens": self.total_output_tokens,
            "total_tokens": self.total_input_tokens + self.total_output_tokens,
            "cost": self.get_cost()
        }

# Example
tracker = CostTracker()
tracker.record_usage(500, 200)
print(tracker.get_stats())</code></pre>
                        </div>
                    </div>

                    <div id="applications" class="content-section">
                        <h2>Real-World Applications</h2>
                        
                        <div class="explanation-box">
                            <h3>Major LLM Applications</h3>
                            <p><strong>Content Creation:</strong></p>
                            <ul>
                                <li>Writing assistance (Grammarly, Jasper)</li>
                                <li>Marketing copy generation</li>
                                <li>Blog post and article writing</li>
                                <li>Social media content</li>
                            </ul>
                            
                            <p><strong>Customer Service:</strong></p>
                            <ul>
                                <li>Chatbots for support</li>
                                <li>Email response generation</li>
                                <li>FAQ automation</li>
                                <li>Ticket classification and routing</li>
                            </ul>
                            
                            <p><strong>Software Development:</strong></p>
                            <ul>
                                <li>Code completion (GitHub Copilot)</li>
                                <li>Code generation from descriptions</li>
                                <li>Documentation generation</li>
                                <li>Code review and debugging assistance</li>
                            </ul>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Best Practices Summary</h3>
                            <p><strong>Design:</strong> Clear prompts, proper formatting, relevant examples</p>
                            <p><strong>Performance:</strong> Optimize prompts, use appropriate models, implement caching</p>
                            <p><strong>Reliability:</strong> Error handling, validation, retries, fallbacks</p>
                            <p><strong>Safety:</strong> Content filtering, bias monitoring, rate limiting</p>
                            <p><strong>Cost:</strong> Monitor usage, optimize prompts, choose right model size</p>
                        </div>
                    </div>

                    <div id="quiz" class="content-section">
                        <h2>Test Your Understanding</h2>
                        
                        <div class="quiz-container">
                            <div class="quiz-question">
                                <h3>Question 1: What is the main concept covered in this chapter?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) LLM Applications & Best Practices</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Related concept</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Different topic</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Unrelated topic</div>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </section>
    </main>

    <footer style="background: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 2px solid #5B7553;">
        <div class="azbn-container" style="text-align: center;">
            <button onclick="scrollToSectionNav()" class="azbn-btn" style="margin: 0.5rem;">
                ‚Üë Back to Section Navigation
            </button>
            <div style="margin-top: 1.5rem;">
                <a href="/tutorials/llms" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Back to Tutorial</a>
                <a href="/tutorials/llms/chapter7" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Chapter 7</a>
                
            </div>
        </div>
    </footer>
    
        <!-- KaTeX for math rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlG8jLC0KXLSyHiQtD6lqG3t3a3H4RbQT6GhhDYFyK4aQo5hk6g/AVC/gw" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script src="{{ url_for('static', filename='js/tutorials/llms/shared-tutorial.js') }}"></script>
    <script>
        function scrollToSectionNav() {
            const sectionNav = document.querySelector('.section-nav');
            if (sectionNav) {
                sectionNav.scrollIntoView({ behavior: 'smooth', block: 'start' });
            }
        }
        
        function checkAnswer(element, isCorrect) {
            element.parentNode.querySelectorAll('.quiz-option').forEach(opt => {
                opt.classList.remove('correct', 'incorrect');
            });
            if (isCorrect) {
                element.classList.add('correct');
                element.textContent += ' ‚úì Correct!';
            } else {
                element.classList.add('incorrect');
                element.textContent += ' ‚úó Incorrect';
                const correctOption = Array.from(element.parentNode.querySelectorAll('.quiz-option'))
                    .find(opt => {
                        const onclick = opt.getAttribute('onclick') || '';
                        return onclick.includes('true');
                    });
                if (correctOption && !correctOption.classList.contains('incorrect')) {
                    correctOption.classList.add('correct');
                    correctOption.textContent += ' ‚úì Correct Answer';
                }
            }
        }
            
        // Initialize KaTeX rendering
        document.addEventListener("DOMContentLoaded", function() {
            if (typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "\[", right: "\]", display: true},
                        {left: "$", right: "$", display: false},
                        {left: "\(", right: "\)", display: false}
                    ],
                    throwOnError: false
                });
            }
            
            // Initialize Prism.js syntax highlighting
            if (typeof Prism !== 'undefined') {
                Prism.highlightAll();
            }
        });
    </script>
</body>
</html>