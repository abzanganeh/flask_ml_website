<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 5: Fine-tuning Strategies - Large Language Models (LLMs)</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/llms/llms.css') }}">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>


</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav">
            <div class="azbn-container">
                <a href="/tutorials/llms" class="course-link">
                    <span>Large Language Models (LLMs)</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <div class="tutorial-header">
            <div class="azbn-container">
                <h1 class="chapter-title">Chapter 5: Fine-tuning Strategies</h1>
                <p class="chapter-subtitle">Adapting Pre-trained Models</p>
                
                <div class="chapter-progress">
                    <div class="chapter-progress-fill" data-progress="62"></div>
                </div>
                
                <div class="chapter-navigation">
                    <a href="/tutorials/llms/chapter1" class="chapter-nav-btn ">Chapter 1</a>
                    <a href="/tutorials/llms/chapter2" class="chapter-nav-btn ">Chapter 2</a>
                    <a href="/tutorials/llms/chapter3" class="chapter-nav-btn ">Chapter 3</a>
                    <a href="/tutorials/llms/chapter4" class="chapter-nav-btn ">Chapter 4</a>
                    <a href="/tutorials/llms/chapter5" class="chapter-nav-btn active">Chapter 5</a>
                    <a href="/tutorials/llms/chapter6" class="chapter-nav-btn ">Chapter 6</a>
                    <a href="/tutorials/llms/chapter7" class="chapter-nav-btn ">Chapter 7</a>
                    <a href="/tutorials/llms/chapter8" class="chapter-nav-btn ">Chapter 8</a>
                </div>
                
                <div class="section-progress">
                    <div class="section-progress-fill" data-progress="14.3"></div>
                </div>
                
                <div class="section-nav">
                    <button class="section-nav-btn azbn-btn active" data-section="overview">Overview</button>
                    <button class="section-nav-btn azbn-btn" data-section="concepts">Key Concepts</button>
                    <button class="section-nav-btn azbn-btn" data-section="formulas">Formulas</button>
                    <button class="section-nav-btn azbn-btn" data-section="examples">Examples</button>
                    <button class="section-nav-btn azbn-btn" data-section="implementation">Implementation</button>
                    <button class="section-nav-btn azbn-btn" data-section="applications">Applications</button>
                    <button class="section-nav-btn azbn-btn" data-section="quiz">Quiz</button>
                </div>
            </div>
        </div>

        <section class="azbn-section">
            <div class="azbn-container">
                <div class="learning-objectives-box">
                    <h2>Learning Objectives</h2>
                    <ul>
                        <li>Understand fine-tuning strategies fundamentals</li>
                        <li>Master the mathematical foundations</li>
                        <li>Learn practical implementation</li>
                        <li>Apply knowledge through examples</li>
                        <li>Recognize real-world applications</li>
                    </ul>
                </div>

                <main class="chapter-main-content">
                    <div id="overview" class="content-section active">
                        <h2>Fine-tuning Strategies</h2>
                        
                        <div class="explanation-box">
                            <h3>Introduction</h3>
                            <p><strong>Adapting Pre-trained Models</strong></p>
                            <p>This chapter provides comprehensive coverage of fine-tuning strategies, including detailed explanations, mathematical formulations, code implementations, and real-world examples.</p>
                        </div>

                        <div class="example-box">
                            <h4>üìö Why This Matters</h4>
                            <p>Understanding fine-tuning strategies is crucial for mastering modern AI systems. This chapter breaks down complex concepts into digestible explanations with step-by-step examples.</p>
                        </div>
                    </div>

                    <div id="concepts" class="content-section">
                        <h2>Key Concepts</h2>
                        
                        <div class="explanation-box">
                            <h3>Fine-tuning Strategies</h3>
                            <p><strong>Full fine-tuning:</strong> Update all model parameters. Most powerful but requires most memory and compute.</p>
                            
                            <p><strong>Partial fine-tuning:</strong> Freeze early layers, only train later layers. Reduces memory requirements while maintaining most performance.</p>
                            
                            <p><strong>Parameter-efficient fine-tuning:</strong> Only train small subset of parameters (LoRA, adapters, prompt tuning). Very efficient, can run on single GPU.</p>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Instruction Tuning</h3>
                            <p><strong>What it is:</strong> Fine-tuning on diverse tasks formatted as instructions. Teaches model to follow instructions and generalize to new tasks.</p>
                            
                            <p><strong>Example format:</strong></p>
                            <ul>
                                <li>Input: "Translate to French: Hello"</li>
                                <li>Output: "Bonjour"</li>
                            </ul>
                            
                            <p><strong>Benefits:</strong> Model becomes better at following prompts, can handle diverse tasks, shows improved few-shot performance.</p>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Multi-task Fine-tuning</h3>
                            <p><strong>Training on multiple tasks simultaneously:</strong></p>
                            <ul>
                                <li>Combines data from different tasks</li>
                                <li>Model learns to handle diverse scenarios</li>
                                <li>Better generalization than single-task fine-tuning</li>
                                <li>Requires careful task balancing</li>
                            </ul>
                        </div>
                    </div>

                    <div id="formulas" class="content-section">
                        <h2>Mathematical Formulations</h2>
                        
                        <div class="formula-box">
                            <h4>Fine-tuning Objective</h4>
                            <div class="formula-display">
                                \[L_{\text{ft}} = -\frac{1}{N} \sum_{i=1}^{N} \log P(y_i | x_i, \theta_0 + \Delta\theta)\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(\theta_0\): Pre-trained parameters (frozen or partially frozen)</li>
                                    <li>\(\Delta\theta\): Parameter updates (small compared to \(\theta_0\))</li>
                                    <li>\(x_i, y_i\): Task-specific input-output pairs</li>
                                    <li>Much smaller dataset than pre-training</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>LoRA Decomposition</h4>
                            <div class="formula-display">
                                \[W' = W_0 + \Delta W = W_0 + BA\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(W_0\): Original weight matrix (frozen, d√ód)</li>
                                    <li>\(B\): Trainable matrix (d√ór, rank r)</li>
                                    <li>\(A\): Trainable matrix (r√ód)</li>
                                    <li>Only \(2dr\) parameters trained instead of \(d^2\)</li>
                                    <li>Typical: r = 4-16, much smaller than d</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Multi-task Loss</h4>
                            <div class="formula-display">
                                \[L = \sum_{t=1}^{T} \alpha_t L_t\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(T\): Number of tasks</li>
                                    <li>\(L_t\): Loss for task t</li>
                                    <li>\(\alpha_t\): Task weight (balances importance)</li>
                                    <li>Allows training on multiple tasks simultaneously</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div id="examples" class="content-section">
                        <h2>Detailed Examples</h2>
                        
                        <div class="example-box">
                            <h4>Example: Full vs LoRA Fine-tuning</h4>
                            <p><strong>Task:</strong> Fine-tune GPT-2 for sentiment analysis</p>
                            
                            <p><strong>Full fine-tuning:</strong></p>
                            <ul>
                                <li>Trainable parameters: 124M (all GPT-2 parameters)</li>
                                <li>Memory: ~2GB per batch</li>
                                <li>Training time: ~2 hours on GPU</li>
                                <li>Performance: Best possible</li>
                            </ul>
                            
                            <p><strong>LoRA fine-tuning (r=8):</strong></p>
                            <ul>
                                <li>Trainable parameters: ~1M (LoRA matrices only)</li>
                                <li>Memory: ~500MB per batch</li>
                                <li>Training time: ~30 minutes on GPU</li>
                                <li>Performance: ~95% of full fine-tuning</li>
                            </ul>
                        </div>
                        
                        <div class="example-box">
                            <h4>Example: Instruction Tuning</h4>
                            <p><strong>Training examples:</strong></p>
                            <ul>
                                <li>"Translate to French: Hello" ‚Üí "Bonjour"</li>
                                <li>"Summarize: [long text]" ‚Üí "[summary]"</li>
                                <li>"Classify sentiment: Great movie!" ‚Üí "Positive"</li>
                                <li>"Answer: What is AI?" ‚Üí "AI is..."</li>
                            </ul>
                            
                            <p><strong>Result:</strong> Model learns to follow instructions and can generalize to new instruction-formatted tasks.</p>
                        </div>
                    </div>

                    <div id="implementation" class="content-section">
                        <h2>Implementation</h2>
                        
                        <div class="code-box">
                            <h4>Partial Fine-tuning (Freeze Early Layers)</h4>
                            <pre><code class="language-python">from transformers import GPT2ForSequenceClassification, GPT2Tokenizer

# Load model
model = GPT2ForSequenceClassification.from_pretrained("gpt2", num_labels=2)

# Freeze early layers (first 6 out of 12)
for i in range(6):
    for param in model.transformer.h[i].parameters():
        param.requires_grad = False

# Later layers remain trainable
# Only train: layers 6-11 + classification head

# Count trainable parameters
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
total = sum(p.numel() for p in model.parameters())
print(f"Trainable: {trainable}, Total: {total}, Ratio: {trainable/total:.2%}")</code></pre>
                        </div>
                        
                        <div class="code-box">
                            <h4>Instruction Tuning Setup</h4>
                            <pre><code class="language-python"># Instruction tuning data format
instruction_data = [
    {
        "instruction": "Translate to French",
        "input": "Hello",
        "output": "Bonjour"
    },
    {
        "instruction": "Summarize",
        "input": "Long article text...",
        "output": "Summary text..."
    },
    {
        "instruction": "Classify sentiment",
        "input": "Great movie!",
        "output": "Positive"
    }
]

def format_instruction(example):
    """Format instruction for training"""
    prompt = f"{example['instruction']}: {example['input']}"
    target = example['output']
    return prompt, target

# Use with standard language modeling loss
# Model learns to generate target given instruction+input</code></pre>
                        </div>
                    </div>

                    <div id="applications" class="content-section">
                        <h2>Real-World Applications</h2>
                        
                        <div class="explanation-box">
                            <h3>Fine-tuning Applications</h3>
                            <p><strong>Domain-specific models:</strong></p>
                            <ul>
                                <li>Medical LLMs: Fine-tuned on medical literature</li>
                                <li>Legal LLMs: Fine-tuned on legal documents</li>
                                <li>Code models: Fine-tuned on code repositories</li>
                                <li>Customer service: Fine-tuned on support tickets</li>
                            </ul>
                            
                            <p><strong>Task-specific models:</strong></p>
                            <ul>
                                <li>Sentiment analysis for product reviews</li>
                                <li>Named entity recognition for information extraction</li>
                                <li>Question answering for knowledge bases</li>
                                <li>Text classification for content moderation</li>
                            </ul>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Instruction-tuned Models</h3>
                            <p><strong>Models like ChatGPT, Claude use instruction tuning:</strong></p>
                            <ul>
                                <li>Better at following user instructions</li>
                                <li>More helpful and aligned with human intent</li>
                                <li>Can handle diverse tasks without task-specific fine-tuning</li>
                                <li>Show improved safety and reduced harmful outputs</li>
                            </ul>
                        </div>
                    </div>

                    <div id="quiz" class="content-section">
                        <h2>Test Your Understanding</h2>
                        
                        <div class="quiz-container">
                            <div class="quiz-question">
                                <h3>Question 1: What is the main purpose of fine-tuning a pre-trained LLM?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) To adapt the pre-trained model to a specific task or domain by updating its parameters on task-specific data, leveraging the general knowledge learned during pre-training</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) To retrain the model from scratch</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) To reduce the model size</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) To change the model architecture</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 2: What is the difference between full fine-tuning and parameter-efficient fine-tuning?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Full fine-tuning updates all model parameters and requires more resources, while parameter-efficient methods (like LoRA) only train a small subset of parameters, making it more memory and compute efficient</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) They are identical approaches</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Full fine-tuning is faster than parameter-efficient methods</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Parameter-efficient methods require more memory</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 3: Why are lower learning rates typically used for fine-tuning compared to training from scratch?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Pre-trained weights are already good, and high learning rates can destroy this pre-trained knowledge, so smaller updates (1e-5 to 1e-3) preserve the learned representations while adapting to the new task</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Lower learning rates make training faster</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Higher learning rates are always better</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Learning rate doesn't matter for fine-tuning</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 4: What is catastrophic forgetting in the context of fine-tuning?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) The phenomenon where fine-tuning on a new task causes the model to forget what it learned during pre-training, which can be mitigated with lower learning rates, freezing early layers, and regularization</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) A technique to improve fine-tuning performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) A method to reduce model size</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) A type of optimization algorithm</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 5: What is instruction tuning?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Fine-tuning on diverse tasks formatted as instructions, which teaches the model to follow instructions and generalize to new instruction-formatted tasks</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) A method to reduce model parameters</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) A technique for generating instructions</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) A way to speed up training</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 6: What is the mathematical formulation for fine-tuning loss?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) \(L_{\text{ft}} = -\frac{1}{N} \sum_{i=1}^{N} \log P(y_i | x_i, \theta_0 + \Delta\theta)\) where \(\theta_0\) are pre-trained parameters and \(\Delta\theta\) are small updates</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) \(L = \sum_{i=1}^{N} y_i\)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) \(L = \max_i P(y_i | x_i)\)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) \(L = \frac{1}{N} \sum_{i=1}^{N} x_i\)</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 7: What is multi-task fine-tuning?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Training on multiple tasks simultaneously by combining data from different tasks, which helps the model learn to handle diverse scenarios and improves generalization</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Training on one task at a time sequentially</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Using multiple models for one task</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) A method to reduce training time</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 8: When should you use fine-tuning versus prompting?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Use fine-tuning when you have task-specific labeled data and need high performance on a specific domain, while use prompting when you have limited data and need quick iteration</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Always use fine-tuning, never prompting</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Always use prompting, never fine-tuning</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) They are interchangeable</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 9: What is partial fine-tuning?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Freezing early layers and only training later layers plus the task-specific head, which reduces memory requirements while maintaining most performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Training only the first layer</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Training only the output layer</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Training with partial data</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 10: What are some common fine-tuning use cases?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Domain-specific applications (medical, legal, code), task-specific models (sentiment analysis, NER, QA), and instruction-tuned models for better instruction following</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only image classification</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only speech recognition</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Only data preprocessing</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 11: What is the learning rate schedule formula used in fine-tuning?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Warmup phase gradually increases learning rate, then linear decay: \(\text{lr}(t) = \text{lr}_{\text{max}} \times \frac{t}{T_{\text{warmup}}}\) for warmup, then linear decay afterward</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Constant learning rate throughout</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Exponential increase</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Random learning rate</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 12: What is the multi-task loss formulation?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) \(L = \sum_{t=1}^{T} \alpha_t L_t\) where \(T\) is the number of tasks, \(L_t\) is the loss for task t, and \(\alpha_t\) is the task weight</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) \(L = \max_t L_t\)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) \(L = \frac{1}{T} \sum_{t=1}^{T} L_t\) (equal weights only)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) \(L = \prod_{t=1}^{T} L_t\)</div>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </section>
    </main>

    <footer style="background: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 2px solid #5B7553;">
        <div class="azbn-container" style="text-align: center;">
            <button onclick="scrollToSectionNav()" class="azbn-btn" style="margin: 0.5rem;">
                ‚Üë Back to Section Navigation
            </button>
            <div style="margin-top: 1.5rem;">
                <a href="/tutorials/llms" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Back to Tutorial</a>
                <a href="/tutorials/llms/chapter4" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Chapter 4</a>
                <a href="/tutorials/llms/chapter6" class="azbn-btn" style="text-decoration: none; margin: 0.5rem;">Chapter 6 ‚Üí</a>
            </div>
        </div>
    </footer>
    
        <!-- KaTeX for math rendering -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
<script src="{{ url_for('static', filename='js/tutorials/llms/shared-tutorial.js') }}"></script>
    <script>
        function scrollToSectionNav() {
            const sectionNav = document.querySelector('.section-nav');
            if (sectionNav) {
                sectionNav.scrollIntoView({ behavior: 'smooth', block: 'start' });
            }
        }
        
        function checkAnswer(element, isCorrect) {
            element.parentNode.querySelectorAll('.quiz-option').forEach(opt => {
                opt.classList.remove('correct', 'incorrect');
            });
            if (isCorrect) {
                element.classList.add('correct');
                element.textContent += ' ‚úì Correct!';
            } else {
                element.classList.add('incorrect');
                element.textContent += ' ‚úó Incorrect';
                const correctOption = Array.from(element.parentNode.querySelectorAll('.quiz-option'))
                    .find(opt => {
                        const onclick = opt.getAttribute('onclick') || '';
                        return onclick.includes('true');
                    });
                if (correctOption && !correctOption.classList.contains('incorrect')) {
                    correctOption.classList.add('correct');
                    correctOption.textContent += ' ‚úì Correct Answer';
                }
            }
        }
            
// Initialize KaTeX rendering - ensure KaTeX is loaded first
        function initKaTeX() {
            if (typeof katex !== 'undefined' && typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "\\[", right: "\\]", display: true},
                        {left: "$", right: "$", display: false},
                        {left: "\\(", right: "\\)", display: false}
                    ],
                    throwOnError: false
                });
            } else {
                // Retry if KaTeX not loaded yet
                setTimeout(initKaTeX, 100);
                return;
            }
            
            // Initialize Prism.js syntax highlighting
            if (typeof Prism !== 'undefined') {
                Prism.highlightAll();
            }
        }
        
        // Wait for DOM and KaTeX to be ready
        if (document.readyState === 'loading') {
            document.addEventListener("DOMContentLoaded", initKaTeX);
        } else {
            // DOM already loaded, wait for KaTeX
            initKaTeX();
