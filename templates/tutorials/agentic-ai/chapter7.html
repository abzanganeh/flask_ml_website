<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 7: Agent Evaluation & Monitoring - Agentic AI & LLM Agents</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/agentic-ai/agentic-ai.css') }}">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>


</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav">
            <div class="azbn-container">
                <a href="/tutorials/agentic-ai" class="course-link">
                    <span>Agentic AI & LLM Agents</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <div class="tutorial-header">
            <div class="azbn-container">
                <h1 class="chapter-title">Chapter 7: Agent Evaluation & Monitoring</h1>
                <p class="chapter-subtitle">Measuring Performance</p>
                
                <div class="chapter-progress">
                    <div class="chapter-progress-fill" data-progress="87"></div>
                </div>
                
                <div class="chapter-navigation">
                    <a href="/tutorials/agentic-ai/chapter1" class="chapter-nav-btn ">Chapter 1</a>
                    <a href="/tutorials/agentic-ai/chapter2" class="chapter-nav-btn ">Chapter 2</a>
                    <a href="/tutorials/agentic-ai/chapter3" class="chapter-nav-btn ">Chapter 3</a>
                    <a href="/tutorials/agentic-ai/chapter4" class="chapter-nav-btn ">Chapter 4</a>
                    <a href="/tutorials/agentic-ai/chapter5" class="chapter-nav-btn ">Chapter 5</a>
                    <a href="/tutorials/agentic-ai/chapter6" class="chapter-nav-btn ">Chapter 6</a>
                    <a href="/tutorials/agentic-ai/chapter7" class="chapter-nav-btn active">Chapter 7</a>
                    <a href="/tutorials/agentic-ai/chapter8" class="chapter-nav-btn ">Chapter 8</a>
                </div>
                
                <div class="section-progress">
                    <div class="section-progress-fill" data-progress="14.3"></div>
                </div>
                
                <div class="section-nav">
                    <button class="section-nav-btn azbn-btn active" data-section="overview">Overview</button>
                    <button class="section-nav-btn azbn-btn" data-section="concepts">Key Concepts</button>
                    <button class="section-nav-btn azbn-btn" data-section="formulas">Formulas</button>
                    <button class="section-nav-btn azbn-btn" data-section="examples">Examples</button>
                    <button class="section-nav-btn azbn-btn" data-section="implementation">Implementation</button>
                    <button class="section-nav-btn azbn-btn" data-section="applications">Applications</button>
                    <button class="section-nav-btn azbn-btn" data-section="quiz">Quiz</button>
                </div>
            </div>
        </div>

        <section class="azbn-section">
            <div class="azbn-container">
                <div class="learning-objectives-box">
                    <h2>Learning Objectives</h2>
                    <ul>
                        <li>Understand agent evaluation & monitoring fundamentals</li>
                        <li>Master the mathematical foundations</li>
                        <li>Learn practical implementation</li>
                        <li>Apply knowledge through examples</li>
                        <li>Recognize real-world applications</li>
                    </ul>
                </div>

                <main class="chapter-main-content">
                    <div id="overview" class="content-section active">
                        <h2>Agent Evaluation & Monitoring</h2>
                        
                        <div class="explanation-box">
                            <h3>Introduction</h3>
                            <p><strong>Measuring Performance</strong></p>
                            <p>This chapter provides comprehensive coverage of agent evaluation & monitoring, including detailed explanations, mathematical formulations, code implementations, and real-world examples.</p>
                        </div>

                        <div class="example-box">
                            <h4>üìö Why This Matters</h4>
                            <p>Understanding agent evaluation & monitoring is crucial for mastering modern AI systems. This chapter breaks down complex concepts into digestible explanations with step-by-step examples.</p>
                        </div>
                    </div>

                    <div id="concepts" class="content-section">
                        <h2>Key Concepts</h2>
                        
                        <div class="explanation-box">
                            <h3>Agent Evaluation Metrics</h3>
                            <p><strong>Task success rate:</strong> Percentage of tasks completed successfully</p>
                            
                            <p><strong>Response quality:</strong></p>
                            <ul>
                                <li>Accuracy: Correctness of agent outputs</li>
                                <li>Relevance: How well output addresses task</li>
                                <li>Completeness: Whether all requirements met</li>
                            </ul>
                            
                            <p><strong>Efficiency metrics:</strong></p>
                            <ul>
                                <li>Latency: Time to complete task</li>
                                <li>Token usage: Cost per task</li>
                                <li>Tool calls: Number of tool invocations</li>
                            </ul>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Monitoring Agent Behavior</h3>
                            <p><strong>What to monitor:</strong></p>
                            <ul>
                                <li>Decision patterns: What actions agent chooses</li>
                                <li>Tool usage: Which tools are used most</li>
                                <li>Error rates: Frequency and types of errors</li>
                                <li>Loop detection: Infinite loops or repetitive behavior</li>
                                <li>Cost tracking: API calls and token usage</li>
                            </ul>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Evaluation Strategies</h3>
                            <p><strong>Automated evaluation:</strong> Use LLMs or rule-based systems to score agent outputs</p>
                            <p><strong>Human evaluation:</strong> Human reviewers assess quality (gold standard but expensive)</p>
                            <p><strong>Hybrid evaluation:</strong> Combine automated and human evaluation</p>
                            <p><strong>A/B testing:</strong> Compare different agent configurations</p>
                        </div>
                    </div>

                    <div id="formulas" class="content-section">
                        <h2>Mathematical Formulations</h2>
                        
                        <div class="formula-box">
                            <h4>Task Success Rate</h4>
                            <div class="formula-display">
                                \[\text{Success Rate} = \frac{\text{Successful Tasks}}{\text{Total Tasks}} \times 100\%\]
                            </div>
                            <div class="formula-explanation">
                                <p>Measures overall agent reliability. Higher is better.</p>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Average Task Latency</h4>
                            <div class="formula-display">
                                \[\text{Avg Latency} = \frac{1}{N} \sum_{i=1}^{N} T_i\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(N\): Number of tasks</li>
                                    <li>\(T_i\): Time to complete task i</li>
                                    <li>Lower latency is better</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Cost per Task</h4>
                            <div class="formula-display">
                                \[\text{Cost} = \sum_{i=1}^{M} (\text{tokens}_i \times \text{price\_per\_token}_i)\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(M\): Number of API calls</li>
                                    <li>\(\text{tokens}_i\): Tokens used in call i</li>
                                    <li>Track total cost for optimization</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div id="examples" class="content-section">
                        <h2>Detailed Examples</h2>
                        
                        <div class="example-box">
                            <h4>Example: Evaluating Agent Performance</h4>
                            <p><strong>Test set:</strong> 100 tasks</p>
                            
                            <p><strong>Results:</strong></p>
                            <ul>
                                <li>Successful: 85 tasks</li>
                                <li>Failed: 10 tasks</li>
                                <li>Timeout: 5 tasks</li>
                            </ul>
                            
                            <p><strong>Metrics:</strong></p>
                            <ul>
                                <li>Success rate: 85%</li>
                                <li>Average latency: 3.2 seconds</li>
                                <li>Average cost: $0.05 per task</li>
                            </ul>
                            
                            <p><strong>Analysis:</strong> Agent performs well but has room for improvement in failure handling.</p>
                        </div>
                        
                        <div class="example-box">
                            <h4>Example: Monitoring Agent Behavior</h4>
                            <p><strong>Observed patterns:</strong></p>
                            <ul>
                                <li>Agent uses search tool 60% of the time</li>
                                <li>Average 3 tool calls per task</li>
                                <li>Most common error: Tool timeout (40% of failures)</li>
                                <li>No infinite loops detected</li>
                            </ul>
                            
                            <p><strong>Action items:</strong></p>
                            <ul>
                                <li>Optimize search tool (reduce timeout rate)</li>
                                <li>Cache frequent searches</li>
                                <li>Add retry logic for timeouts</li>
                            </ul>
                        </div>
                    </div>

                    <div id="implementation" class="content-section">
                        <h2>Implementation</h2>
                        
                        <div class="code-box">
                            <h4>Agent Evaluation System</h4>
                            <pre><code class="language-python">import time
from typing import List, Dict

class AgentEvaluator:
    """Evaluate agent performance"""
    
    def __init__(self):
        self.metrics = {
            'total_tasks': 0,
            'successful_tasks': 0,
            'failed_tasks': 0,
            'total_latency': 0,
            'total_cost': 0
        }
    
    def evaluate_task(self, task, agent, expected_output=None):
        """Evaluate single task"""
        start_time = time.time()
        
        try:
            result = agent.execute(task)
            latency = time.time() - start_time
            cost = self.estimate_cost(agent.last_api_calls)
            
            # Check success
            success = self.check_success(result, expected_output)
            
            # Update metrics
            self.metrics['total_tasks'] += 1
            if success:
                self.metrics['successful_tasks'] += 1
            else:
                self.metrics['failed_tasks'] += 1
            self.metrics['total_latency'] += latency
            self.metrics['total_cost'] += cost
            
            return {
                'success': success,
                'latency': latency,
                'cost': cost,
                'result': result
            }
        except Exception as e:
            self.metrics['failed_tasks'] += 1
            return {'success': False, 'error': str(e)}
    
    def get_metrics(self):
        """Get aggregated metrics"""
        total = self.metrics['total_tasks']
        if total == 0:
            return {}
        
        return {
            'success_rate': self.metrics['successful_tasks'] / total,
            'avg_latency': self.metrics['total_latency'] / total,
            'avg_cost': self.metrics['total_cost'] / total,
            'total_tasks': total
        }
    
    def check_success(self, result, expected):
        """Check if result matches expected output"""
        if expected is None:
            return result is not None
        return result == expected
    
    def estimate_cost(self, api_calls):
        """Estimate cost from API calls"""
        # Simplified: assume $0.002 per 1K tokens
        total_tokens = sum(call.get('tokens', 0) for call in api_calls)
        return (total_tokens / 1000) * 0.002

# Example usage
evaluator = AgentEvaluator()
# evaluator.evaluate_task("Task 1", agent, expected_output="...")
# metrics = evaluator.get_metrics()</code></pre>
                        </div>
                    </div>

                    <div id="applications" class="content-section">
                        <h2>Real-World Applications</h2>
                        
                        <div class="explanation-box">
                            <h3>Evaluation and Monitoring in Production</h3>
                            <p><strong>Continuous monitoring:</strong></p>
                            <ul>
                                <li>Track agent performance in real-time</li>
                                <li>Alert on quality degradation</li>
                                <li>Detect anomalies in behavior</li>
                                <li>Monitor costs and usage</li>
                            </ul>
                            
                            <p><strong>A/B testing:</strong></p>
                            <ul>
                                <li>Compare different agent configurations</li>
                                <li>Test new prompts or tools</li>
                                <li>Measure impact of changes</li>
                            </ul>
                            
                            <p><strong>Quality assurance:</strong></p>
                            <ul>
                                <li>Validate agent outputs before deployment</li>
                                <li>Regression testing for agent updates</li>
                                <li>Compliance and safety checks</li>
                            </ul>
                        </div>
                    </div>

                    <div id="quiz" class="content-section">
                        <h2>Test Your Understanding</h2>
                        
                        <div class="quiz-container">
                        <div class="quiz-question">
                                <h3>Question 1: What is agent evaluation?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">A) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">B) Measuring agent performance, quality, and effectiveness using metrics like success rate, accuracy, and efficiency</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 2: What are the key metrics for evaluating agents?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">A) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">B) Task success rate, response quality (accuracy, relevance, completeness), and efficiency metrics (latency, token usage, tool calls)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 3: In the formula \(\text{Success Rate} = \frac{\text{Successful Tasks}}{\text{Total Tasks}} \times 100\%\), what does this measure?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">A) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">B) Overall agent reliability - percentage of tasks completed successfully</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 4: Interview question: "How would you design an evaluation system for agents?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">A) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">B) Define success criteria, create test datasets, implement automated metrics, use human evaluation for quality, track performance over time, and implement A/B testing</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 5: What should you monitor in agent behavior?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">A) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">D) Decision patterns, tool usage, error rates, loop detection, and cost tracking</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 6: What is the formula \(\text{Avg Latency} = \frac{1}{N} \sum_{i=1}^{N} T_i\) measuring?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">A) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">D) Average time to complete tasks, where N is number of tasks and T_i is time for task i</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 7: Interview question: "How do you detect infinite loops in agents?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Track action sequences, detect repeated patterns, implement max iteration limits, monitor state changes, and use timeout mechanisms</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 8: What is the cost per task formula \(\text{Cost} = \sum_{i=1}^{M} (\text{tokens}_i \times \text{price\_per\_token}_i)\) used for?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Calculating total cost by summing token costs across all API calls (M calls)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 9: What is A/B testing in agent evaluation?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">A) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">B) Comparing different agent configurations, prompts, or tools to measure impact of changes</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 10: Interview question: "How would you implement continuous monitoring for production agents?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">A) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">B) Implement comprehensive logging, real-time metrics dashboards, automated alerts for anomalies, track key performance indicators, and set up alerting thresholds</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 11: What is the difference between automated and human evaluation?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">A) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">D) Automated uses LLMs or rule-based systems for speed and scale, human evaluation provides gold standard quality assessment but is expensive</div>
                            </div>
                        <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 12: What is quality assurance in agent evaluation?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">A) While this might seem reasonable, it's not the correct approach for AI agents and would lead to poor performance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) This approach doesn't work for agent systems</div>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">C) Validating agent outputs before deployment, regression testing for updates, and compliance/safety checks</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) This comprehensive approach has been considered but doesn't align with agent architecture best practices and would introduce unnecessary complexity</div>
                            </div>
                        </div>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </section>
    </main>

    <footer style="background: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 2px solid #5B7553;">
        <div class="azbn-container" style="text-align: center;">
            <button onclick="scrollToSectionNav()" class="azbn-btn" style="margin: 0.5rem;">
                ‚Üë Back to Section Navigation
            </button>
            <div style="margin-top: 1.5rem;">
                <a href="/tutorials/agentic-ai" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Back to Tutorial</a>
                <a href="/tutorials/agentic-ai/chapter6" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Chapter 6</a>
                <a href="/tutorials/agentic-ai/chapter8" class="azbn-btn" style="text-decoration: none; margin: 0.5rem;">Chapter 8 ‚Üí</a>
            </div>
        </div>
    </footer>
    
        <!-- KaTeX for math rendering -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
<script src="{{ url_for('static', filename='js/tutorials/agentic-ai/shared-tutorial.js') }}"></script>
    <script>
        function scrollToSectionNav() {
            const sectionNav = document.querySelector('.section-nav');
            if (sectionNav) {
                sectionNav.scrollIntoView({ behavior: 'smooth', block: 'start' });
            }
        }
        
        function checkAnswer(element, isCorrect) {
            element.parentNode.querySelectorAll('.quiz-option').forEach(opt => {
                opt.classList.remove('correct', 'incorrect');
            });
            if (isCorrect) {
                element.classList.add('correct');
                element.textContent += ' ‚úì Correct!';
            } else {
                element.classList.add('incorrect');
                element.textContent += ' ‚úó Incorrect';
                const correctOption = Array.from(element.parentNode.querySelectorAll('.quiz-option'))
                    .find(opt => {
                        const onclick = opt.getAttribute('onclick') || '';
                        return onclick.includes('true');
                    });
                if (correctOption && !correctOption.classList.contains('incorrect')) {
                    correctOption.classList.add('correct');
                    correctOption.textContent += ' ‚úì Correct Answer';
                }
            }
        }
            
// Initialize KaTeX rendering - ensure KaTeX is loaded first
        function initKaTeX() {
            if (typeof katex !== 'undefined' && typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "\\[", right: "\\]", display: true},
                        {left: "$", right: "$", display: false},
                        {left: "\\(", right: "\\)", display: false}
                    ],
                    throwOnError: false
                });
            } else {
                // Retry if KaTeX not loaded yet
                setTimeout(initKaTeX, 100);
                return;
            }
            
            // Initialize Prism.js syntax highlighting
            if (typeof Prism !== 'undefined') {
                Prism.highlightAll();
            }
        }
        
        // Wait for DOM and KaTeX to be ready
        if (document.readyState === 'loading') {
            document.addEventListener("DOMContentLoaded", initKaTeX);
        } else {
            // DOM already loaded, wait for KaTeX
            initKaTeX();
