<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 1: Introduction to RAG - RAG & Retrieval Systems</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/rag/rag.css') }}">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>


</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav">
            <div class="azbn-container">
                <a href="/tutorials/rag" class="course-link">
                    <span>RAG & Retrieval Systems</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <div class="tutorial-header">
            <div class="azbn-container">
                <h1 class="chapter-title">Chapter 1: Introduction to RAG</h1>
                <p class="chapter-subtitle">Retrieval-Augmented Generation</p>
                
                <div class="chapter-progress">
                    <div class="chapter-progress-fill" data-progress="14"></div>
                </div>
                
                <div class="chapter-navigation">
                    <a href="/tutorials/rag/chapter1" class="chapter-nav-btn active">Chapter 1</a>
                    <a href="/tutorials/rag/chapter2" class="chapter-nav-btn ">Chapter 2</a>
                    <a href="/tutorials/rag/chapter3" class="chapter-nav-btn ">Chapter 3</a>
                    <a href="/tutorials/rag/chapter4" class="chapter-nav-btn ">Chapter 4</a>
                    <a href="/tutorials/rag/chapter5" class="chapter-nav-btn ">Chapter 5</a>
                    <a href="/tutorials/rag/chapter6" class="chapter-nav-btn ">Chapter 6</a>
                    <a href="/tutorials/rag/chapter7" class="chapter-nav-btn ">Chapter 7</a>
                </div>
                
                <div class="section-progress">
                    <div class="section-progress-fill" data-progress="14.3"></div>
                </div>
                
                <div class="section-nav">
                    <button class="section-nav-btn azbn-btn active" data-section="overview">Overview</button>
                    <button class="section-nav-btn azbn-btn" data-section="concepts">Key Concepts</button>
                    <button class="section-nav-btn azbn-btn" data-section="formulas">Formulas</button>
                    <button class="section-nav-btn azbn-btn" data-section="examples">Examples</button>
                    <button class="section-nav-btn azbn-btn" data-section="implementation">Implementation</button>
                    <button class="section-nav-btn azbn-btn" data-section="applications">Applications</button>
                    <button class="section-nav-btn azbn-btn" data-section="quiz">Quiz</button>
                </div>
            </div>
        </div>

        <section class="azbn-section">
            <div class="azbn-container">
                <div class="learning-objectives-box">
                    <h2>Learning Objectives</h2>
                    <ul>
                        <li>Understand introduction to rag fundamentals</li>
                        <li>Master the mathematical foundations</li>
                        <li>Learn practical implementation</li>
                        <li>Apply knowledge through examples</li>
                        <li>Recognize real-world applications</li>
                    </ul>
                </div>

                <main class="chapter-main-content">
                    <div id="overview" class="content-section active">
                        <h2>Introduction to RAG</h2>
                        
                        <div class="explanation-box">
                            <h3>What is RAG?</h3>
                            <p><strong>Retrieval-Augmented Generation (RAG) combines information retrieval with language generation.</strong> Instead of relying solely on the LLM's training data, RAG retrieves relevant information from external knowledge sources and uses it to generate more accurate, up-to-date responses.</p>
                            
                            <p><strong>Think of RAG like a research assistant:</strong></p>
                            <ul>
                                <li><strong>Traditional LLM:</strong> Like answering from memory - might be outdated or incomplete</li>
                                <li><strong>RAG System:</strong> Like a researcher who looks up current information, then answers based on what they found</li>
                                <li><strong>Result:</strong> More accurate, factual, and up-to-date responses</li>
                            </ul>
                        </div>

                        <div class="explanation-box">
                            <h4>⚠️ The Problem with LLMs</h4>
                            <p><strong>LLMs have three critical limitations:</strong></p>
                            
                            <div class="example-box">
                                <h5>1. Hallucination</h5>
                                <p><strong>LLMs can generate plausible-sounding but incorrect information:</strong></p>
                                <ul>
                                    <li>Question: "What is the capital of France?"</li>
                                    <li>LLM might say: "The capital of France is Paris" (correct)</li>
                                    <li>But also: "The capital of France is Lyon" (incorrect, but sounds plausible)</li>
                                    <li><strong>Problem:</strong> No way to verify without external knowledge</li>
                                </ul>
                            </div>
                            
                            <div class="example-box">
                                <h5>2. Outdated Information</h5>
                                <p><strong>LLMs are trained on data up to a cutoff date:</strong></p>
                                <ul>
                                    <li>GPT-3.5 trained on data up to September 2021</li>
                                    <li>Cannot know about events after that date</li>
                                    <li>Question: "Who won the 2024 World Cup?" → Might not know or hallucinate</li>
                                </ul>
                            </div>
                            
                            <div class="example-box">
                                <h5>3. Limited Context Window</h5>
                                <p><strong>LLMs have fixed context limits:</strong></p>
                                <ul>
                                    <li>Cannot store entire knowledge bases in context</li>
                                    <li>Cannot access private/internal documents</li>
                                    <li>Limited to what fits in the prompt</li>
                                </ul>
                            </div>
                        </div>

                        <div class="explanation-box">
                            <h4>✅ How RAG Solves These Problems</h4>
                            <p><strong>RAG architecture:</strong></p>
                            <ol>
                                <li><strong>Retrieval:</strong> Search external knowledge base for relevant information</li>
                                <li><strong>Augmentation:</strong> Add retrieved information to the prompt</li>
                                <li><strong>Generation:</strong> LLM generates answer based on retrieved context</li>
                            </ol>
                            
                            <p><strong>Benefits:</strong></p>
                            <ul>
                                <li>✅ Reduces hallucination (grounded in retrieved facts)</li>
                                <li>✅ Provides up-to-date information (can update knowledge base)</li>
                                <li>✅ Accesses private documents (can index internal docs)</li>
                                <li>✅ More transparent (can cite sources)</li>
                            </ul>
                        </div>
                    </div>

                    <div id="concepts" class="content-section">
                        <h2>Key Concepts</h2>
                        
                        <div class="explanation-box">
                            <h3>RAG Architecture</h3>
                            <p><strong>Components:</strong></p>
                            <ul>
                                <li><strong>Knowledge Base:</strong> Collection of documents (vector database)</li>
                                <li><strong>Retriever:</strong> Finds relevant documents for query</li>
                                <li><strong>LLM:</strong> Generates answer using retrieved context</li>
                            </ul>
                            
                            <p><strong>Process:</strong></p>
                            <ol>
                                <li>User asks question</li>
                                <li>Retriever searches knowledge base</li>
                                <li>Top-k relevant documents retrieved</li>
                                <li>Documents added to LLM prompt as context</li>
                                <li>LLM generates answer based on context</li>
                            </ol>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>RAG vs Fine-tuning</h3>
                            <p><strong>RAG advantages:</strong></p>
                            <ul>
                                <li>No training required</li>
                                <li>Easy to update knowledge (just add documents)</li>
                                <li>Can cite sources</li>
                                <li>Works with any LLM</li>
                            </ul>
                            
                            <p><strong>Fine-tuning advantages:</strong></p>
                            <ul>
                                <li>Better for learning specific patterns</li>
                                <li>No retrieval latency</li>
                                <li>More consistent behavior</li>
                            </ul>
                        </div>
                    </div>

                    <div id="formulas" class="content-section">
                        <h2>Mathematical Formulations</h2>
                        
                        <div class="formula-box">
                            <h4>RAG Generation Process</h4>
                            <div class="formula-display">
                                \[P(y | q) = P(y | q, \text{Retrieve}(q, D))\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(y\): Generated answer</li>
                                    <li>\(q\): User query</li>
                                    <li>\(D\): Knowledge base (document collection)</li>
                                    <li>\(\text{Retrieve}(q, D)\): Retrieved relevant documents</li>
                                    <li>LLM conditions on both query and retrieved context</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Retrieval Score (Cosine Similarity)</h4>
                            <div class="formula-display">
                                \[\text{score}(q, d) = \frac{q \cdot d}{\|q\| \|d\|} = \cos(\theta)\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(q\): Query embedding vector</li>
                                    <li>\(d\): Document embedding vector</li>
                                    <li>\(\theta\): Angle between vectors</li>
                                    <li>Higher score = more relevant document</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Top-k Retrieval</h4>
                            <div class="formula-display">
                                \[D_{\text{retrieved}} = \text{argmax}_k \{\text{score}(q, d) : d \in D\}\]
                            </div>
                            <div class="formula-explanation">
                                <p>Select top k documents with highest similarity scores. Typical k values: 3-10 documents.</p>
                            </div>
                        </div>
                    </div>

                    <div id="examples" class="content-section">
                        <h2>Detailed Examples</h2>
                        
                        <div class="example-box">
                            <h4>Example: RAG Question Answering</h4>
                            <p><strong>User query:</strong> "What is the capital of France?"</p>
                            
                            <p><strong>Step 1: Query Embedding</strong></p>
                            <ul>
                                <li>Convert query to embedding vector: [0.2, -0.5, 0.8, ...]</li>
                            </ul>
                            
                            <p><strong>Step 2: Retrieval</strong></p>
                            <ul>
                                <li>Search knowledge base for similar embeddings</li>
                                <li>Find document: "France is a country in Europe. Its capital is Paris."</li>
                                <li>Similarity score: 0.92</li>
                            </ul>
                            
                            <p><strong>Step 3: Context Augmentation</strong></p>
                            <ul>
                                <li>Build prompt: "Context: France is a country in Europe. Its capital is Paris. Question: What is the capital of France?"</li>
                            </ul>
                            
                            <p><strong>Step 4: Generation</strong></p>
                            <ul>
                                <li>LLM generates: "The capital of France is Paris."</li>
                                <li>Answer is grounded in retrieved context</li>
                            </ul>
                        </div>
                        
                        <div class="example-box">
                            <h4>Example: Without RAG vs With RAG</h4>
                            <p><strong>Query:</strong> "What happened in the company Q4 2024 earnings?"</p>
                            
                            <p><strong>Without RAG:</strong></p>
                            <ul>
                                <li>LLM only knows training data (cutoff date)</li>
                                <li>May hallucinate or say "I don't have information about that"</li>
                            </ul>
                            
                            <p><strong>With RAG:</strong></p>
                            <ul>
                                <li>Retrieves Q4 2024 earnings report from knowledge base</li>
                                <li>LLM generates answer based on actual report</li>
                                <li>Accurate, up-to-date information</li>
                            </ul>
                        </div>
                    </div>

                    <div id="implementation" class="content-section">
                        <h2>Implementation</h2>
                        
                        <div class="code-box">
                            <h4>Simple RAG Implementation</h4>
                            <pre><code class="language-python">from sentence_transformers import SentenceTransformer
import numpy as np
from transformers import pipeline

class SimpleRAG:
    """Basic RAG implementation"""
    
    def __init__(self):
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')
        self.llm = pipeline("text-generation", model="gpt2")
        self.documents = []
        self.embeddings = None
    
    def add_documents(self, docs):
        """Add documents to knowledge base"""
        self.documents = docs
        self.embeddings = self.embedder.encode(docs)
    
    def retrieve(self, query, top_k=3):
        """Retrieve top-k relevant documents"""
        query_embedding = self.embedder.encode([query])
        
        # Compute cosine similarity
        scores = np.dot(self.embeddings, query_embedding.T).flatten()
        
        # Get top-k indices
        top_indices = np.argsort(scores)[-top_k:][::-1]
        
        return [self.documents[i] for i in top_indices]
    
    def generate(self, query, top_k=3):
        """Generate answer using RAG"""
        # Retrieve relevant documents
        context_docs = self.retrieve(query, top_k)
        
        # Build prompt
        context = "\n".join(context_docs)
        prompt = f"Context: {context}\n\nQuestion: {query}\n\nAnswer:"
        
        # Generate
        result = self.llm(prompt, max_length=200, num_return_sequences=1)
        return result[0]['generated_text']

# Example usage
rag = SimpleRAG()
rag.add_documents([
    "France is a country in Europe. Its capital is Paris.",
    "Germany is a country in Europe. Its capital is Berlin.",
    "Italy is a country in Europe. Its capital is Rome."
])

answer = rag.generate("What is the capital of France?")
print(answer)</code></pre>
                        </div>
                    </div>

                    <div id="applications" class="content-section">
                        <h2>Real-World Applications</h2>
                        
                        <div class="explanation-box">
                            <h3>RAG Use Cases</h3>
                            <p><strong>Customer Support:</strong></p>
                            <ul>
                                <li>Chatbots with access to product documentation</li>
                                <li>FAQ systems with up-to-date information</li>
                                <li>Support ticket resolution</li>
                            </ul>
                            
                            <p><strong>Enterprise Knowledge Bases:</strong></p>
                            <ul>
                                <li>Internal documentation search</li>
                                <li>Company policy Q&A</li>
                                <li>Technical documentation assistance</li>
                            </ul>
                            
                            <p><strong>Research and Analysis:</strong></p>
                            <ul>
                                <li>Academic paper Q&A</li>
                                <li>Legal document analysis</li>
                                <li>Medical information systems</li>
                            </ul>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>RAG Advantages</h3>
                            <p><strong>Key benefits:</strong></p>
                            <ul>
                                <li>Up-to-date information (no retraining needed)</li>
                                <li>Source attribution (can cite documents)</li>
                                <li>Reduced hallucination (grounded in real data)</li>
                                <li>Domain-specific knowledge without fine-tuning</li>
                                <li>Easy to update (just add new documents)</li>
                            </ul>
                        </div>
                    </div>

                    <div id="quiz" class="content-section">
                        <h2>Test Your Understanding</h2>
                        
                        <div class="quiz-container">
                            <div class="quiz-question">
                                <h3>Question 1: What is RAG (Retrieval-Augmented Generation)?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) A system that combines information retrieval with language generation, retrieving relevant information from external sources before generating responses</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) A method to train LLMs faster</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) A type of neural network architecture</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) A database system</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 2: What are the main limitations of traditional LLMs that RAG addresses?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Hallucination, outdated information, lack of source attribution, and knowledge cutoff dates</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Speed and cost only</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Model size</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Training time</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 3: In the RAG formula \(P(y \mid q) = P(y \mid q, \text{Retrieve}(q, D))\), what does \(\text{Retrieve}(q, D)\) represent?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) The retrieved relevant documents from knowledge base D for query q</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) The generated answer</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) The query embedding</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) The LLM model</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 4: Interview question: "What are the key advantages of RAG over fine-tuning?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) No training required, easy to update knowledge by adding documents, can cite sources, works with any LLM, and no retraining needed for new information</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Faster inference</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Smaller model size</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Lower cost</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 5: What is cosine similarity used for in RAG?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Measuring semantic similarity between query and document embeddings to find relevant documents</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Training the LLM</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Generating embeddings</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Chunking documents</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 6: What does top-k retrieval mean in RAG?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Selecting the k documents with highest similarity scores (typically k=3-10)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Using k different models</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Training k times</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Processing k queries</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 7: Interview question: "When would you choose RAG over fine-tuning?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) When you need up-to-date information, want source attribution, have frequently changing knowledge, or need to work with domain-specific documents without retraining</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Always choose RAG</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Always choose fine-tuning</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) When you need faster inference</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 8: What is the typical RAG pipeline flow?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Query → Embedding → Retrieval → Context Assembly → LLM Generation → Response</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Query → LLM → Response</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Documents → Training → Model</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Query → Database → Response</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 9: What is the main difference between RAG and traditional LLM responses?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) RAG retrieves relevant context from external knowledge sources before generating, while traditional LLMs only use training data</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) RAG is faster</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) RAG uses smaller models</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) There's no difference</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 10: Interview question: "How does RAG reduce hallucination?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) By grounding responses in retrieved documents from the knowledge base, providing factual context that constrains the LLM's generation</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) By using smaller models</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) By training more</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) By using faster inference</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 11: What is the cosine similarity formula \(\text{score}(q, d) = \frac{q \cdot d}{\|q\| \|d\|}\) measuring?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) The cosine of the angle between query and document vectors, indicating semantic similarity (range: -1 to 1, higher = more similar)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Euclidean distance</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Dot product only</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Vector magnitude</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 12: Interview question: "What are the key components of a RAG system?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Document knowledge base, embedding model, vector database, retrieval mechanism, LLM for generation, and context assembly logic</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Just an LLM</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Just a database</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Just embeddings</div>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </section>
    </main>

    <footer style="background: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 2px solid #5B7553;">
        <div class="azbn-container" style="text-align: center;">
            <button onclick="scrollToSectionNav()" class="azbn-btn" style="margin: 0.5rem;">
                ↑ Back to Section Navigation
            </button>
            <div style="margin-top: 1.5rem;">
                <a href="/tutorials/rag" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">← Back to Tutorial</a>
                <a href="/tutorials/rag/chapter2" class="azbn-btn" style="text-decoration: none; margin: 0.5rem;">Chapter 2 →</a>
            </div>
        </div>
    </footer>
    
        <!-- KaTeX for math rendering -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
<script src="{{ url_for('static', filename='js/tutorials/rag/shared-tutorial.js') }}"></script>
    <script>
        function checkAnswer(element, isCorrect) {
            element.parentNode.querySelectorAll('.quiz-option').forEach(opt => {
                opt.classList.remove('correct', 'incorrect');
            });
            if (isCorrect) {
                element.classList.add('correct');
                element.textContent += ' ✓ Correct!';
            } else {
                element.classList.add('incorrect');
                element.textContent += ' ✗ Incorrect';
                const correctOption = Array.from(element.parentNode.querySelectorAll('.quiz-option'))
                    .find(opt => {
                        const onclick = opt.getAttribute('onclick') || '';
                        return onclick.includes('true');
                    });
                if (correctOption && !correctOption.classList.contains('incorrect')) {
                    correctOption.classList.add('correct');
                    correctOption.textContent += ' ✓ Correct Answer';
                }
            }
        }
            
// Initialize KaTeX rendering - ensure KaTeX is loaded first
        function initKaTeX() {
            if (typeof katex !== 'undefined' && typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "\\[", right: "\\]", display: true},
                        {left: "$", right: "$", display: false},
                        {left: "\\(", right: "\\)", display: false}
                    ],
                    throwOnError: false
                });
            } else {
                // Retry if KaTeX not loaded yet
                setTimeout(initKaTeX, 100);
                return;
            }
            
            // Initialize Prism.js syntax highlighting
            if (typeof Prism !== 'undefined') {
                Prism.highlightAll();
            }
        }
        
        // Wait for DOM and KaTeX to be ready
        if (document.readyState === 'loading') {
            document.addEventListener("DOMContentLoaded", initKaTeX);
        } else {
            // DOM already loaded, wait for KaTeX
            initKaTeX();
