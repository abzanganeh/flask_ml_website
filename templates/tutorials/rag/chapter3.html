<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 3: Document Processing & Chunking - RAG & Retrieval Systems</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}?v=2">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/rag/rag.css') }}?v=3">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>


</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav">
            <div class="azbn-container">
                <a href="/tutorials/rag" class="course-link">
                    <span>RAG & Retrieval Systems</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <div class="tutorial-header">
            <div class="azbn-container">
                <h1 class="chapter-title">Chapter 3: Document Processing & Chunking</h1>
                <p class="chapter-subtitle">Preparing Documents for Retrieval</p>
                
                <div class="chapter-progress">
                    <div class="chapter-progress-fill" data-progress="42"></div>
                </div>
                
                <div class="chapter-navigation">
                    <a href="/tutorials/rag/chapter1" class="chapter-nav-btn ">Chapter 1</a>
                    <a href="/tutorials/rag/chapter2" class="chapter-nav-btn ">Chapter 2</a>
                    <a href="/tutorials/rag/chapter3" class="chapter-nav-btn active">Chapter 3</a>
                    <a href="/tutorials/rag/chapter4" class="chapter-nav-btn ">Chapter 4</a>
                    <a href="/tutorials/rag/chapter5" class="chapter-nav-btn ">Chapter 5</a>
                    <a href="/tutorials/rag/chapter6" class="chapter-nav-btn ">Chapter 6</a>
                    <a href="/tutorials/rag/chapter7" class="chapter-nav-btn ">Chapter 7</a>
                </div>
                
                <div class="section-progress">
                    <div class="section-progress-fill" data-progress="14.3"></div>
                </div>
                
                <div class="section-nav">
                    <button class="section-nav-btn azbn-btn active" data-section="overview">Overview</button>
                    <button class="section-nav-btn azbn-btn" data-section="concepts">Key Concepts</button>
                    <button class="section-nav-btn azbn-btn" data-section="formulas">Formulas</button>
                    <button class="section-nav-btn azbn-btn" data-section="examples">Examples</button>
                    <button class="section-nav-btn azbn-btn" data-section="implementation">Implementation</button>
                    <button class="section-nav-btn azbn-btn" data-section="applications">Applications</button>
                    <button class="section-nav-btn azbn-btn" data-section="quiz">Quiz</button>
                </div>
            </div>
        </div>

        <section class="azbn-section">
            <div class="azbn-container">
                <div class="learning-objectives-box">
                    <h2>Learning Objectives</h2>
                    <ul>
                        <li>Understand document processing & chunking fundamentals</li>
                        <li>Master the mathematical foundations</li>
                        <li>Learn practical implementation</li>
                        <li>Apply knowledge through examples</li>
                        <li>Recognize real-world applications</li>
                    </ul>
                </div>

                <main class="chapter-main-content">
                    <div id="overview" class="content-section active">
                        <h2>Document Processing & Chunking</h2>
                        
                        <div class="explanation-box">
                            <h3>Introduction</h3>
                            <p><strong>Preparing Documents for Retrieval</strong></p>
                            <p>This chapter provides comprehensive coverage of document processing & chunking, including detailed explanations, mathematical formulations, code implementations, and real-world examples.</p>
                        </div>

                        <div class="example-box">
                            <h4>üìö Why This Matters</h4>
                            <p>Understanding document processing & chunking is crucial for mastering modern AI systems. This chapter breaks down complex concepts into digestible explanations with step-by-step examples.</p>
                        </div>
                    </div>

                    <div id="concepts" class="content-section">
                        <h2>Key Concepts</h2>
                        
                        <div class="explanation-box">
                            <h3>Why Chunking is Critical for RAG Systems</h3>
                            
                            <h4>The Core Problem</h4>
                            <p>Raw documents in real-world RAG systems are often <strong>extremely long</strong>‚Äîthink research papers (10,000+ words), legal documents (hundreds of pages), technical documentation (thousands of sections), or entire books. These documents present several fundamental challenges:</p>
                            
                            <ul>
                                <li><strong>Context Window Limits:</strong> Most LLMs have fixed context windows (e.g., GPT-4: 8K-128K tokens, Claude: 100K-200K tokens). A single large document can easily exceed these limits, making it impossible to process the entire document at once.</li>
                                <li><strong>Embedding Model Constraints:</strong> Embedding models like SentenceTransformers work best with text segments of 128-512 tokens. Very long documents produce embeddings that lose semantic precision‚Äîthe model struggles to capture the meaning of a 10,000-word document in a single 384-dimensional vector.</li>
                                <li><strong>Retrieval Precision:</strong> When you retrieve a 50-page document for a specific question, most of that document is irrelevant. The LLM has to sift through thousands of words to find the answer, leading to poor performance and high costs.</li>
                                <li><strong>Computational Efficiency:</strong> Processing entire documents is computationally expensive. Smaller chunks allow for faster embedding generation, more efficient storage, and quicker retrieval.</li>
                            </ul>
                            
                            <h4>The Solution: Intelligent Chunking</h4>
                            <p>Chunking splits large documents into smaller, manageable pieces that:</p>
                            
                            <ul>
                                <li><strong>Fit within context limits:</strong> Each chunk is small enough to fit comfortably in the LLM's context window, even when combined with the query and other chunks.</li>
                                <li><strong>Are semantically meaningful:</strong> Each chunk represents a coherent unit of information (a paragraph, a section, a concept) rather than arbitrary text splits.</li>
                                <li><strong>Can be retrieved independently:</strong> Each chunk can be embedded and stored separately, allowing the retrieval system to find the most relevant chunk(s) for a specific query.</li>
                                <li><strong>Maintain context when possible:</strong> Chunks preserve surrounding context (through overlap or metadata) so the LLM understands the broader context when generating answers.</li>
                            </ul>
                            
                            <div class="example-box">
                                <h5>Real-World Example:</h5>
                                <p>Imagine you have a 200-page technical manual about machine learning. Without chunking:</p>
                                <ul>
                                    <li>‚ùå The entire document is too large to embed meaningfully</li>
                                    <li>‚ùå Retrieval returns the whole manual, even if the question is about a specific algorithm</li>
                                    <li>‚ùå The LLM wastes tokens processing irrelevant sections</li>
                                </ul>
                                <p>With intelligent chunking:</p>
                                <ul>
                                    <li>‚úÖ The manual is split into 500 chunks (one per section/topic)</li>
                                    <li>‚úÖ Each chunk is embedded separately and stored in the vector database</li>
                                    <li>‚úÖ A query about "gradient descent" retrieves only the 2-3 most relevant chunks</li>
                                    <li>‚úÖ The LLM receives focused, relevant context and generates accurate answers</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Chunking Strategies: Choosing the Right Approach</h3>
                            
                            <p>Different chunking strategies serve different purposes. The choice depends on your document type, use case, and performance requirements.</p>
                            
                            <h4>1. Fixed-Size Chunking</h4>
                            <p><strong>What it is:</strong> Splits documents into chunks of a fixed size (measured in characters or tokens), regardless of content structure.</p>
                            
                            <p><strong>How it works:</strong></p>
                            <ul>
                                <li>Divide the document into equal-sized segments (e.g., 500 characters or 200 tokens)</li>
                                <li>Each chunk has exactly the same size (except possibly the last chunk)</li>
                                <li>No consideration for sentence boundaries, paragraphs, or semantic meaning</li>
                            </ul>
                            
                            <p><strong>Advantages:</strong></p>
                            <ul>
                                <li>‚úÖ <strong>Simple and fast:</strong> Very easy to implement, no complex logic needed</li>
                                <li>‚úÖ <strong>Predictable:</strong> You know exactly how many chunks you'll get for any document size</li>
                                <li>‚úÖ <strong>Efficient storage:</strong> Uniform chunk sizes make storage and indexing straightforward</li>
                                <li>‚úÖ <strong>Good for uniform content:</strong> Works well when documents have consistent structure</li>
                            </ul>
                            
                            <p><strong>Disadvantages:</strong></p>
                            <ul>
                                <li>‚ùå <strong>May break sentences:</strong> A chunk might end mid-sentence, losing meaning</li>
                                <li>‚ùå <strong>Ignores semantic boundaries:</strong> A single concept might be split across two chunks</li>
                                <li>‚ùå <strong>Poor for structured content:</strong> Doesn't respect paragraphs, sections, or logical divisions</li>
                            </ul>
                            
                            <p><strong>When to use:</strong> When you have uniform, unstructured text where semantic boundaries don't matter much, or when you need maximum speed and simplicity.</p>
                            
                            <h4>2. Sentence-Based Chunking</h4>
                            <p><strong>What it is:</strong> Splits documents at sentence boundaries, grouping multiple sentences into chunks of roughly equal size.</p>
                            
                            <p><strong>How it works:</strong></p>
                            <ul>
                                <li>Identify sentence boundaries using NLP tools (NLTK, spaCy, or regex)</li>
                                <li>Group sentences together until reaching a target chunk size (e.g., 5-10 sentences or 200-500 tokens)</li>
                                <li>Each chunk contains complete sentences, never breaking mid-sentence</li>
                            </ul>
                            
                            <p><strong>Advantages:</strong></p>
                            <ul>
                                <li>‚úÖ <strong>Preserves sentence integrity:</strong> Sentences remain intact, maintaining grammatical and semantic coherence</li>
                                <li>‚úÖ <strong>Better semantic coherence:</strong> Related sentences stay together, improving embedding quality</li>
                                <li>‚úÖ <strong>Respects natural boundaries:</strong> Works with how humans structure information</li>
                                <li>‚úÖ <strong>Good for narrative content:</strong> Excellent for articles, stories, and prose</li>
                            </ul>
                            
                            <p><strong>Disadvantages:</strong></p>
                            <ul>
                                <li>‚ùå <strong>Variable chunk sizes:</strong> Chunks may vary significantly in size depending on sentence length</li>
                                <li>‚ùå <strong>May split related concepts:</strong> A concept spanning multiple sentences might be split across chunks</li>
                                <li>‚ùå <strong>Requires sentence detection:</strong> Needs reliable sentence segmentation (can fail with abbreviations, decimals, etc.)</li>
                            </ul>
                            
                            <p><strong>When to use:</strong> For narrative text, articles, blog posts, or any content where sentence boundaries matter. This is often the default choice for general-purpose RAG systems.</p>
                            
                            <h4>3. Semantic Chunking (Advanced)</h4>
                            <p><strong>What it is:</strong> Uses embeddings and similarity calculations to group semantically related sentences together, creating chunks based on meaning rather than size.</p>
                            
                            <p><strong>How it works:</strong></p>
                            <ul>
                                <li>Embed each sentence (or small group of sentences) into vector space</li>
                                <li>Calculate similarity between consecutive sentences</li>
                                <li>When similarity drops below a threshold, that's a chunk boundary (new topic/concept)</li>
                                <li>Group similar sentences together until reaching a maximum chunk size</li>
                            </ul>
                            
                            <p><strong>Advantages:</strong></p>
                            <ul>
                                <li>‚úÖ <strong>Most semantically coherent:</strong> Chunks represent complete concepts or topics</li>
                                <li>‚úÖ <strong>Adaptive to content:</strong> Automatically adjusts to document structure</li>
                                <li>‚úÖ <strong>Better retrieval quality:</strong> Chunks are more likely to be fully relevant or fully irrelevant</li>
                                <li>‚úÖ <strong>Respects topic boundaries:</strong> Natural breaks occur at topic transitions</li>
                            </ul>
                            
                            <p><strong>Disadvantages:</strong></p>
                            <ul>
                                <li>‚ùå <strong>Computationally expensive:</strong> Requires embedding every sentence, then calculating similarities</li>
                                <li>‚ùå <strong>More complex to implement:</strong> Needs careful tuning of similarity thresholds</li>
                                <li>‚ùå <strong>Variable chunk sizes:</strong> Can produce very small or very large chunks</li>
                                <li>‚ùå <strong>Requires embedding model:</strong> Needs a good sentence embedding model to work well</li>
                            </ul>
                            
                            <p><strong>When to use:</strong> For high-quality RAG systems where retrieval precision matters more than speed. Ideal for technical documentation, research papers, or any content with clear topic boundaries.</p>
                            
                            <h4>4. Recursive Chunking (Hierarchical)</h4>
                            <p><strong>What it is:</strong> A hybrid approach that tries multiple chunking strategies in a hierarchy (e.g., try paragraphs first, then sentences, then fixed-size).</p>
                            
                            <p><strong>How it works:</strong></p>
                            <ul>
                                <li>First, try to split by paragraphs (if they exist and are reasonable size)</li>
                                <li>If paragraphs are too large, split by sentences</li>
                                <li>If sentences are still too large, use fixed-size chunking as fallback</li>
                                <li>Maintains hierarchy: parent chunks contain metadata about child chunks</li>
                            </ul>
                            
                            <p><strong>Advantages:</strong></p>
                            <ul>
                                <li>‚úÖ <strong>Adaptive:</strong> Automatically chooses the best strategy for each part of the document</li>
                                <li>‚úÖ <strong>Respects structure:</strong> Uses document structure when available</li>
                                <li>‚úÖ <strong>Robust:</strong> Falls back gracefully when structure is missing</li>
                            </ul>
                            
                            <p><strong>When to use:</strong> When you have diverse document types with varying structures. Popular in production RAG systems (used by LangChain, LlamaIndex).</p>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Chunk Overlap: Preserving Context at Boundaries</h3>
                            
                            <h4>Why Overlap is Essential</h4>
                            <p>When you split a document into chunks, you create <strong>boundaries</strong> between chunks. These boundaries are artificial‚Äîthey don't exist in the original document. This creates a critical problem:</p>
                            
                            <p><strong>The Boundary Problem:</strong> Important information often appears at the edges of chunks. Consider this example:</p>
                            
                            <div class="example-box">
                                <h5>Example: The Boundary Problem</h5>
                                <p><strong>Original Document:</strong></p>
                                <p>"Machine learning models require careful tuning. <strong>Hyperparameters like learning rate and batch size significantly impact model performance.</strong> Regularization techniques help prevent overfitting."</p>
                                
                                <p><strong>Without Overlap (Bad):</strong></p>
                                <ul>
                                    <li><strong>Chunk 1:</strong> "Machine learning models require careful tuning. Hyperparameters like learning rate and batch size significantly impact model performance."</li>
                                    <li><strong>Chunk 2:</strong> "Regularization techniques help prevent overfitting."</li>
                                </ul>
                                <p>‚ùå If a query asks about "hyperparameters and regularization," Chunk 1 might be retrieved (mentions hyperparameters) but Chunk 2 (mentions regularization) might not be, even though they're related concepts.</p>
                                
                                <p><strong>With Overlap (Good):</strong></p>
                                <ul>
                                    <li><strong>Chunk 1:</strong> "Machine learning models require careful tuning. Hyperparameters like learning rate and batch size significantly impact model performance. Regularization techniques help prevent overfitting."</li>
                                    <li><strong>Chunk 2:</strong> "Hyperparameters like learning rate and batch size significantly impact model performance. Regularization techniques help prevent overfitting."</li>
                                </ul>
                                <p>‚úÖ Now both chunks contain information about hyperparameters AND regularization, improving retrieval quality.</p>
                            </div>
                            
                            <h4>How Overlap Works</h4>
                            <p>Overlap means that consecutive chunks share some content at their boundaries. For example, with 20% overlap:</p>
                            
                            <ul>
                                <li>If chunk size is 500 tokens, overlap is 100 tokens</li>
                                <li>Chunk 1: tokens 1-500</li>
                                <li>Chunk 2: tokens 401-900 (starts at token 401, overlapping the last 100 tokens of Chunk 1)</li>
                                <li>Chunk 3: tokens 801-1300 (overlaps with Chunk 2)</li>
                            </ul>
                            
                            <h4>Choosing the Right Overlap</h4>
                            <p><strong>Typical overlap:</strong> 10-20% of chunk size is standard. Here's why:</p>
                            
                            <ul>
                                <li><strong>Too little overlap (0-5%):</strong> ‚ùå Doesn't solve the boundary problem. Important context at boundaries is still lost. Not recommended.</li>
                                <li><strong>Moderate overlap (10-20%):</strong> ‚úÖ Good balance. Preserves context without excessive storage overhead. This is the sweet spot for most use cases.</li>
                                <li><strong>High overlap (30-50%):</strong> ‚ö†Ô∏è Better context preservation but significantly increases storage costs. Use only when context preservation is critical (e.g., legal documents, medical records).</li>
                                <li><strong>Very high overlap (50%+):</strong> ‚ùå Wasteful. You're essentially storing the document twice. Rarely justified.</li>
                            </ul>
                            
                            <h4>Trade-offs</h4>
                            <p><strong>Benefits of overlap:</strong></p>
                            <ul>
                                <li>‚úÖ Preserves context at boundaries</li>
                                <li>‚úÖ Improves retrieval quality (related concepts stay together)</li>
                                <li>‚úÖ Reduces risk of missing relevant information</li>
                                <li>‚úÖ Better for queries that span multiple topics</li>
                            </ul>
                            
                            <p><strong>Costs of overlap:</strong></p>
                            <ul>
                                <li>‚ùå <strong>Increased storage:</strong> More chunks = more embeddings to store</li>
                                <li>‚ùå <strong>Higher embedding costs:</strong> More chunks to embed (if using paid APIs)</li>
                                <li>‚ùå <strong>Potential redundancy:</strong> Same information retrieved multiple times (though this is usually acceptable)</li>
                            </ul>
                            
                            <h4>Best Practices</h4>
                            <ul>
                                <li><strong>Start with 10-20% overlap:</strong> This works well for most documents</li>
                                <li><strong>Increase for critical documents:</strong> Use 20-30% for legal, medical, or financial documents where context is crucial</li>
                                <li><strong>Decrease for uniform content:</strong> Use 5-10% for structured data or lists where boundaries are less important</li>
                                <li><strong>Test and measure:</strong> Evaluate retrieval quality with different overlap percentages on your specific documents</li>
                            </ul>
                        </div>
                    </div>

                    <div id="formulas" class="content-section">
                        <h2>Mathematical Formulations</h2>
                        
                        <div class="formula-box">
                            <h4>BM25 (Sparse Retrieval)</h4>
                            <div class="formula-display">
                                \[\text{BM25}(q, d) = \sum_{t \in q} \text{IDF}(t) \times \frac{f(t,d) \times (k_1 + 1)}{f(t,d) + k_1 \times (1 - b + b \times \frac{|d|}{\text{avgdl}})}\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(q\): Query</li>
                                    <li>\(d\): Document</li>
                                    <li>\(f(t,d)\): Term frequency in document</li>
                                    <li>\(\text{IDF}(t)\): Inverse document frequency</li>
                                    <li>\(k_1, b\): Tuning parameters</li>
                                    <li>\(|d|, \text{avgdl}\): Document length and average length</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Hybrid Score</h4>
                            <div class="formula-display">
                                \[\text{score}(q, d) = \alpha \times \text{BM25}(q, d) + (1 - \alpha) \times \text{cosine}(E(q), E(d))\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(\alpha\): Weight between sparse and dense (typically 0.3-0.7)</li>
                                    <li>Combines keyword matching with semantic similarity</li>
                                    <li>Often outperforms either method alone</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Reranking Score</h4>
                            <div class="formula-display">
                                \[\text{rerank\_score}(q, d) = \text{CrossEncoder}([q; d])\]
                            </div>
                            <div class="formula-explanation">
                                <p>Cross-encoder processes query and document together, providing more accurate relevance score than bi-encoder (embedding-based) methods.</p>
                            </div>
                        </div>
                    </div>

                    <div id="examples" class="content-section">
                        <h2>Detailed Examples</h2>
                        
                        <div class="example-box">
                            <h4>Example: Dense vs Sparse Retrieval</h4>
                            <p><strong>Query:</strong> "How do I reset my password?"</p>
                            
                            <p><strong>Dense retrieval (semantic):</strong></p>
                            <ul>
                                <li>Finds: "Password recovery steps", "Reset account access", "Forgot password guide"</li>
                                <li>Understands synonyms: "reset" = "recovery" = "forgot"</li>
                            </ul>
                            
                            <p><strong>Sparse retrieval (keyword):</strong></p>
                            <ul>
                                <li>Finds: Documents containing "reset" AND "password"</li>
                                <li>Misses: "Password recovery" (no "reset" keyword)</li>
                            </ul>
                            
                            <p><strong>Hybrid:</strong> Combines both, gets best results</p>
                        </div>
                        
                        <div class="example-box">
                            <h4>Example: Reranking</h4>
                            <p><strong>Initial retrieval (top-10):</strong></p>
                            <ul>
                                <li>Doc 1: "Password reset" (score: 0.85)</li>
                                <li>Doc 2: "Account settings" (score: 0.82)</li>
                                <li>Doc 3: "Password recovery" (score: 0.80)</li>
                                <li>...</li>
                            </ul>
                            
                            <p><strong>After reranking:</strong></p>
                            <ul>
                                <li>Doc 3: "Password recovery" (score: 0.92) ‚Üê More relevant!</li>
                                <li>Doc 1: "Password reset" (score: 0.88)</li>
                                <li>Doc 2: "Account settings" (score: 0.65) ‚Üê Less relevant</li>
                            </ul>
                            
                            <p><strong>Result:</strong> Better ordering improves final answer quality</p>
                        </div>
                    </div>

                    <div id="implementation" class="content-section">
                        <h2>Implementation</h2>
                        
                        <div class="code-box">
                            <h4>Hybrid Retrieval</h4>
                            <pre><code class="language-python">from sentence_transformers import SentenceTransformer
from rank_bm25 import BM25Okapi
import numpy as np

class HybridRetriever:
    """Hybrid dense + sparse retrieval"""
    
    def __init__(self, documents, alpha=0.5):
        self.documents = documents
        self.alpha = alpha  # Weight for BM25 vs dense
        
        # Dense retriever
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')
        self.embeddings = self.embedder.encode(documents)
        
        # Sparse retriever (BM25)
        tokenized_docs = [doc.split() for doc in documents]
        self.bm25 = BM25Okapi(tokenized_docs)
    
    def retrieve(self, query, top_k=5):
        """Retrieve using hybrid approach"""
        # Dense retrieval
        query_embedding = self.embedder.encode([query])
        dense_scores = np.dot(self.embeddings, query_embedding.T).flatten()
        dense_scores = (dense_scores - dense_scores.min()) / (dense_scores.max() - dense_scores.min() + 1e-8)
        
        # Sparse retrieval
        tokenized_query = query.split()
        sparse_scores = self.bm25.get_scores(tokenized_query)
        sparse_scores = (sparse_scores - sparse_scores.min()) / (sparse_scores.max() - sparse_scores.min() + 1e-8)
        
        # Combine
        hybrid_scores = self.alpha * sparse_scores + (1 - self.alpha) * dense_scores
        
        # Get top-k
        top_indices = np.argsort(hybrid_scores)[-top_k:][::-1]
        return [self.documents[i] for i in top_indices]

# Example
docs = ["Password reset instructions", "Account settings guide", "Password recovery steps"]
retriever = HybridRetriever(docs)
results = retriever.retrieve("How do I reset my password?")
print(results)</code></pre>
                        </div>
                        
                        <div class="code-box">
                            <h4>Reranking with Cross-Encoder</h4>
                            <pre><code class="language-python">from sentence_transformers import CrossEncoder

class Reranker:
    """Rerank retrieved documents"""
    
    def __init__(self):
        self.model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    def rerank(self, query, documents, top_k=3):
        """Rerank documents for query"""
        # Create query-document pairs
        pairs = [[query, doc] for doc in documents]
        
        # Get scores
        scores = self.model.predict(pairs)
        
        # Sort by score
        ranked_indices = np.argsort(scores)[::-1]
        
        # Return top-k
        return [documents[i] for i in ranked_indices[:top_k]]

# Example
reranker = Reranker()
docs = ["Password reset", "Account settings", "Password recovery"]
reranked = reranker.rerank("How do I reset my password?", docs)
print(reranked)</code></pre>
                        </div>
                    </div>

                    <div id="applications" class="content-section">
                        <h2>Real-World Applications</h2>
                        
                        <div class="explanation-box">
                            <h3>Retrieval Strategy Selection</h3>
                            <p><strong>Use dense retrieval when:</strong></p>
                            <ul>
                                <li>Semantic understanding is important</li>
                                <li>Users may phrase queries differently</li>
                                <li>Domain-specific terminology</li>
                            </ul>
                            
                            <p><strong>Use sparse retrieval when:</strong></p>
                            <ul>
                                <li>Exact keyword matching is important</li>
                                <li>Speed is critical</li>
                                <li>Technical documentation with specific terms</li>
                            </ul>
                            
                            <p><strong>Use hybrid when:</strong></p>
                            <ul>
                                <li>You want best of both worlds</li>
                                <li>High accuracy is required</li>
                                <li>Can afford extra computation</li>
                            </ul>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Reranking Benefits</h3>
                            <p><strong>When to use reranking:</strong></p>
                            <ul>
                                <li>Initial retrieval returns many candidates</li>
                                <li>Need high precision in top results</li>
                                <li>Can afford additional latency</li>
                                <li>Quality is more important than speed</li>
                            </ul>
                        </div>
                    </div>

                    <div id="quiz" class="content-section">
                        <h2>Test Your Understanding</h2>
                        
                        <div class="quiz-container">
                            <div class="quiz-question">
                                <h3>Question 1: Why is document chunking important in RAG systems?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) LLMs have context limits, chunking breaks documents into manageable pieces that fit in context windows while preserving semantic meaning</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) To make documents smaller</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) To reduce storage</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Chunking is not needed</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 2: Interview question: "What are the different chunking strategies and when would you use each?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Fixed-size: Simple, fast, good for uniform text. Semantic: Preserves meaning, better for varied content. Recursive: Handles nested structures. Use fixed-size for speed, semantic for quality, recursive for structured documents</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only fixed-size</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only semantic</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Chunking strategy doesn't matter</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 3: What is chunk overlap and why is it used?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Overlapping chunks share some content to preserve context at boundaries, preventing information loss when sentences/paragraphs are split</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) To reduce storage</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) To make chunks smaller</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Overlap is not needed</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 4: Interview question: "How do you determine optimal chunk size?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Balance LLM context window, retrieval precision (smaller = more precise), and semantic completeness (larger = more context). Common: 200-1000 tokens. Test on your data and downstream task</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Always use 100 tokens</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Always use 5000 tokens</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Chunk size doesn't matter</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 5: What is semantic chunking?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Chunking based on semantic boundaries (sentences, paragraphs, topics) rather than fixed sizes, preserving meaning and context</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Chunking by file size</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Random chunking</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Chunking by word count only</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 6: Interview question: "How do you handle different document types (PDF, HTML, Markdown) in RAG?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Use appropriate parsers (PyPDF2, BeautifulSoup, markdown), extract text while preserving structure, handle metadata, and apply document-type-specific chunking strategies</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Convert all to text first</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only support one format</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) No special handling needed</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 7: What is metadata extraction in document processing?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Extracting document properties (title, author, date, source, section) to enable filtering and better retrieval in vector databases</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Extracting all text</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Compressing documents</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Metadata is not needed</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 8: Interview question: "How do you preserve context when chunking documents?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Use chunk overlap, preserve sentence/paragraph boundaries, include surrounding context in metadata, and use semantic chunking to keep related content together</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) No context preservation needed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only use fixed-size chunks</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Split randomly</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 9: What are the trade-offs between small and large chunk sizes?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Small chunks: More precise retrieval but may lose context. Large chunks: More context but less precise retrieval. Balance based on query type and document structure</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Small is always better</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Large is always better</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Size doesn't matter</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 10: Interview question: "How would you handle very long documents (e.g., books) in RAG?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Use hierarchical chunking (chapters ‚Üí sections ‚Üí paragraphs), maintain document structure in metadata, use multi-level retrieval, and consider document summarization for overview</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Split into equal chunks</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Use only first part</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Skip long documents</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 11: What is recursive chunking?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Chunking that tries multiple strategies in order (e.g., paragraphs ‚Üí sentences ‚Üí characters) until chunks fit size requirements, handling nested document structures</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Chunking twice</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Random chunking</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) No difference from fixed-size</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 12: Interview question: "How do you evaluate chunking quality?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Measure retrieval performance (precision@k, recall@k), test downstream RAG quality, check if relevant information is preserved, and evaluate chunk coherence</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only check chunk size</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) No evaluation needed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Only check number of chunks</div>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </section>
    </main>

    <footer style="background: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 2px solid #5B7553;">
        <div class="azbn-container" style="text-align: center;">
            <button onclick="scrollToSectionNav()" class="azbn-btn" style="margin: 0.5rem;">
                ‚Üë Back to Section Navigation
            </button>
            <div style="margin-top: 1.5rem;">
                <a href="/tutorials/rag" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Back to Tutorial</a>
                <a href="/tutorials/rag/chapter2" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Chapter 2</a>
                <a href="/tutorials/rag/chapter4" class="azbn-btn" style="text-decoration: none; margin: 0.5rem;">Chapter 4 ‚Üí</a>
            </div>
        </div>
    </footer>
    
        <!-- KaTeX for math rendering -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
<script src="{{ url_for('static', filename='js/tutorials/shared-quiz.js') }}?v=2"></script>
<script src="{{ url_for('static', filename='js/tutorials/rag/shared-tutorial.js') }}?v=2"></script>
    <script>
            
// Initialize KaTeX rendering - ensure KaTeX is loaded first
        function initKaTeX() {
            if (typeof katex !== 'undefined' && typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "\\[", right: "\\]", display: true},
                        {left: "$", right: "$", display: false},
                        {left: "\\(", right: "\\)", display: false}
                    ],
                    throwOnError: false
                });
            } else {
                // Retry if KaTeX not loaded yet
                setTimeout(initKaTeX, 100);
                return;
            }
            
            // Initialize Prism.js syntax highlighting
            if (typeof Prism !== 'undefined') {
                Prism.highlightAll();
            }
        }
        
        // Wait for DOM and KaTeX to be ready
        if (document.readyState === 'loading') {
            document.addEventListener("DOMContentLoaded", initKaTeX);
        } else {
            // DOM already loaded, wait for KaTeX
            initKaTeX();
    </script>
</body>
</html>