<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 7: Production RAG Systems - RAG & Retrieval Systems</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/rag/rag.css') }}">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>


</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav">
            <div class="azbn-container">
                <a href="/tutorials/rag" class="course-link">
                    <span>RAG & Retrieval Systems</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <div class="tutorial-header">
            <div class="azbn-container">
                <h1 class="chapter-title">Chapter 7: Production RAG Systems</h1>
                <p class="chapter-subtitle">Deployment & Monitoring</p>
                
                <div class="chapter-progress">
                    <div class="chapter-progress-fill" data-progress="100"></div>
                </div>
                
                <div class="chapter-navigation">
                    <a href="/tutorials/rag/chapter1" class="chapter-nav-btn ">Chapter 1</a>
                    <a href="/tutorials/rag/chapter2" class="chapter-nav-btn ">Chapter 2</a>
                    <a href="/tutorials/rag/chapter3" class="chapter-nav-btn ">Chapter 3</a>
                    <a href="/tutorials/rag/chapter4" class="chapter-nav-btn ">Chapter 4</a>
                    <a href="/tutorials/rag/chapter5" class="chapter-nav-btn ">Chapter 5</a>
                    <a href="/tutorials/rag/chapter6" class="chapter-nav-btn ">Chapter 6</a>
                    <a href="/tutorials/rag/chapter7" class="chapter-nav-btn active">Chapter 7</a>
                </div>
                
                <div class="section-progress">
                    <div class="section-progress-fill" data-progress="14.3"></div>
                </div>
                
                <div class="section-nav">
                    <button class="section-nav-btn azbn-btn active" data-section="overview">Overview</button>
                    <button class="section-nav-btn azbn-btn" data-section="concepts">Key Concepts</button>
                    <button class="section-nav-btn azbn-btn" data-section="formulas">Formulas</button>
                    <button class="section-nav-btn azbn-btn" data-section="examples">Examples</button>
                    <button class="section-nav-btn azbn-btn" data-section="implementation">Implementation</button>
                    <button class="section-nav-btn azbn-btn" data-section="applications">Applications</button>
                    <button class="section-nav-btn azbn-btn" data-section="quiz">Quiz</button>
                </div>
            </div>
        </div>

        <section class="azbn-section">
            <div class="azbn-container">
                <div class="learning-objectives-box">
                    <h2>Learning Objectives</h2>
                    <ul>
                        <li>Understand production rag systems fundamentals</li>
                        <li>Master the mathematical foundations</li>
                        <li>Learn practical implementation</li>
                        <li>Apply knowledge through examples</li>
                        <li>Recognize real-world applications</li>
                    </ul>
                </div>

                <main class="chapter-main-content">
                    <div id="overview" class="content-section active">
                        <h2>Production RAG Systems</h2>
                        
                        <div class="explanation-box">
                            <h3>Introduction</h3>
                            <p><strong>Deployment & Monitoring</strong></p>
                            <p>This chapter provides comprehensive coverage of production rag systems, including detailed explanations, mathematical formulations, code implementations, and real-world examples.</p>
                        </div>

                        <div class="example-box">
                            <h4>üìö Why This Matters</h4>
                            <p>Understanding production rag systems is crucial for mastering modern AI systems. This chapter breaks down complex concepts into digestible explanations with step-by-step examples.</p>
                        </div>
                    </div>

                    <div id="concepts" class="content-section">
                        <h2>Key Concepts</h2>
                        
                        <div class="explanation-box">
                            <h3>Production RAG Considerations</h3>
                            <p><strong>Scalability:</strong></p>
                            <ul>
                                <li>Handle millions of documents</li>
                                <li>Fast retrieval (sub-second latency)</li>
                                <li>Efficient embedding storage</li>
                                <li>Horizontal scaling for high traffic</li>
                            </ul>
                            
                            <p><strong>Monitoring and evaluation:</strong></p>
                            <ul>
                                <li>Track retrieval quality (precision, recall)</li>
                                <li>Monitor answer quality (faithfulness, relevance)</li>
                                <li>Log queries and responses</li>
                                <li>Alert on quality degradation</li>
                            </ul>
                            
                            <p><strong>Error handling:</strong></p>
                            <ul>
                                <li>Handle retrieval failures gracefully</li>
                                <li>Fallback when no relevant docs found</li>
                                <li>Validate retrieved context quality</li>
                                <li>Retry mechanisms for transient failures</li>
                            </ul>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Performance Optimization</h3>
                            <p><strong>Caching:</strong> Cache embeddings and retrieval results for common queries.</p>
                            
                            <p><strong>Batch processing:</strong> Process multiple queries together for efficiency.</p>
                            
                            <p><strong>Async operations:</strong> Parallelize retrieval and generation when possible.</p>
                            
                            <p><strong>Model selection:</strong> Balance quality vs latency (smaller models for faster responses).</p>
                        </div>
                    </div>

                    <div id="formulas" class="content-section">
                        <h2>Mathematical Formulations</h2>
                        
                        <div class="formula-box">
                            <h4>Key Formulas</h4>
                            <div class="formula-display">
                                \[\text{Retrieval\_Precision@k} = \frac{|\{\text{relevant docs}\} \cap \{\text{retrieved top-k}\}|}{k}\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(\text{relevant docs}\): Documents actually relevant to query</li>
                                    <li>\(\text{retrieved top-k}\): Top-k documents retrieved</li>
                                    <li>Measures fraction of retrieved docs that are relevant</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Retrieval Recall</h4>
                            <div class="formula-display">
                                \[\text{Retrieval\_Recall@k} = \frac{|\{\text{relevant docs}\} \cap \{\text{retrieved top-k}\}|}{|\{\text{relevant docs}\}|}\]
                            </div>
                            <div class="formula-explanation">
                                <p>Measures fraction of relevant documents that were retrieved. Higher recall = fewer missed relevant docs.</p>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Answer Faithfulness</h4>
                            <div class="formula-display">
                                \[\text{Faithfulness} = \frac{|\{\text{claims in answer}\} \cap \{\text{claims in context}\}|}{|\{\text{claims in answer}\}|}\]
                            </div>
                            <div class="formula-explanation">
                                <p>Fraction of answer claims that are supported by context. Measures grounding quality.</p>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Answer Relevance</h4>
                            <div class="formula-display">
                                \[\text{Relevance} = \text{similarity}(E(\text{query}), E(\text{answer}))\]
                            </div>
                            <div class="formula-explanation">
                                <p>Semantic similarity between query and answer. Higher similarity = more relevant answer.</p>
                            </div>
                            </div>
                        </div>
                    </div>

                    <div id="examples" class="content-section">
                        <h2>Detailed Examples</h2>
                        
                        <div class="example-box">
                            <h4>Step-by-Step Examples</h4>
                            <h4>Example: Evaluating Retrieval</h4>
                            <p><strong>Query:</strong> "What is Python?"</p>
                            
                            <p><strong>Relevant documents:</strong> ["Python is a programming language", "Python tutorial"]</p>
                            
                            <p><strong>Retrieved top-3:</strong> ["Python is a programming language", "Java tutorial", "Python tutorial"]</p>
                            
                            <p><strong>Precision@3:</strong> 2/3 = 0.67 (2 relevant out of 3 retrieved)</p>
                            <p><strong>Recall@3:</strong> 2/2 = 1.0 (all relevant docs retrieved)</p>
                        </div>
                        
                        <div class="example-box">
                            <h4>Example: Evaluating Generation</h4>
                            <p><strong>Query:</strong> "What is the capital of France?"</p>
                            <p><strong>Context:</strong> "France is a country. Its capital is Paris."</p>
                            <p><strong>Generated answer:</strong> "The capital of France is Paris."</p>
                            
                            <p><strong>Faithfulness:</strong> 1.0 (answer fully supported by context)</p>
                            <p><strong>Relevance:</strong> 0.95 (high semantic similarity to query)</p>
                            <p><strong>Completeness:</strong> 1.0 (answer is complete)</p>
                        </div>
                    </div>

                    <div id="implementation" class="content-section">
                        <h2>Implementation</h2>
                        
                        <div class="code-box">
                            <h4>RAG Evaluation Metrics</h4>
                            <pre><code class="language-python">def evaluate_retrieval(relevant_docs, retrieved_docs, k=10):
    """
    Evaluate retrieval quality
    """
    # Precision@k
    relevant_retrieved = len(set(relevant_docs) & set(retrieved_docs[:k]))
    precision = relevant_retrieved / k
    
    # Recall@k
    recall = relevant_retrieved / len(relevant_docs) if relevant_docs else 0
    
    # F1 score
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    return {
        'precision@k': precision,
        'recall@k': recall,
        'f1@k': f1
    }

def evaluate_answer_faithfulness(answer, context):
    """
    Check if answer claims are supported by context
    """
    # Extract claims from answer (simplified)
    answer_claims = extract_claims(answer)
    context_claims = extract_claims(context)
    
    # Check how many answer claims are in context
    supported = len(set(answer_claims) & set(context_claims))
    faithfulness = supported / len(answer_claims) if answer_claims else 0
    
    return faithfulness

# Example usage
relevant = ['doc1', 'doc2', 'doc3']
retrieved = ['doc1', 'doc4', 'doc2', 'doc5']
metrics = evaluate_retrieval(relevant, retrieved, k=3)
print(metrics)</code></pre>
                        </div>
                        
                        <div class="code-box">
                            <h4>Production RAG with Error Handling</h4>
                            <pre><code class="language-python">class ProductionRAG:
    """Production-ready RAG with error handling"""
    
    def __init__(self, embedder, vector_db, llm):
        self.embedder = embedder
        self.vector_db = vector_db
        self.llm = llm
        self.cache = {}
    
    def query(self, question, top_k=5, use_cache=True):
        """Query with error handling and caching"""
        try:
            # Check cache
            if use_cache and question in self.cache:
                return self.cache[question]
            
            # Retrieve
            contexts = self.retrieve(question, top_k)
            
            if not contexts:
                return "I couldn't find relevant information to answer your question."
            
            # Generate
            answer = self.generate(question, contexts)
            
            # Cache result
            if use_cache:
                self.cache[question] = answer
            
            return answer
            
        except Exception as e:
            # Log error
            print(f"Error in RAG query: {e}")
            return "I encountered an error processing your question. Please try again."
    
    def retrieve(self, question, top_k):
        """Retrieve with fallback"""
        try:
            query_embedding = self.embedder.encode([question])
            results = self.vector_db.search(query_embedding, top_k=top_k)
            return [r['text'] for r in results if r['score'] > 0.7]  # Threshold
        except:
            return []
    
    def generate(self, question, contexts):
        """Generate with context validation"""
        if not contexts:
            return "No relevant context found."
        
        prompt = f"Context: {' '.join(contexts)}\n\nQuestion: {question}\nAnswer:"
        return self.llm.generate(prompt)</code></pre>
                        </div>
                    </div>

                    <div id="applications" class="content-section">
                        <h2>Real-World Applications</h2>
                        
                        <div class="explanation-box">
                            <h3>Production RAG Systems</h3>
                            <p><strong>Enterprise knowledge bases:</strong></p>
                            <ul>
                                <li>Internal documentation search (Confluence, Notion)</li>
                                <li>Company policy Q&A systems</li>
                                <li>Technical support knowledge bases</li>
                            </ul>
                            
                            <p><strong>Customer-facing applications:</strong></p>
                            <ul>
                                <li>E-commerce product Q&A</li>
                                <li>FAQ chatbots</li>
                                <li>Help center assistants</li>
                            </ul>
                            
                            <p><strong>Research and analysis:</strong></p>
                            <ul>
                                <li>Legal document analysis systems</li>
                                <li>Medical literature Q&A</li>
                                <li>Academic paper search and summarization</li>
                            </ul>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Best Practices</h3>
                            <p><strong>Deployment:</strong> Use managed vector databases, implement caching, monitor performance</p>
                            <p><strong>Quality:</strong> Regular evaluation, A/B testing, continuous improvement</p>
                            <p><strong>Reliability:</strong> Error handling, fallbacks, retries, graceful degradation</p>
                            <p><strong>Security:</strong> Access control, data privacy, input validation</p>
                        </div>
                    </div>

                    <div id="quiz" class="content-section">
                        <h2>Test Your Understanding</h2>
                        
                        <div class="quiz-container">
                            <div class="quiz-question">
                                <h3>Question 1: Interview question: "What are the key considerations for production RAG systems?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Scalability (millions of docs, high traffic), monitoring (retrieval/answer quality), error handling (fallbacks, retries), performance optimization (caching, async), and reliability (99.9%+ uptime)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only speed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only cost</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) No special considerations</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 2: What is retrieval precision@k and how is it calculated?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) \(\frac{|\{\text{relevant docs}\} \cap \{\text{retrieved top-k}\}|}{k}\) - fraction of retrieved top-k documents that are actually relevant</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Total number of documents</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Average similarity score</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Retrieval speed</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 3: Interview question: "How do you monitor RAG system quality in production?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Track retrieval metrics (precision@k, recall@k), answer quality (faithfulness, relevance), log queries/responses, set up alerts for quality degradation, and use A/B testing</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only check errors</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) No monitoring needed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Only check once</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 4: What is answer faithfulness and why is it important?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Fraction of answer claims supported by retrieved context. Measures grounding quality - ensures answers are based on documents, not hallucinated</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Answer length</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Answer speed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Answer cost</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 5: Interview question: "How would you scale a RAG system to handle millions of documents?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Use distributed vector databases, implement sharding, use efficient indexing (HNSW), implement caching, use approximate search (ANN), and optimize embedding storage</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Use single server</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) No scaling needed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Only vertical scaling</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 6: What is the difference between precision@k and recall@k?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Precision@k: fraction of retrieved docs that are relevant. Recall@k: fraction of relevant docs that were retrieved. Precision measures quality, recall measures coverage</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) They are the same</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Precision is speed, recall is accuracy</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) No difference</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 7: Interview question: "How do you handle errors in production RAG systems?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Implement graceful fallbacks (return "no relevant info found"), retry mechanisms for transient failures, validate retrieved context quality, log errors for debugging, and use circuit breakers for downstream services</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Stop the system</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Ignore errors</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Return empty response</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 8: What is answer relevance and how is it measured?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Semantic similarity between query and answer embeddings. Measures how well the answer addresses the query. Higher similarity = more relevant</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Answer length</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Number of documents used</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Retrieval speed</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 9: Interview question: "How do you optimize RAG system performance?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Cache embeddings and retrieval results, use batch processing, implement async operations, optimize model selection (balance quality/latency), use approximate search, and implement connection pooling</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only use faster models</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only use more servers</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) No optimization possible</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 10: What is the formula for retrieval recall@k?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) \(\frac{|\{\text{relevant docs}\} \cap \{\text{retrieved top-k}\}|}{|\{\text{relevant docs}\}|}\) - fraction of all relevant documents that were retrieved in top-k</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Total documents retrieved</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Average similarity</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Retrieval time</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 11: Interview question: "How do you ensure RAG system reliability in production?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Implement comprehensive error handling, fallback mechanisms, retry logic with exponential backoff, health checks, monitoring/alerting, graceful degradation, and redundancy for critical components</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) No error handling needed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only check once</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Manual monitoring only</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 12: Interview question: "What metrics would you track for a production RAG system?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Retrieval metrics (precision@k, recall@k, MRR), answer quality (faithfulness, relevance, completeness), latency (retrieval time, generation time), cost (API calls, tokens), error rates, and user satisfaction</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only speed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only cost</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) No metrics needed</div>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </section>
    </main>

    <footer style="background: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 2px solid #5B7553;">
        <div class="azbn-container" style="text-align: center;">
            <button onclick="scrollToSectionNav()" class="azbn-btn" style="margin: 0.5rem;">
                ‚Üë Back to Section Navigation
            </button>
            <div style="margin-top: 1.5rem;">
                <a href="/tutorials/rag" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Back to Tutorial</a>
                <a href="/tutorials/rag/chapter6" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Chapter 6</a>
                
            </div>
        </div>
    </footer>
    
        <!-- KaTeX for math rendering -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
<script src="{{ url_for('static', filename='js/tutorials/rag/shared-tutorial.js') }}"></script>
    <script>
        function checkAnswer(element, isCorrect) {
            element.parentNode.querySelectorAll('.quiz-option').forEach(opt => {
                opt.classList.remove('correct', 'incorrect');
            });
            if (isCorrect) {
                element.classList.add('correct');
                element.textContent += ' ‚úì Correct!';
            } else {
                element.classList.add('incorrect');
                element.textContent += ' ‚úó Incorrect';
                const correctOption = Array.from(element.parentNode.querySelectorAll('.quiz-option'))
                    .find(opt => {
                        const onclick = opt.getAttribute('onclick') || '';
                        return onclick.includes('true');
                    });
                if (correctOption && !correctOption.classList.contains('incorrect')) {
                    correctOption.classList.add('correct');
                    correctOption.textContent += ' ‚úì Correct Answer';
                }
            }
        }
            
// Initialize KaTeX rendering - ensure KaTeX is loaded first
        function initKaTeX() {
            if (typeof katex !== 'undefined' && typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "\\[", right: "\\]", display: true},
                        {left: "$", right: "$", display: false},
                        {left: "\\(", right: "\\)", display: false}
                    ],
                    throwOnError: false
                });
            } else {
                // Retry if KaTeX not loaded yet
                setTimeout(initKaTeX, 100);
                return;
            }
            
            // Initialize Prism.js syntax highlighting
            if (typeof Prism !== 'undefined') {
                Prism.highlightAll();
            }
        }
        
        // Wait for DOM and KaTeX to be ready
        if (document.readyState === 'loading') {
            document.addEventListener("DOMContentLoaded", initKaTeX);
        } else {
            // DOM already loaded, wait for KaTeX
            initKaTeX();
