<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 4: Vector Databases - RAG & Retrieval Systems</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}?v=2">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/rag/rag.css') }}?v=3">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>


</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav">
            <div class="azbn-container">
                <a href="/tutorials/rag" class="course-link">
                    <span>RAG & Retrieval Systems</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <div class="tutorial-header">
            <div class="azbn-container">
                <h1 class="chapter-title">Chapter 4: Vector Databases</h1>
                <p class="chapter-subtitle">Storing and Searching Embeddings</p>
                
                <div class="chapter-progress">
                    <div class="chapter-progress-fill" data-progress="57"></div>
                </div>
                
                <div class="chapter-navigation">
                    <a href="/tutorials/rag/chapter1" class="chapter-nav-btn ">Chapter 1</a>
                    <a href="/tutorials/rag/chapter2" class="chapter-nav-btn ">Chapter 2</a>
                    <a href="/tutorials/rag/chapter3" class="chapter-nav-btn ">Chapter 3</a>
                    <a href="/tutorials/rag/chapter4" class="chapter-nav-btn active">Chapter 4</a>
                    <a href="/tutorials/rag/chapter5" class="chapter-nav-btn ">Chapter 5</a>
                    <a href="/tutorials/rag/chapter6" class="chapter-nav-btn ">Chapter 6</a>
                    <a href="/tutorials/rag/chapter7" class="chapter-nav-btn ">Chapter 7</a>
                </div>
                
                <div class="section-progress">
                    <div class="section-progress-fill" data-progress="14.3"></div>
                </div>
                
                <div class="section-nav">
                    <button class="section-nav-btn azbn-btn active" data-section="overview">Overview</button>
                    <button class="section-nav-btn azbn-btn" data-section="concepts">Key Concepts</button>
                    <button class="section-nav-btn azbn-btn" data-section="formulas">Formulas</button>
                    <button class="section-nav-btn azbn-btn" data-section="examples">Examples</button>
                    <button class="section-nav-btn azbn-btn" data-section="implementation">Implementation</button>
                    <button class="section-nav-btn azbn-btn" data-section="applications">Applications</button>
                    <button class="section-nav-btn azbn-btn" data-section="quiz">Quiz</button>
                </div>
            </div>
        </div>

        <section class="azbn-section">
            <div class="azbn-container">
                <div class="learning-objectives-box">
                    <h2>Learning Objectives</h2>
                    <ul>
                        <li>Understand vector databases fundamentals</li>
                        <li>Master the mathematical foundations</li>
                        <li>Learn practical implementation</li>
                        <li>Apply knowledge through examples</li>
                        <li>Recognize real-world applications</li>
                    </ul>
                </div>

                <main class="chapter-main-content">
                    <div id="overview" class="content-section active">
                        <h2>Vector Databases</h2>
                        
                        <div class="explanation-box">
                            <h3>Why Vector Databases are Essential for RAG</h3>
                            <p>Once you've created embeddings for your documents, you need to store them somewhere and search through them efficiently. A traditional database (like PostgreSQL or MySQL) is designed for exact matches and structured queries, not for finding "similar" vectors. <strong>Vector databases</strong> are specialized databases optimized for storing and searching high-dimensional vectors using similarity metrics like cosine similarity.</p>
                            
                            <p><strong>The scale problem:</strong> In production RAG systems, you might have millions or billions of document chunks, each with a 384-1536 dimensional embedding vector. Searching through all of them to find the most similar to a query vector would take hours using brute-force methods. Vector databases use sophisticated indexing algorithms (like HNSW, IVF, or LSH) to enable <strong>sub-millisecond</strong> similarity search even across billions of vectors.</p>
                            
                            <h4>What Vector Databases Provide</h4>
                            <ul>
                                <li><strong>Fast Similarity Search:</strong> Find top-k most similar vectors in milliseconds, even with millions of documents</li>
                                <li><strong>Scalable Storage:</strong> Efficiently store and index billions of high-dimensional vectors</li>
                                <li><strong>Metadata Filtering:</strong> Combine vector similarity search with traditional filters (date, category, author, etc.)</li>
                                <li><strong>Real-time Updates:</strong> Add, update, or delete vectors without rebuilding entire indexes</li>
                                <li><strong>Approximate Nearest Neighbor (ANN):</strong> Trade some accuracy for massive speed improvements (1000-10000x faster than exact search)</li>
                            </ul>
                            
                            <div class="example-box">
                                <h5>Performance Comparison:</h5>
                                <p><strong>Brute-force search (NumPy):</strong> To find top-5 most similar vectors among 1 million documents:</p>
                                <ul>
                                    <li>❌ Compute 1 million cosine similarities: ~16 minutes</li>
                                    <li>❌ Sort results: Additional time</li>
                                    <li>❌ Total: ~16+ minutes per query (completely impractical)</li>
                                </ul>
                                <p><strong>Vector database (HNSW index):</strong> Same task:</p>
                                <ul>
                                    <li>✅ Find top-5 similar vectors: 50-200 milliseconds</li>
                                    <li>✅ Speedup: ~5,000-20,000x faster!</li>
                                    <li>✅ Enables real-time RAG systems</li>
                                </ul>
                            </div>
                        </div>

                        <div class="explanation-box">
                            <h3>Key Concepts You'll Learn</h3>
                            <ul>
                                <li><strong>Indexing Algorithms:</strong> HNSW (Hierarchical Navigable Small World), IVF (Inverted File Index), Product Quantization, and LSH - how they work and when to use each</li>
                                <li><strong>Vector Database Options:</strong> Pinecone, Weaviate, Chroma, Qdrant, FAISS, Milvus - comparing features, performance, and use cases</li>
                                <li><strong>Metadata Filtering:</strong> Combining vector similarity search with traditional database filters for precise retrieval</li>
                                <li><strong>Exact vs Approximate Search:</strong> Understanding the trade-offs between accuracy and speed</li>
                                <li><strong>Scaling Strategies:</strong> Sharding, distributed indexing, and optimization techniques for billion-scale systems</li>
                                <li><strong>Production Considerations:</strong> Update strategies, index maintenance, and performance monitoring</li>
                            </ul>
                            
                            <p><strong>Why this matters:</strong> Vector databases are the infrastructure that makes RAG systems practical at scale. Without them, you're limited to small document collections or unacceptably slow query times. Choosing the right vector database and indexing strategy directly impacts your RAG system's performance, cost, and scalability.</p>
                        </div>
                    </div>

                    <div id="concepts" class="content-section">
                        <h2>Key Concepts</h2>
                        
                        <div class="explanation-box">
                            <h3>Vector Database Indexing Strategies: How Fast Retrieval Works</h3>
                            
                            <p>Vector databases use sophisticated indexing algorithms to enable fast similarity search across millions of vectors. Understanding these indexing strategies is crucial for choosing the right database and optimizing performance.</p>
                            
                            <h4>1. HNSW (Hierarchical Navigable Small World)</h4>
                            <p><strong>What it is:</strong> HNSW is one of the most popular and effective indexing algorithms for approximate nearest neighbor (ANN) search. It builds a multi-layer graph where each layer is a subset of the previous layer, creating a "small world" network that allows efficient navigation.</p>
                            
                            <p><strong>How it works:</strong></p>
                            <ul>
                                <li><strong>Multi-layer structure:</strong> Creates multiple layers (levels) of graphs, with the top layer having few nodes and bottom layer having all nodes</li>
                                <li><strong>Greedy search:</strong> Starts at the top layer, finds the nearest neighbor, then moves to the next layer and continues</li>
                                <li><strong>Small world property:</strong> Each node is connected to a small number of "long-range" connections, allowing fast navigation across the graph</li>
                                <li><strong>Dynamic insertion:</strong> New vectors can be added without rebuilding the entire index</li>
                            </ul>
                            
                            <p><strong>Advantages:</strong></p>
                            <ul>
                                <li>✅ <strong>Very fast:</strong> Sub-millisecond search times even for millions of vectors</li>
                                <li>✅ <strong>High accuracy:</strong> Can achieve 95%+ recall (finds 95% of true nearest neighbors)</li>
                                <li>✅ <strong>Scalable:</strong> Works well with billions of vectors</li>
                                <li>✅ <strong>Used by major databases:</strong> Pinecone, Weaviate, Qdrant all use HNSW variants</li>
                            </ul>
                            
                            <p><strong>Trade-offs:</strong></p>
                            <ul>
                                <li>⚠️ <strong>Memory intensive:</strong> Stores the graph structure in memory (though can be optimized)</li>
                                <li>⚠️ <strong>Indexing time:</strong> Building the index takes time, though it's a one-time cost</li>
                            </ul>
                            
                            <p><strong>When to use:</strong> For production RAG systems where speed and accuracy are critical. This is the default choice for most vector databases.</p>
                            
                            <h4>2. IVF (Inverted File Index)</h4>
                            <p><strong>What it is:</strong> IVF partitions the vector space into clusters (Voronoi cells) and creates an inverted index mapping each cluster to its vectors.</p>
                            
                            <p><strong>How it works:</strong></p>
                            <ul>
                                <li><strong>Clustering:</strong> Uses k-means or similar to partition vectors into clusters</li>
                                <li><strong>Inverted index:</strong> For each cluster, stores a list of vectors belonging to that cluster</li>
                                <li><strong>Search:</strong> Finds the nearest cluster(s) to the query vector, then searches only within those clusters</li>
                            </ul>
                            
                            <p><strong>Advantages:</strong></p>
                            <ul>
                                <li>✅ <strong>Memory efficient:</strong> Lower memory footprint than HNSW</li>
                                <li>✅ <strong>Fast for large datasets:</strong> Only searches relevant clusters, not all vectors</li>
                                <li>✅ <strong>Used by FAISS:</strong> FAISS's IVF-Flat and IVF-PQ use this approach</li>
                            </ul>
                            
                            <p><strong>Trade-offs:</strong></p>
                            <ul>
                                <li>⚠️ <strong>Lower accuracy:</strong> May miss vectors near cluster boundaries</li>
                                <li>⚠️ <strong>Requires tuning:</strong> Number of clusters needs careful selection</li>
                            </ul>
                            
                            <p><strong>When to use:</strong> For very large datasets (billions of vectors) where memory is a constraint, or when using FAISS.</p>
                            
                            <h4>3. Product Quantization (PQ)</h4>
                            <p><strong>What it is:</strong> A compression technique that reduces vector storage by quantizing (discretizing) vector components into a smaller number of values.</p>
                            
                            <p><strong>How it works:</strong></p>
                            <ul>
                                <li><strong>Vector splitting:</strong> Splits each vector into multiple sub-vectors</li>
                                <li><strong>Quantization:</strong> Each sub-vector is mapped to a "codebook" (set of representative vectors)</li>
                                <li><strong>Compression:</strong> Stores only the codebook indices, not full vectors</li>
                                <li><strong>Fast distance:</strong> Uses lookup tables for fast approximate distance calculations</li>
                            </ul>
                            
                            <p><strong>Advantages:</strong></p>
                            <ul>
                                <li>✅ <strong>Massive storage reduction:</strong> Can reduce storage by 10-100x</li>
                                <li>✅ <strong>Fast search:</strong> Approximate distances computed quickly using lookup tables</li>
                                <li>✅ <strong>Enables billion-scale:</strong> Makes it feasible to store billions of vectors</li>
                            </ul>
                            
                            <p><strong>Trade-offs:</strong></p>
                            <ul>
                                <li>⚠️ <strong>Accuracy loss:</strong> Compression introduces approximation errors</li>
                                <li>⚠️ <strong>Training required:</strong> Codebooks need to be trained on representative data</li>
                            </ul>
                            
                            <p><strong>When to use:</strong> For extremely large datasets where storage is a primary concern. Often combined with IVF (IVF-PQ).</p>
                            
                            <h4>4. LSH (Locality-Sensitive Hashing)</h4>
                            <p><strong>What it is:</strong> Uses hash functions that map similar vectors to the same hash buckets, enabling fast approximate search.</p>
                            
                            <p><strong>How it works:</strong></p>
                            <ul>
                                <li><strong>Hash functions:</strong> Creates multiple hash functions that preserve similarity (similar vectors hash to same bucket)</li>
                                <li><strong>Bucketing:</strong> Vectors are placed into hash buckets</li>
                                <li><strong>Search:</strong> Query vector is hashed, then only vectors in the same bucket(s) are searched</li>
                            </ul>
                            
                            <p><strong>Advantages:</strong></p>
                            <ul>
                                <li>✅ <strong>Very fast:</strong> Constant-time hash lookup</li>
                                <li>✅ <strong>Simple:</strong> Easy to understand and implement</li>
                            </ul>
                            
                            <p><strong>Trade-offs:</strong></p>
                            <ul>
                                <li>⚠️ <strong>Lower accuracy:</strong> May miss some similar vectors</li>
                                <li>⚠️ <strong>Parameter tuning:</strong> Number of hash functions and buckets needs tuning</li>
                            </ul>
                            
                            <p><strong>When to use:</strong> For very fast, approximate search when some accuracy loss is acceptable. Less common in modern RAG systems.</p>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Metadata Filtering: Combining Vector Search with Traditional Filters</h3>
                            
                            <p>Real-world RAG systems often need to filter documents by metadata (date, author, category, etc.) in addition to semantic similarity. Vector databases support this through <strong>metadata filtering</strong>.</p>
                            
                            <h4>How Metadata Filtering Works</h4>
                            <p><strong>Two-stage process:</strong></p>
                            <ol>
                                <li><strong>Filter first:</strong> Apply metadata filters to reduce the search space (e.g., "only documents from 2023")</li>
                                <li><strong>Search in filtered set:</strong> Perform vector similarity search only on the filtered documents</li>
                            </ol>
                            
                            <p><strong>Example:</strong></p>
                            <div class="example-box">
                                <h5>Query with Metadata Filtering</h5>
                                <p><strong>Query:</strong> "machine learning best practices"</p>
                                <p><strong>Metadata filters:</strong> 
                                    <ul>
                                        <li>Category = "Technical Blog"</li>
                                        <li>Date >= "2023-01-01"</li>
                                        <li>Author = "John Doe"</li>
                                    </ul>
                                </p>
                                <p><strong>Process:</strong></p>
                                <ol>
                                    <li>Filter 1M documents → 50K documents matching metadata</li>
                                    <li>Vector search in 50K documents → Top 5 most similar</li>
                                </ol>
                                <p>✅ Much faster than searching all 1M documents!</p>
                            </div>
                            
                            <h4>Types of Metadata Filters</h4>
                            <ul>
                                <li><strong>Equality filters:</strong> <code>author = "John Doe"</code></li>
                                <li><strong>Range filters:</strong> <code>date >= "2023-01-01" AND date <= "2023-12-31"</code></li>
                                <li><strong>In filters:</strong> <code>category IN ["Tech", "Science"]</code></li>
                                <li><strong>Boolean combinations:</strong> <code>(category = "Tech" OR category = "Science") AND date >= "2023"</code></li>
                            </ul>
                            
                            <h4>Benefits of Metadata Filtering</h4>
                            <ul>
                                <li>✅ <strong>Faster search:</strong> Reduces the number of vectors to search</li>
                                <li>✅ <strong>More relevant results:</strong> Ensures results match business constraints</li>
                                <li>✅ <strong>Better user experience:</strong> Users can narrow down by date, source, etc.</li>
                                <li>✅ <strong>Compliance:</strong> Can filter by access permissions, data retention policies</li>
                            </ul>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Vector Database Operations: Indexing, Querying, and Maintenance</h3>
                            
                            <h4>1. Indexing (One-Time Setup)</h4>
                            <p><strong>What happens:</strong> When you add documents to a vector database, they go through an indexing process:</p>
                            
                            <ol>
                                <li><strong>Embedding generation:</strong> Each document chunk is converted to a vector using an embedding model</li>
                                <li><strong>Metadata extraction:</strong> Extract and store metadata (title, date, author, etc.)</li>
                                <li><strong>Index building:</strong> Vector is inserted into the index structure (HNSW, IVF, etc.)</li>
                                <li><strong>Storage:</strong> Vector, metadata, and original text are stored</li>
                            </ol>
                            
                            <p><strong>Performance considerations:</strong></p>
                            <ul>
                                <li>⚠️ <strong>Indexing is slow:</strong> Building indexes takes time (minutes to hours for large datasets)</li>
                                <li>⚠️ <strong>Batch processing:</strong> More efficient to index in batches rather than one-by-one</li>
                                <li>⚠️ <strong>Incremental updates:</strong> Some databases support adding vectors without rebuilding (HNSW), others require full rebuild (IVF)</li>
                            </ul>
                            
                            <h4>2. Querying (Per-Request)</h4>
                            <p><strong>What happens:</strong> When a user query arrives:</p>
                            
                            <ol>
                                <li><strong>Query embedding:</strong> Convert query to vector using the same embedding model</li>
                                <li><strong>Metadata filtering (optional):</strong> Apply metadata filters to reduce search space</li>
                                <li><strong>Vector search:</strong> Use the index to find top-k most similar vectors</li>
                                <li><strong>Result retrieval:</strong> Return document IDs, metadata, and similarity scores</li>
                                <li><strong>Document fetching:</strong> Retrieve actual document text using IDs</li>
                            </ol>
                            
                            <p><strong>Performance considerations:</strong></p>
                            <ul>
                                <li>✅ <strong>Very fast:</strong> Sub-100ms for millions of vectors with good indexes</li>
                                <li>✅ <strong>Scalable:</strong> Query time grows slowly with dataset size (logarithmic for HNSW)</li>
                                <li>⚠️ <strong>First query slower:</strong> May need to load index into memory</li>
                            </ul>
                            
                            <h4>3. Maintenance Operations</h4>
                            <p><strong>Index updates:</strong> When documents are added, updated, or deleted:</p>
                            <ul>
                                <li><strong>Add:</strong> Insert new vector into index (fast for HNSW, may require rebuild for IVF)</li>
                                <li><strong>Update:</strong> Delete old vector, insert new one (or update in-place if supported)</li>
                                <li><strong>Delete:</strong> Remove vector from index (mark as deleted or physically remove)</li>
                            </ul>
                            
                            <p><strong>Index optimization:</strong></p>
                            <ul>
                                <li><strong>Rebuilding:</strong> Periodically rebuild index to optimize structure (especially for IVF)</li>
                                <li><strong>Compaction:</strong> Remove deleted vectors and optimize storage</li>
                                <li><strong>Monitoring:</strong> Track index size, query performance, accuracy metrics</li>
                            </ul>
                        </div>
                    </div>

                    <div id="formulas" class="content-section">
                        <h2>Mathematical Formulations</h2>
                        
                        <div class="explanation-box">
                            <h3>Vector Database Performance Metrics</h3>
                            <p>Vector databases use sophisticated indexing algorithms to enable fast similarity search. Understanding the mathematical foundations helps you choose the right database, configure indexes, and optimize performance. These formulas describe how vector databases achieve sub-millisecond search times even with millions of vectors.</p>
                        </div>
                        
                        <div class="formula-box">
                            <h4>1. HNSW Search Complexity</h4>
                            <div class="formula-display">
                                \[T_{\text{search}} = O(\log N)\]
                            </div>
                            <div class="formula-explanation">
                                <h5>What This Represents:</h5>
                                <p>HNSW (Hierarchical Navigable Small World) achieves logarithmic search time complexity, meaning search time grows very slowly as the number of vectors increases. This is why it can search millions of vectors in milliseconds.</p>
                                
                                <h5>Breaking It Down:</h5>
                                <ul>
                                    <li><strong>\(T_{\text{search}}\):</strong> Time complexity of search operation</li>
                                    <li><strong>\(O(\log N)\):</strong> Big-O notation indicating logarithmic time complexity</li>
                                    <li><strong>\(N\):</strong> Number of vectors in the database</li>
                                </ul>
                                
                                <h5>What Logarithmic Means:</h5>
                                <p>If you double the number of vectors, search time increases by a constant amount (not doubled). For example:</p>
                                <ul>
                                    <li>1,000 vectors: ~10 operations</li>
                                    <li>10,000 vectors: ~13 operations (only 30% more!)</li>
                                    <li>1,000,000 vectors: ~20 operations (only 100% more for 1000x more data!)</li>
                                </ul>
                                
                                <h5>Comparison to Brute-Force:</h5>
                                <p><strong>Brute-force:</strong> \(O(N)\) - linear time. To search 1M vectors, you must compare query with all 1M vectors.</p>
                                <p><strong>HNSW:</strong> \(O(\log N)\) - logarithmic time. To search 1M vectors, you only need ~20 comparisons by navigating the graph structure.</p>
                                
                                <h5>Why HNSW is Fast:</h5>
                                <p>HNSW builds a multi-layer graph where each layer has fewer nodes. Search starts at the top (few nodes), finds approximate location, then refines in lower layers. This hierarchical approach dramatically reduces comparisons needed.</p>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>2. IVF Cluster Search Reduction</h4>
                            <div class="formula-display">
                                \[T_{\text{search}} = O(\sqrt{N} + k)\]
                            </div>
                            <div class="formula-explanation">
                                <h5>What This Represents:</h5>
                                <p>IVF (Inverted File Index) partitions vectors into clusters. Instead of searching all \(N\) vectors, you only search within the nearest cluster(s), dramatically reducing search space.</p>
                                
                                <h5>Breaking It Down:</h5>
                                <ul>
                                    <li><strong>\(O(\sqrt{N})\):</strong> Time to find the nearest cluster(s) - grows with square root of N</li>
                                    <li><strong>\(O(k)\):</strong> Time to search within the cluster(s) - constant or linear in cluster size</li>
                                    <li><strong>Total:</strong> Much faster than \(O(N)\) brute-force search</li>
                                </ul>
                                
                                <h5>How It Works:</h5>
                                <ol>
                                    <li>Partition all vectors into \(\sqrt{N}\) clusters using k-means</li>
                                    <li>For a query, find the nearest cluster(s): \(O(\sqrt{N})\) operations</li>
                                    <li>Search only within those clusters: \(O(k)\) where k is cluster size</li>
                                    <li>Total: \(O(\sqrt{N} + k)\) instead of \(O(N)\)</li>
                                </ol>
                                
                                <h5>Example:</h5>
                                <p>1,000,000 vectors partitioned into 1,000 clusters (1,000 vectors per cluster):</p>
                                <ul>
                                    <li><strong>Brute-force:</strong> Compare with all 1,000,000 vectors</li>
                                    <li><strong>IVF:</strong> Find nearest cluster (1,000 comparisons) + search within cluster (1,000 comparisons) = 2,000 total comparisons</li>
                                    <li><strong>Speedup:</strong> 500x faster!</li>
                                </ul>
                                
                                <h5>Trade-off:</h5>
                                <p>IVF is faster than brute-force but may miss vectors near cluster boundaries. HNSW is more accurate but uses more memory. Choose based on your accuracy vs speed requirements.</p>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>3. Product Quantization Compression Ratio</h4>
                            <div class="formula-display">
                                \[\text{compression\_ratio} = \frac{\text{original\_size}}{\text{compressed\_size}} = \frac{d \times 4 \text{ bytes}}{m \times \log_2(k) \text{ bits}}\]
                            </div>
                            <div class="formula-explanation">
                                <h5>What This Measures:</h5>
                                <p>Product Quantization (PQ) compresses vectors by quantizing sub-vectors into codebooks. This formula calculates the compression ratio achieved.</p>
                                
                                <h5>Breaking It Down:</h5>
                                <ul>
                                    <li><strong>\(d\):</strong> Original vector dimension (e.g., 384)</li>
                                    <li><strong>\(4 \text{ bytes}\):</strong> Size per float32 value (original storage)</li>
                                    <li><strong>\(m\):</strong> Number of sub-vectors (e.g., 8 sub-vectors of 48 dimensions each)</li>
                                    <li><strong>\(k\):</strong> Codebook size (number of quantization levels, e.g., 256)</li>
                                    <li><strong>\(\log_2(k) \text{ bits}\):</strong> Bits needed to store codebook index (e.g., \(\log_2(256) = 8\) bits = 1 byte)</li>
                                </ul>
                                
                                <h5>Example:</h5>
                                <p>Original: 384-dimensional vector = 384 × 4 bytes = 1,536 bytes<br>
                                PQ compressed: 8 sub-vectors × 1 byte = 8 bytes<br>
                                Compression ratio: \(\frac{1536}{8} = 192x\) reduction!</p>
                                
                                <h5>Trade-off:</h5>
                                <p>Higher compression = less storage but some accuracy loss. Typical PQ achieves 10-100x compression with minimal accuracy degradation (95%+ recall maintained).</p>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>4. Vector Database Query Time</h4>
                            <div class="formula-display">
                                \[T_{\text{query}} = T_{\text{embed}} + T_{\text{search}} + T_{\text{retrieve}}\]
                            </div>
                            <div class="formula-explanation">
                                <h5>What This Represents:</h5>
                                <p>Total query time in a RAG system is the sum of embedding generation, vector search, and document retrieval times. Understanding this breakdown helps you optimize each component.</p>
                                
                                <h5>Breaking It Down:</h5>
                                <ul>
                                    <li><strong>\(T_{\text{embed}}\):</strong> Time to convert query text to embedding vector (typically 10-50ms for local models, 50-200ms for API calls)</li>
                                    <li><strong>\(T_{\text{search}}\):</strong> Time to find top-k similar vectors in the database (typically 10-100ms with HNSW for millions of vectors)</li>
                                    <li><strong>\(T_{\text{retrieve}}\):</strong> Time to fetch actual document text using retrieved IDs (typically 1-10ms if documents are cached)</li>
                                </ul>
                                
                                <h5>Typical Breakdown:</h5>
                                <p>For a query in a system with 1M documents:</p>
                                <ul>
                                    <li>Embedding: 20ms (local model) or 100ms (API)</li>
                                    <li>Vector search: 50ms (HNSW index)</li>
                                    <li>Document retrieval: 5ms (cached)</li>
                                    <li><strong>Total: 75ms (local) or 155ms (API)</strong></li>
                                </ul>
                                
                                <h5>Optimization Strategies:</h5>
                                <ul>
                                    <li><strong>Reduce \(T_{\text{embed}}\):</strong> Cache query embeddings for common queries, use faster embedding models</li>
                                    <li><strong>Reduce \(T_{\text{search}}\):</strong> Use efficient indexes (HNSW), limit search space with metadata filters</li>
                                    <li><strong>Reduce \(T_{\text{retrieve}}\):</strong> Cache documents in memory, use fast storage (SSD, in-memory cache)</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>5. Index Build Time</h4>
                            <div class="formula-display">
                                \[T_{\text{build}} = O(N \log N)\]
                            </div>
                            <div class="formula-explanation">
                                <h5>What This Represents:</h5>
                                <p>Building an HNSW index takes \(O(N \log N)\) time, where \(N\) is the number of vectors. This is a one-time cost when indexing documents, but it's important to understand for planning indexing operations.</p>
                                
                                <h5>Breaking It Down:</h5>
                                <ul>
                                    <li><strong>\(N\):</strong> Number of vectors to index</li>
                                    <li><strong>\(O(N \log N)\):</strong> Time complexity - grows faster than linear but slower than quadratic</li>
                                    <li>For each vector, the algorithm needs to find its position in the graph structure</li>
                                </ul>
                                
                                <h5>Practical Times:</h5>
                                <ul>
                                    <li>10,000 vectors: ~1-5 seconds</li>
                                    <li>100,000 vectors: ~30-120 seconds (1-2 minutes)</li>
                                    <li>1,000,000 vectors: ~10-30 minutes</li>
                                    <li>10,000,000 vectors: ~2-8 hours</li>
                                </ul>
                                
                                <h5>Strategies for Large Datasets:</h5>
                                <ul>
                                    <li><strong>Batch indexing:</strong> Index in batches rather than one-by-one</li>
                                    <li><strong>Incremental updates:</strong> Use databases that support adding vectors without full rebuild (HNSW supports this)</li>
                                    <li><strong>Parallel indexing:</strong> Use multiple CPU cores to speed up index building</li>
                                    <li><strong>Background indexing:</strong> Build index in background while serving queries from old index</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div id="examples" class="content-section">
                        <h2>Detailed Examples</h2>
                        
                        <div class="example-box">
                            <h4>Example: Fixed-Size Chunking</h4>
                            <p><strong>Document:</strong> "Python is a programming language. It is widely used for data science. Machine learning uses Python extensively."</p>
                            
                            <p><strong>Chunk size:</strong> 50 characters, overlap: 10 characters</p>
                            
                            <p><strong>Chunks:</strong></p>
                            <ul>
                                <li>Chunk 1: "Python is a programming language. It is widely used for data"</li>
                                <li>Chunk 2: "for data science. Machine learning uses Python extensively."</li>
                            </ul>
                            
                            <p><strong>Note:</strong> Overlap ensures "for data" appears in both chunks, preserving context.</p>
                        </div>
                        
                        <div class="example-box">
                            <h4>Example: Sentence-Based Chunking</h4>
                            <p><strong>Document:</strong> "Python is a programming language. It is widely used. Machine learning uses Python."</p>
                            
                            <p><strong>Chunk size:</strong> 2 sentences</p>
                            
                            <p><strong>Chunks:</strong></p>
                            <ul>
                                <li>Chunk 1: "Python is a programming language. It is widely used."</li>
                                <li>Chunk 2: "It is widely used. Machine learning uses Python."</li>
                            </ul>
                            
                            <p><strong>Advantage:</strong> Preserves sentence integrity, better semantic coherence.</p>
                        </div>
                    </div>

                    <div id="implementation" class="content-section">
                        <h2>Implementation</h2>
                        
                        <div class="code-box">
                            <h4>Code Implementation</h4>
                            <pre><code class="language-python">from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter

# Fixed-size chunking
text_splitter = CharacterTextSplitter(
    separator="\n",
    chunk_size=1000,
    chunk_overlap=200,
    length_function=len
)

text = "Your long document text here..."
chunks = text_splitter.split_text(text)

# Recursive chunking (tries multiple separators)
recursive_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    length_function=len,
    separators=["\n\n", "\n", " ", ""]
)

chunks = recursive_splitter.split_text(text)

# Sentence-based chunking
from langchain.text_splitter import SentenceTransformersTokenTextSplitter

splitter = SentenceTransformersTokenTextSplitter(
    chunk_overlap=50,
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

chunks = splitter.split_text(text)</code></pre>
                        </div>
                    </div>

                    <div id="applications" class="content-section">
                        <h2>Real-World Applications</h2>
                        
                        <div class="explanation-box">
                            <h3>Chunking in RAG Systems</h3>
                            <p><strong>Document processing:</strong> Split large documents into manageable chunks for embedding and retrieval</p>
                            <p><strong>Context management:</strong> Ensure chunks fit within LLM context windows</p>
                            <p><strong>Retrieval optimization:</strong> Smaller, focused chunks improve retrieval precision</p>
                            <p><strong>Storage efficiency:</strong> Balance between chunk size and storage costs</p>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Best Practices</h3>
                            <p><strong>Chunk size:</strong> 200-1000 tokens (depends on embedding model and LLM context)</p>
                            <p><strong>Overlap:</strong> 10-20% of chunk size</p>
                            <p><strong>Strategy:</strong> Use semantic chunking when possible, fallback to sentence-based, then fixed-size</p>
                            <p><strong>Testing:</strong> Evaluate retrieval quality with different chunk sizes</p>
                        </div>
                    </div>

                    <div id="quiz" class="content-section">
                        <h2>Test Your Understanding</h2>
                        
                        <div class="quiz-container">
                            <div class="quiz-question">
                                <h3>Question 1: What is a vector database?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) A specialized database optimized for storing and efficiently searching high-dimensional vector embeddings using similarity search algorithms</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) A regular SQL database</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) A text storage system</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) A file system</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 2: Interview question: "What are the key features of vector databases for RAG?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Fast approximate nearest neighbor (ANN) search, scalable to millions of vectors, metadata filtering, real-time updates, and support for similarity metrics (cosine, Euclidean, dot product)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only fast search</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only storage</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Only metadata</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 3: What are popular vector databases used in RAG systems?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Pinecone, Weaviate, Chroma, Qdrant, FAISS, Milvus, and pgvector (PostgreSQL extension)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only MySQL</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only MongoDB</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Only Redis</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 4: Interview question: "What is HNSW indexing and why is it used in vector databases?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Hierarchical Navigable Small World - a graph-based ANN algorithm that provides fast approximate search with good accuracy, commonly used in production vector databases</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) A compression algorithm</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) A sorting method</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) A storage format</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 5: What is IVF (Inverted File Index) in vector databases?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) An indexing method that partitions vector space into clusters (Voronoi cells), enabling faster search by only searching relevant clusters</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) A file format</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) A compression method</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) A query language</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 6: Interview question: "How do you choose between different vector databases?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Consider scale (millions vs billions), deployment (cloud vs self-hosted), features (metadata filtering, real-time updates), cost, ease of use, and integration with your stack</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Always use the cheapest</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Always use the fastest</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Any database works</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 7: What is metadata filtering in vector databases?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Filtering search results by document metadata (date, author, category) before or after similarity search, enabling precise retrieval</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Filtering by vector similarity only</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Compressing metadata</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Metadata is not used</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 8: Interview question: "What is the difference between exact and approximate nearest neighbor search?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Exact search finds true nearest neighbors but is slow for large datasets. Approximate (ANN) is much faster with high accuracy, using indexing (HNSW, IVF) to trade some accuracy for speed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) They are the same</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Exact is always faster</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Approximate is always more accurate</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 9: What is FAISS and when would you use it?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Facebook AI Similarity Search - a library for efficient similarity search, good for self-hosted solutions, research, and when you need fine-grained control over indexing</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) A cloud service</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) A database management system</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) A query language</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 10: Interview question: "How do you handle vector database updates in a production RAG system?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Implement incremental updates, batch processing for large changes, re-indexing strategies, versioning for document updates, and ensure consistency between embeddings and metadata</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Rebuild entire database</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) No updates needed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Manual updates only</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 11: What is the difference between Pinecone and self-hosted solutions like Chroma?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Pinecone is managed cloud service (easy setup, scaling, but cost). Chroma is self-hosted (more control, lower cost, but requires infrastructure management)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) They are identical</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Pinecone is always better</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Chroma is always better</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 12: Interview question: "How do you scale a vector database for millions of documents?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Use distributed indexing, sharding by metadata or hash, horizontal scaling with multiple nodes, efficient indexing algorithms (HNSW), and consider approximate search for speed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Use a single server</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) No scaling needed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Only vertical scaling</div>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </section>
    </main>

    <footer style="background: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 2px solid #5B7553;">
        <div class="azbn-container" style="text-align: center;">
            <button onclick="scrollToSectionNav()" class="azbn-btn" style="margin: 0.5rem;">
                ↑ Back to Section Navigation
            </button>
            <div style="margin-top: 1.5rem;">
                <a href="/tutorials/rag" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">← Back to Tutorial</a>
                <a href="/tutorials/rag/chapter3" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">← Chapter 3</a>
                <a href="/tutorials/rag/chapter5" class="azbn-btn" style="text-decoration: none; margin: 0.5rem;">Chapter 5 →</a>
            </div>
        </div>
    </footer>
    
        <!-- KaTeX for math rendering -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
<script src="{{ url_for('static', filename='js/tutorials/shared-quiz.js') }}?v=2"></script>
<script src="{{ url_for('static', filename='js/tutorials/rag/shared-tutorial.js') }}?v=2"></script>
    <script>
            
// Initialize KaTeX rendering - ensure KaTeX is loaded first
        function initKaTeX() {
            if (typeof katex !== 'undefined' && typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "\\[", right: "\\]", display: true},
                        {left: "$", right: "$", display: false},
                        {left: "\\(", right: "\\)", display: false}
                    ],
                    throwOnError: false
                });
            } else {
                // Retry if KaTeX not loaded yet
                setTimeout(initKaTeX, 100);
                return;
            }
            
            // Initialize Prism.js syntax highlighting
            if (typeof Prism !== 'undefined') {
                Prism.highlightAll();
            }
        }
        
        // Wait for DOM and KaTeX to be ready
        if (document.readyState === 'loading') {
            document.addEventListener("DOMContentLoaded", initKaTeX);
        } else {
            // DOM already loaded, wait for KaTeX
            initKaTeX();
    </script>
</body>
</html>