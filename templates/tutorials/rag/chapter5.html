<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 5: Retrieval Strategies - RAG & Retrieval Systems</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/rag/rag.css') }}">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
    <!-- Prism.js for code syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>


</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav">
            <div class="azbn-container">
                <a href="/tutorials/rag" class="course-link">
                    <span>RAG & Retrieval Systems</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <div class="tutorial-header">
            <div class="azbn-container">
                <h1 class="chapter-title">Chapter 5: Retrieval Strategies</h1>
                <p class="chapter-subtitle">Finding Relevant Information</p>
                
                <div class="chapter-progress">
                    <div class="chapter-progress-fill" data-progress="71"></div>
                </div>
                
                <div class="chapter-navigation">
                    <a href="/tutorials/rag/chapter1" class="chapter-nav-btn ">Chapter 1</a>
                    <a href="/tutorials/rag/chapter2" class="chapter-nav-btn ">Chapter 2</a>
                    <a href="/tutorials/rag/chapter3" class="chapter-nav-btn ">Chapter 3</a>
                    <a href="/tutorials/rag/chapter4" class="chapter-nav-btn ">Chapter 4</a>
                    <a href="/tutorials/rag/chapter5" class="chapter-nav-btn active">Chapter 5</a>
                    <a href="/tutorials/rag/chapter6" class="chapter-nav-btn ">Chapter 6</a>
                    <a href="/tutorials/rag/chapter7" class="chapter-nav-btn ">Chapter 7</a>
                </div>
                
                <div class="section-progress">
                    <div class="section-progress-fill" data-progress="14.3"></div>
                </div>
                
                <div class="section-nav">
                    <button class="section-nav-btn azbn-btn active" data-section="overview">Overview</button>
                    <button class="section-nav-btn azbn-btn" data-section="concepts">Key Concepts</button>
                    <button class="section-nav-btn azbn-btn" data-section="formulas">Formulas</button>
                    <button class="section-nav-btn azbn-btn" data-section="examples">Examples</button>
                    <button class="section-nav-btn azbn-btn" data-section="implementation">Implementation</button>
                    <button class="section-nav-btn azbn-btn" data-section="applications">Applications</button>
                    <button class="section-nav-btn azbn-btn" data-section="quiz">Quiz</button>
                </div>
            </div>
        </div>

        <section class="azbn-section">
            <div class="azbn-container">
                <div class="learning-objectives-box">
                    <h2>Learning Objectives</h2>
                    <ul>
                        <li>Understand retrieval strategies fundamentals</li>
                        <li>Master the mathematical foundations</li>
                        <li>Learn practical implementation</li>
                        <li>Apply knowledge through examples</li>
                        <li>Recognize real-world applications</li>
                    </ul>
                </div>

                <main class="chapter-main-content">
                    <div id="overview" class="content-section active">
                        <h2>Retrieval Strategies</h2>
                        
                        <div class="explanation-box">
                            <h3>Introduction</h3>
                            <p><strong>Finding Relevant Information</strong></p>
                            <p>This chapter provides comprehensive coverage of retrieval strategies, including detailed explanations, mathematical formulations, code implementations, and real-world examples.</p>
                        </div>

                        <div class="example-box">
                            <h4>üìö Why This Matters</h4>
                            <p>Understanding retrieval strategies is crucial for mastering modern AI systems. This chapter breaks down complex concepts into digestible explanations with step-by-step examples.</p>
                        </div>
                    </div>

                    <div id="concepts" class="content-section">
                        <h2>Key Concepts</h2>
                        
                        <div class="explanation-box">
                            <h3>Dense vs Sparse Retrieval</h3>
                            <p><strong>Dense retrieval (semantic search):</strong></p>
                            <ul>
                                <li>Uses embeddings to find semantically similar documents</li>
                                <li>Handles synonyms and paraphrasing well</li>
                                <li>Example: Query "automobile" finds docs about "car"</li>
                                <li>More computationally expensive</li>
                            </ul>
                            
                            <p><strong>Sparse retrieval (keyword search):</strong></p>
                            <ul>
                                <li>Uses keyword matching (BM25, TF-IDF)</li>
                                <li>Faster but requires exact term matches</li>
                                <li>Example: Query "automobile" won't find "car" unless both terms present</li>
                                <li>Good for exact term matching</li>
                            </ul>
                            
                            <p><strong>Hybrid retrieval:</strong> Combines both methods for best results.</p>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Reranking Strategies</h3>
                            <p><strong>Why rerank:</strong> Initial retrieval may miss perfect matches. Reranking refines results.</p>
                            
                            <p><strong>Cross-encoder reranking:</strong></p>
                            <ul>
                                <li>More accurate than embedding similarity</li>
                                <li>Slower (processes query-document pairs)</li>
                                <li>Used on top-k candidates from initial retrieval</li>
                            </ul>
                            
                            <p><strong>LLM-based reranking:</strong> Uses LLM to score relevance, most accurate but slowest.</p>
                        </div>
                    </div>

                    <div id="formulas" class="content-section">
                        <h2>Mathematical Formulations</h2>
                        
                        <div class="formula-box">
                            <h4>Key Formulas</h4>
                            <div class="formula-display">
                                \[\text{retrieval\_score}(q, d) = \alpha \cdot \text{similarity}(E(q), E(d)) + \beta \cdot \text{keyword\_score}(q, d)\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(E(q), E(d)\): Query and document embeddings</li>
                                    <li>\(\text{similarity}\): Vector similarity (cosine, dot product)</li>
                                    <li>\(\text{keyword\_score}\): BM25 or TF-IDF score</li>
                                    <li>\(\alpha, \beta\): Weighting factors (typically \(\alpha + \beta = 1\))</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>BM25 Score</h4>
                            <div class="formula-display">
                                \[\text{BM25}(q, d) = \sum_{t \in q} \text{IDF}(t) \cdot \frac{f(t, d) \cdot (k_1 + 1)}{f(t, d) + k_1 \cdot (1 - b + b \cdot \frac{|d|}{\text{avgdl}})}\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(f(t, d)\): Term frequency in document</li>
                                    <li>\(\text{IDF}(t)\): Inverse document frequency</li>
                                    <li>\(|d|\): Document length</li>
                                    <li>\(\text{avgdl}\): Average document length</li>
                                    <li>\(k_1, b\): Tuning parameters</li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="formula-box">
                            <h4>Reranking Score</h4>
                            <div class="formula-display">
                                \[\text{rerank\_score}(q, d) = \text{CrossEncoder}(q, d)\]
                            </div>
                            <div class="formula-explanation">
                                <h5>Where:</h5>
                                <ul>
                                    <li>\(\text{CrossEncoder}\): Model that processes query and document together</li>
                                    <li>More accurate than embedding-based similarity (bi-encoder)</li>
                                    <li>Slower because it processes each query-document pair</li>
                                    <li>Typically used to rerank top-k candidates from initial retrieval</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <div id="examples" class="content-section">
                        <h2>Detailed Examples</h2>
                        
                        <div class="example-box">
                            <h4>Step-by-Step Examples</h4>
                            <h4>Example: Hybrid Search</h4>
                            <p><strong>Query:</strong> "Python machine learning library"</p>
                            
                            <p><strong>Vector search:</strong> Finds documents semantically similar (e.g., "scikit-learn", "TensorFlow")</p>
                            <p><strong>Keyword search:</strong> Finds documents with exact terms ("Python", "machine learning", "library")</p>
                            <p><strong>Hybrid:</strong> Combines both, retrieves documents that are both semantically relevant AND contain keywords</p>
                            
                            <p><strong>Result:</strong> Better retrieval quality than either method alone.</p>
                        </div>
                        
                        <div class="example-box">
                            <h4>Example: Reranking</h4>
                            <p><strong>Initial retrieval:</strong> Top-100 documents from vector search</p>
                            
                            <p><strong>Reranking:</strong> Use cross-encoder to score each (query, document) pair</p>
                            
                            <p><strong>Result:</strong> Top-5 most relevant documents after reranking</p>
                            
                            <p><strong>Benefit:</strong> Cross-encoder sees full query and document, more accurate than embedding similarity alone.</p>
                        </div>
                    </div>

                    <div id="implementation" class="content-section">
                        <h2>Implementation</h2>
                        
                        <div class="code-box">
                            <h4>Code Implementation</h4>
                            <pre><code class="language-python">import numpy as np

from sentence_transformers import SentenceTransformer, CrossEncoder
from rank_bm25 import BM25Okapi
import numpy as np

# Initialize models
embedder = SentenceTransformer('all-MiniLM-L6-v2')
reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

# Documents
documents = ["Python machine learning library", "scikit-learn tutorial", "TensorFlow guide"]

# Hybrid search
def hybrid_search(query, documents, alpha=0.7, top_k=5):
    # Vector search
    query_emb = embedder.encode([query])
    doc_embs = embedder.encode(documents)
    vector_scores = np.dot(query_emb, doc_embs.T)[0]
    
    # Keyword search (BM25)
    tokenized_docs = [doc.split() for doc in documents]
    bm25 = BM25Okapi(tokenized_docs)
    keyword_scores = bm25.get_scores(query.split())
    
    # Normalize scores
    vector_scores = (vector_scores - vector_scores.min()) / (vector_scores.max() - vector_scores.min() + 1e-8)
    keyword_scores = (keyword_scores - keyword_scores.min()) / (keyword_scores.max() - keyword_scores.min() + 1e-8)
    
    # Combine
    hybrid_scores = alpha * vector_scores + (1 - alpha) * keyword_scores
    
    # Get top-k
    top_indices = np.argsort(hybrid_scores)[-top_k:][::-1]
    return [documents[i] for i in top_indices]

# Reranking
def rerank(query, documents, top_k=3):
    # Initial retrieval (e.g., top-10 from vector search)
    initial_docs = documents[:10]
    
    # Rerank with cross-encoder
    pairs = [[query, doc] for doc in initial_docs]
    scores = reranker.predict(pairs)
    
    # Get top-k
    top_indices = np.argsort(scores)[-top_k:][::-1]
    return [initial_docs[i] for i in top_indices]</code></pre>
                        </div>
                    </div>

                    <div id="applications" class="content-section">
                        <h2>Real-World Applications</h2>
                        
                        <div class="explanation-box">
                            <h3>Where This Is Used</h3>
                            <h3>Retrieval Strategies in Practice</h3>
                            <p><strong>When to use vector search:</strong> Semantic similarity is important, synonyms matter, multilingual content</p>
                            <p><strong>When to use keyword search:</strong> Exact term matching needed, domain-specific terminology</p>
                            <p><strong>When to use hybrid:</strong> Best of both worlds, production systems often use this</p>
                            <p><strong>When to use reranking:</strong> Need highest accuracy, can afford extra latency</p>
                        </div>
                        
                        <div class="explanation-box">
                            <h3>Performance Trade-offs</h3>
                            <p><strong>Vector search:</strong> Fast, good semantic understanding, but may miss exact matches</p>
                            <p><strong>Keyword search:</strong> Very fast, exact matches, but misses synonyms</p>
                            <p><strong>Hybrid:</strong> Balanced, combines strengths, slightly slower</p>
                            <p><strong>Reranking:</strong> Most accurate, but slowest (processes each candidate)</p>
                        </div>
                    </div>

                    <div id="quiz" class="content-section">
                        <h2>Test Your Understanding</h2>
                        
                        <div class="quiz-container">
                            <div class="quiz-question">
                                <h3>Question 1: What are the main retrieval strategies in RAG?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Dense retrieval (semantic search), sparse retrieval (keyword/BM25), and hybrid retrieval (combining both)</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only keyword search</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only semantic search</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Random selection</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 2: Interview question: "What is the difference between dense and sparse retrieval?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Dense uses embeddings for semantic similarity (handles synonyms, paraphrasing). Sparse uses keyword matching (BM25, TF-IDF) for exact term matching. Dense is better for meaning, sparse for keywords</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) They are the same</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Dense is always better</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Sparse is always better</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 3: What is hybrid retrieval and why is it effective?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Combining dense and sparse retrieval scores, leveraging semantic understanding and keyword matching together for better results than either alone</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Using two different models</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Searching twice</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Hybrid is not effective</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 4: In the hybrid score formula \(\text{score}(q, d) = \alpha \times \text{BM25}(q, d) + (1 - \alpha) \times \text{cosine}(E(q), E(d))\), what does \(\alpha\) control?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) The weight between sparse (BM25) and dense (cosine similarity) scores. Higher Œ± emphasizes keywords, lower Œ± emphasizes semantics</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) The number of results</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) The similarity threshold</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) The embedding dimension</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 5: Interview question: "What is BM25 and how does it work?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Best Matching 25 - a probabilistic ranking function that scores documents based on term frequency, inverse document frequency, and document length normalization. Better than TF-IDF for retrieval</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) A neural network</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) An embedding model</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) A database</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 6: What is reranking in retrieval?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Re-scoring initial retrieval results using more accurate models (cross-encoders) to improve relevance ordering before passing to LLM</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Removing results</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Combining results</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Reranking is not used</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 7: Interview question: "When would you use dense vs sparse retrieval?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Dense for semantic queries, synonyms, paraphrasing. Sparse for exact keyword matching, technical terms, names. Hybrid for best of both</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Always use dense</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Always use sparse</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Random choice</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 8: What is a cross-encoder and how is it used in reranking?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) A model that processes query and document together (not separately like bi-encoder), providing more accurate relevance scores but slower. Used for reranking top-k results</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) A database</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) An embedding model</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) A search algorithm</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 9: Interview question: "How do you choose top-k for retrieval?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Balance context quality (more docs = more info) vs cost/latency (fewer = faster, cheaper). Typical: 3-10. Test on your data. Use reranking if retrieving more initially</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Always use k=1</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Always use k=100</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) k doesn't matter</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 10: What is the typical value of Œ± in hybrid retrieval?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) 0.3-0.7, often around 0.5. Tune based on your data - more semantic queries need lower Œ±, more keyword queries need higher Œ±</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Always 0.0</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Always 1.0</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Œ± is not used</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 11: Interview question: "How do you evaluate retrieval quality?"</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) Use metrics like precision@k, recall@k, MRR (Mean Reciprocal Rank), NDCG. Test on labeled query-document pairs. Measure downstream RAG answer quality</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Only check speed</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only check cost</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) No evaluation needed</div>
                            </div>
                            
                            <div class="quiz-question" style="margin-top: 2rem;">
                                <h3>Question 12: What is the trade-off between retrieval speed and accuracy?</h3>
                                <div class="quiz-option" onclick="checkAnswer(this, true)">A) More accurate methods (reranking, exact search) are slower. Approximate search (ANN) is faster but less accurate. Balance based on latency requirements and quality needs</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">B) Speed and accuracy are the same</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">C) Faster is always more accurate</div>
                                <div class="quiz-option" onclick="checkAnswer(this, false)">D) Slower is always more accurate</div>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </section>
    </main>

    <footer style="background: #f8f9fa; padding: 2rem 0; margin-top: 3rem; border-top: 2px solid #5B7553;">
        <div class="azbn-container" style="text-align: center;">
            <button onclick="scrollToSectionNav()" class="azbn-btn" style="margin: 0.5rem;">
                ‚Üë Back to Section Navigation
            </button>
            <div style="margin-top: 1.5rem;">
                <a href="/tutorials/rag" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Back to Tutorial</a>
                <a href="/tutorials/rag/chapter4" class="azbn-btn azbn-secondary" style="text-decoration: none; margin: 0.5rem;">‚Üê Chapter 4</a>
                <a href="/tutorials/rag/chapter6" class="azbn-btn" style="text-decoration: none; margin: 0.5rem;">Chapter 6 ‚Üí</a>
            </div>
        </div>
    </footer>
    
        <!-- KaTeX for math rendering -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
<script src="{{ url_for('static', filename='js/tutorials/shared-quiz.js') }}"></script>
<script src="{{ url_for('static', filename='js/tutorials/rag/shared-tutorial.js') }}"></script>
    <script>
            
// Initialize KaTeX rendering - ensure KaTeX is loaded first
        function initKaTeX() {
            if (typeof katex !== 'undefined' && typeof renderMathInElement !== 'undefined') {
                renderMathInElement(document.body, {
                    delimiters: [
                        {left: "$$", right: "$$", display: true},
                        {left: "\\[", right: "\\]", display: true},
                        {left: "$", right: "$", display: false},
                        {left: "\\(", right: "\\)", display: false}
                    ],
                    throwOnError: false
                });
            } else {
                // Retry if KaTeX not loaded yet
                setTimeout(initKaTeX, 100);
                return;
            }
            
            // Initialize Prism.js syntax highlighting
            if (typeof Prism !== 'undefined') {
                Prism.highlightAll();
            }
        }
        
        // Wait for DOM and KaTeX to be ready
        if (document.readyState === 'loading') {
            document.addEventListener("DOMContentLoaded", initKaTeX);
        } else {
            // DOM already loaded, wait for KaTeX
            initKaTeX();
