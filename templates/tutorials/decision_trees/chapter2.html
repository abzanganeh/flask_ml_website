<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 2: Decision Tree Mathematics - Decision Trees Tutorial</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/main.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/tutorials/clustering/clustering.css') }}">
    <script src="{{ url_for('static', filename='js/tutorials/clustering/shared-tutorial.js') }}"></script>
    <script src="{{ url_for('static', filename='js/tutorials/clustering/shared-quiz.js') }}"></script>
    <script src="{{ url_for('static', filename='js/tutorials/decision_trees/chapter2.js') }}"></script>
</head>
<body>
    <header class="azbn-header">
        <nav class="azbn-nav">
            <div class="azbn-container">
                <a href="/tutorials/decision-trees" class="course-link">
                    <span>Decision Trees Tutorial</span>
                </a>
                <div class="azbn-links">
                    <a href="/">Home</a>
                    <a href="/#about">About</a>
                    <a href="/tutorials/">Tutorials</a>
                    <a href="/#projects">Projects</a>
                    <a href="/contact">Contact</a>
                </div>
            </div>
        </nav>
    </header>

    <main class="main-content">
        <!-- Tutorial Header -->
        <div class="tutorial-header">
            <div class="azbn-container">
                <h1 class="chapter-title">Chapter 2: Decision Tree Mathematics</h1>
                <p class="chapter-subtitle">Dive deep into the mathematical foundations of decision trees, including entropy, information gain, and splitting criteria.</p>
                
                <!-- Chapter Progress Bar (2/5) -->
                <div class="chapter-progress">
                    <div class="chapter-progress-fill" data-progress="40"></div>
                </div>
                
                <!-- Chapter Navigation (All 5 chapters) -->
                <div class="chapter-navigation">
                    <a href="/tutorials/decision-trees/chapter1" class="chapter-nav-btn">Chapter 1</a>
                    <a href="/tutorials/decision-trees/chapter2" class="chapter-nav-btn active">Chapter 2</a>
                    <a href="/tutorials/decision-trees/chapter3" class="chapter-nav-btn">Chapter 3</a>
                    <a href="/tutorials/decision-trees/chapter4" class="chapter-nav-btn">Chapter 4</a>
                    <a href="/tutorials/decision-trees/chapter5" class="chapter-nav-btn">Chapter 5</a>
                </div>
                
                <!-- Section Progress Bar -->
                <div class="section-progress">
                    <div class="section-progress-fill" data-progress="16.67"></div>
                </div>
                
                <!-- Section Navigation -->
                <div class="section-nav">
                    <button class="section-nav-btn active" data-section="entropy">Entropy & Information</button>
                    <button class="section-nav-btn" data-section="information-gain">Information Gain</button>
                    <button class="section-nav-btn" data-section="gini">Gini Impurity</button>
                    <button class="section-nav-btn" data-section="splitting">Splitting Criteria</button>
                    <button class="section-nav-btn" data-section="demo">Interactive Demo</button>
                    <button class="section-nav-btn" data-section="quiz">Quiz</button>
                </div>
            </div>
        </div>

        <section class="azbn-section">
            <div class="azbn-container">
                <!-- Learning Objectives -->
                <div class="learning-objectives-box">
                    <h2>Learning Objectives</h2>
                    <ul>
                        <li>Understand entropy and its role in decision tree splitting</li>
                        <li>Learn how to calculate information gain</li>
                        <li>Master Gini impurity as an alternative splitting criterion</li>
                        <li>Understand different splitting criteria and when to use them</li>
                        <li>See mathematical concepts in action with interactive demos</li>
                    </ul>
                </div>

                <!-- Main Content Area -->
                <main class="chapter-main-content">
                    <!-- Entropy Section -->
                    <div id="entropy" class="content-section active">
                        <h2>Entropy & Information Theory</h2>
                        
                        <div class="explanation-box">
                            <h3>üé≤ Think of Entropy Like a Coin Flip</h3>
                            <p>Imagine you have a bag of coins. If all coins are fair (50% heads, 50% tails), you're very uncertain about what you'll get - this is high entropy. If all coins are weighted to always land heads, you're certain about the outcome - this is low entropy.</p>
                        </div>

                        <p>Entropy measures the amount of uncertainty or randomness in a dataset. In decision trees, we use entropy to determine how "pure" or "impure" a group of data points is.</p>

                        <div class="key-concept">
                            <h3>Mathematical Definition</h3>
                            <p>Entropy is calculated using the formula:</p>
                            <div class="formula">
                                <code>H(S) = -Œ£ p(x) √ó log‚ÇÇ(p(x))</code>
                            </div>
                            <p>Where:</p>
                            <ul>
                                <li><strong>H(S)</strong> is the entropy of set S</li>
                                <li><strong>p(x)</strong> is the proportion of class x in the set</li>
                                <li><strong>log‚ÇÇ</strong> is the logarithm base 2</li>
                            </ul>
                        </div>
                    </div>

                    <!-- Information Gain Section -->
                    <div id="information-gain" class="content-section">
                        <h2>Information Gain</h2>
                        
                        <div class="explanation-box">
                            <h3>üéÅ Information Gain = How Much We Learn</h3>
                            <p>Information gain measures how much we reduce uncertainty by splitting the data. If splitting gives us much more organized groups, we gain a lot of information!</p>
                        </div>

                        <div class="key-concept">
                            <h3>Information Gain Formula</h3>
                            <p>Information Gain is calculated as:</p>
                            <div class="formula">
                                <code>IG(S, A) = H(S) - Œ£ (|Sv|/|S|) √ó H(Sv)</code>
                            </div>
                        </div>
                    </div>

                    <!-- Gini Impurity Section -->
                    <div id="gini" class="content-section">
                        <h2>Gini Impurity</h2>
                        
                        <div class="explanation-box">
                            <h3>üéØ Gini: A Simpler Alternative to Entropy</h3>
                            <p>Gini impurity is another way to measure how "mixed" a dataset is. It's computationally faster than entropy and gives similar results in most cases.</p>
                        </div>

                        <div class="key-concept">
                            <h3>Gini Impurity Formula</h3>
                            <p>Gini impurity is calculated as:</p>
                            <div class="formula">
                                <code>Gini(S) = 1 - Œ£ p(x)¬≤</code>
                            </div>
                        </div>
                    </div>

                    <!-- Splitting Criteria Section -->
                    <div id="splitting" class="content-section">
                        <h2>Splitting Criteria</h2>
                        
                        <div class="explanation-box">
                            <h3>üîç How Decision Trees Choose the Best Split</h3>
                            <p>Decision trees try every possible way to split the data and pick the one that gives the most "pure" groups. It's like trying different questions to see which one best separates the data.</p>
                        </div>

                        <h3>Common Splitting Criteria</h3>
                        <div class="concept-grid">
                            <div class="concept-card">
                                <h4>ÔøΩÔøΩ Information Gain</h4>
                                <p>Maximizes the reduction in entropy. Good for balanced datasets.</p>
                            </div>
                            
                            <div class="concept-card">
                                <h4>üéØ Gini Impurity</h4>
                                <p>Minimizes the probability of misclassification. Faster computation.</p>
                            </div>
                            
                            <div class="concept-card">
                                <h4>üìà Information Gain Ratio</h4>
                                <p>Information gain divided by split information. Reduces bias toward multi-valued attributes.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Interactive Demo Section -->
                    <div id="demo" class="content-section">
                        <h2>Interactive Mathematics Demo</h2>
                        
                        <div class="explanation-box">
                            <h3>üßÆ Calculate Entropy & Information Gain</h3>
                            <p>Try different datasets and see how entropy and information gain change. This will help you understand the math behind decision tree splitting!</p>
                        </div>

                        <div class="interactive-demo">
                            <div class="demo-controls">
                                <button class="azbn-btn" onclick="generateMathDemo()">Generate Sample Data</button>
                                <button class="azbn-btn" onclick="calculateEntropy()">Calculate Entropy</button>
                                <button class="azbn-btn" onclick="calculateInformationGain()">Calculate Information Gain</button>
                                <button class="azbn-btn azbn-secondary" onclick="resetMathDemo()">Reset Demo</button>
                            </div>
                            
                            <div class="demo-status" id="math-demo-status">
                                <p>Click "Generate Sample Data" to start</p>
                            </div>
                            
                            <div class="demo-visualization">
                                <div class="demo-canvas" id="math-demo-canvas">
                                    <p>Mathematical calculations will appear here</p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Quiz Section -->
                    <div id="quiz" class="content-section">
                        <h2>Chapter 2 Quiz</h2>
                        
                        <div class="explanation-box">
                            <h3>üß† Test Your Mathematical Understanding</h3>
                            <p>Answer these questions to make sure you understand the math behind decision trees!</p>
                        </div>

                        <div class="quiz-container">
                            <div class="quiz-question">
                                <h4>Question 1: What is the entropy of a perfectly pure dataset?</h4>
                                <div class="quiz-options">
                                    <label class="quiz-option">
                                        <input type="radio" name="q1" value="a">
                                        <span>1.0</span>
                                    </label>
                                    <label class="quiz-option">
                                        <input type="radio" name="q1" value="b">
                                        <span>0.0</span>
                                    </label>
                                    <label class="quiz-option">
                                        <input type="radio" name="q1" value="c">
                                        <span>0.5</span>
                                    </label>
                                    <label class="quiz-option">
                                        <input type="radio" name="q1" value="d">
                                        <span>Depends on the data</span>
                                    </label>
                                </div>
                                <button class="check-answer-btn" onclick="checkAnswer(1, 'b')">Check Answer</button>
                                <div class="answer-feedback" id="feedback1"></div>
                            </div>

                            <div class="quiz-question">
                                <h4>Question 2: Which splitting criterion is computationally fastest?</h4>
                                <div class="quiz-options">
                                    <label class="quiz-option">
                                        <input type="radio" name="q2" value="a">
                                        <span>Information Gain</span>
                                    </label>
                                    <label class="quiz-option">
                                        <input type="radio" name="q2" value="b">
                                        <span>Gini Impurity</span>
                                    </label>
                                    <label class="quiz-option">
                                        <input type="radio" name="q2" value="c">
                                        <span>Information Gain Ratio</span>
                                    </label>
                                    <label class="quiz-option">
                                        <input type="radio" name="q2" value="d">
                                        <span>All are equally fast</span>
                                    </label>
                                </div>
                                <button class="check-answer-btn" onclick="checkAnswer(2, 'b')">Check Answer</button>
                                <div class="answer-feedback" id="feedback2"></div>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </section>
    </main>

    <!-- Sub-section Navigation Footer -->
    <div class="sub-section-nav-footer">
        <div class="sub-nav-buttons">
            <button id="prev-subsection" class="sub-nav-btn prev-btn">
                <span>‚Üê Previous</span>
                <span class="sub-nav-label" id="prev-label">What are Decision Trees?</span>
            </button>
            <button id="next-subsection" class="sub-nav-btn next-btn">
                <span class="sub-nav-label" id="next-label">Information Gain</span>
                <span>Next ‚Üí</span>
            </button>
        </div>
    </div>

    <!-- Chapter Navigation Footer -->
    <div class="navigation-buttons">
        <a href="/tutorials/decision-trees/chapter1" class="azbn-btn azbn-secondary" onclick="scrollToTop()">‚Üê Chapter 1: Introduction to Decision Trees</a>
        <a href="/tutorials/decision-trees/chapter3" class="azbn-btn azbn-secondary" onclick="scrollToTop()">Chapter 3: Python Implementation ‚Üí</a>
    </div>
</body>
</html>